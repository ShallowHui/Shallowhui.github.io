[{"title":"生成一个简洁、美观、方便的接口文档","url":"/posts/39655/","content":"## 前言\n\n日常开发中，接口文档是至关重要的，规范、清晰明了的接口文档更是能让人赏心悦目。虽然说接口文档是比较开放的~~看开发人员心情的~~，在哪写，怎么写都可以，只要项目成员之间看得懂就行了，但还是有必要建立一套规范，来说明接口文档应该如何写。\n\n## 规范\n\n[Swagger](https://swagger.io)是一个用于描述`RESTful API`的规范和工具集合，它以`yaml`或者`json`格式来描述接口的结构，方便机器读取：\n\n```yaml\nswagger: \"2.0\"\ninfo:\n  title: Sample API\n  description: API description in Markdown.\n  version: 1.0.0\n\nhost: api.example.com\nbasePath: /v1\nschemes:\n  - https\n\npaths:\n  /users:\n    get:\n      summary: Returns a list of users.\n      description: Optional extended description in Markdown.\n      produces:\n        - application/json\n      responses:\n        200:\n          description: OK\n```\n\n基于这个结构，Swagger中的一个工具`swagger-ui`就可以生成一个可交互的接口文档，是一个HTML页面，可以在浏览器中访问：\n\n![Swagger](https://cdn.jsdelivr.net/gh/shallowhui/cdn/picgo/swagger-ui.png)\n\n`Swagger规范(Swagger Specification)`在2015年左右逐渐演变成了`OpenAPI规范(OpenAPI Specification)`，这一转变进一步推动了API开放行业的发展。OpenAPI是Linux基金会的一个项目，Linux选择OpenAPI作为API的标准描述语言，让OpenAPI(Swagger)规范得到了广泛的接受，成为了事实上的行业标准。\n\n随着`OpenAPI 3.0`版本的发布，OpenAPI规范更加注重规范本身，而不关心具体实现的工具，所以与之对应的`Swagger 3`被视作为基于OpenAPI 3.0规范实现的一个工具集，之前版本的Swagger 2被称为`Swagger 2`或者`OpenAPI 2.0`规范。**如今，OpenAPI已经成为了描述RESTful API的标准规范，而Swagger则更多地被看作是实现这一规范的工具集。**\n\n[OpenAPI 3.0 Specification](https://swagger.io/docs/specification/about)的结构如下：\n\n```yaml\nopenapi: 3.0.0\ninfo:\n  title: Sample API\n  description: Optional multiline or single-line description in [CommonMark](http://commonmark.org/help/) or HTML.\n  version: 0.1.9\n\nservers:\n  - url: http://api.example.com/v1\n    description: Optional server description, e.g. Main (production) server\n  - url: http://staging-api.example.com\n    description: Optional server description, e.g. Internal staging server for testing\n\npaths:\n  /users:\n    get:\n      summary: Returns a list of users.\n      description: Optional extended description in CommonMark or HTML.\n      responses:\n        '200':    # status code\n          description: A JSON array of user names\n          content:\n            application/json:\n              schema: \n                type: array\n                items: \n                  type: string\n```\n\n也是可以用`yaml`或者`json`格式来编写。\n\n我们可以手写这样一份规范文件，然后再用Swagger工具来生成接口文档，但这显然工作量有点大，查OpenAPI的规范文档也让人头大。事实上，这可以通过在项目代码中使用注解来标记接口，让框架解析并自动生成，下面会介绍。\n\n## SpringBoot集成springdoc-openapi\n\n[springdoc-openapi](https://github.com/springdoc/springdoc-openapi)是一个可以将SpringBoot和SwaggerUI集成到一起的库。SpringBoot 2.x版本可以引入springdoc-openapi v1的版本，如下：\n\n```xml\n<dependency>\n    <groupId>org.springdoc</groupId>\n    <artifactId>springdoc-openapi-ui</artifactId>\n    <version>1.8.0</version>\n</dependency>\n```\n\n引入之后就可以直接访问接口文档了，SwaggerUI生成的接口文档默认地址是：`http://localhost:8080/swagger-ui.html`，生成的OpenAPI Specification可以通过`http://localhost:8080/v3/api-docs`访问。\n\n下面是一些基本配置：\n\n```yaml\nspringdoc:\n  swagger-ui:\n    path: /swagger-ui-custom.html # 自定义接口文档的地址\n  api-docs:\n    path: /v3/api-docs\n  # 接口分组，可以通过扫描包路径来分组，也可以通过匹配URL前缀来分组\n  group-configs:\n    - group: module1\n      # 指定要包含的接口路径前缀\n      pathsToMatch:\n        - /api/**\n    - group: module2\n      pathsToMatch:\n        - /**\n      pathsToExclude:\n        - /api/**\n```\n\n详细的配置可以编写一个配置类，对接口文档的基本信息进行一下配置：\n\n```java\nimport io.swagger.v3.oas.models.OpenAPI;\nimport io.swagger.v3.oas.models.info.Contact;\nimport io.swagger.v3.oas.models.info.Info;\nimport io.swagger.v3.oas.models.info.License;\nimport org.springframework.context.annotation.Bean;\nimport org.springframework.context.annotation.Configuration;\n\n@Configuration\npublic class OpenAPIConfig {\n    @Bean\n    public OpenAPI openAPI() {\n        return new OpenAPI()\n                .info(new Info()\n                        .title(\"接口文档的标题\")\n                        .description(\"接口文档的介绍\")\n                        .version(\"接口文档的版本 V1\")\n                        .license(new License().name(\"接口文档的许可协议 License\").url(\"https://zunhuier.top\"))\n                        .contact(new Contact().name(\"联系人 zunhuier\").email(\"联系人邮箱\")));\n    }\n}\n```\n\n在SwaggerUI中效果如图所示：\n\n![OpenAPI Config](https://cdn.jsdelivr.net/gh/shallowhui/cdn/picgo/swaggerui-info.png)\n\n最后，就是使用OpenAPI规范的注解，来注释各个Restful接口了，下面介绍这些注解的作用。\n\n## 注解\n\n### @Tag\n\n这个注解作用于类上，也可以标记到方法上，起一个标记的作用。一般加在Controller类上，表示这个Controller下的所有接口是某一类的接口，被归类到同一标记下，可以起到接口分组的作用。\n\n```java\nimport org.springframework.web.bind.annotation.*;\nimport io.swagger.v3.oas.annotations.tags.Tag;\n\n@RestController\n@Tag(name = \"测试接口\", description = \"这个controller里的都是测试接口\")\npublic class TestController {\n\n}\n```\n\n### @Operation\n\n一般加在接口方法上，表示这是一个操作，用来对接口进行详细的描述。后面讲的@Parameters、@ApiResponses注解的作用其实都可以直接用@Operation注解中的属性来说明实现，一个注解就能干很多事。\n\n```java\nimport org.springframework.web.bind.annotation.*;\nimport io.swagger.v3.oas.annotations.tags.Tag;\nimport io.swagger.v3.oas.annotations.Operation;\n\n@RestController\n@Tag(name = \"测试接口\", description = \"这个controller里的都是测试接口\")\npublic class TestController {\n  \n    @Operation(summary = \"修改用户信息\", description = \"上传用户id和用户信息\")\n    @PutMapping(\"/api/user/{id}\")\n    public CommonResponse<User> user(@RequestBody User user, @PathVariable(\"id\") int id) {\n        System.out.println(user);\n        // 修改用户信息...\n        return CommonResponse.result(ResultEnum.SUCCESS, user);\n    }\n\n}\n```\n\n### @Parameters和@Parameter\n\n这两个注解用于描述接口中的显式参数，显式参数是指`header、query、path、cookie`上的参数，不是请求体中的参数，请求体有专门的注解说明。@Parameters中可以有多个@Parameter。\n\n```java\nimport org.springframework.web.bind.annotation.*;\nimport io.swagger.v3.oas.annotations.tags.Tag;\nimport io.swagger.v3.oas.annotations.Operation;\nimport io.swagger.v3.oas.annotations.Parameter;\nimport io.swagger.v3.oas.annotations.Parameters;\nimport io.swagger.v3.oas.annotations.enums.ParameterIn;\n\n@RestController\n@Tag(name = \"测试接口\", description = \"这个controller里的都是测试接口\")\npublic class TestController {\n  \n    @Operation(summary = \"修改用户id\", description = \"上传用户id和用户信息\")\n    @Parameters({\n            @Parameter(name = \"id\", description = \"要修改的用户id\", in = ParameterIn.PATH, example = \"123\")\n    })\n    @PutMapping(\"/api/user/{id}\")\n    public CommonResponse<User> user(@RequestBody User user, @PathVariable(\"id\") int id) {\n        System.out.println(user);\n        // 修改用户信息...\n        return CommonResponse.result(ResultEnum.SUCCESS, user);\n    }\n\n}\n```\n\n**springdoc会自动扫描接口方法中的参数，推断参数的数据类型，以及根据@PathVariable注解判断出是path上的参数。如果要手动给接口方法中的参数添加描述，那@Parameter注解的`name`属性要设置成跟方法参数名一样。注意，`name`属性始终表示的是HTTP请求中的参数名。**\n\n### @RequestBody\n\n这个注解用来描述请求体中的内容，比如`Content-Type`是`multipart/form-data`、`application/x-www-form-urlencoded`或者`application/xml`等等类型的请求，还有可能是上传文件之类的请求，这类请求中的请求体内容可以通过这个注解来定义，关键是注解的`content`属性。\n\n```java\n@PostMapping(\"/api/hello\")\n@Operation(summary = \"Hello\", description = \"回复Hello\")\n@io.swagger.v3.oas.annotations.parameters.RequestBody(\n        content = @Content(mediaType = MediaType.MULTIPART_FORM_DATA_VALUE,\n        schema = @Schema(implementation = User.class))\n)\npublic CommonResponse<String> hello(User user) {\n    return CommonResponse.result(ResultEnum.SUCCESS, \"hello\");\n}\n```\n\n上面例子的接口方法中用一个实体类来接收参数，默认springdoc会把它解析为query上的参数，形如`/api/hello?username=xxx&birthday=xxx`，而POST请求一般参数是在请求体中的，所以可以通过@RequestBody注解来指明将`User`类中的属性解析为表单中的字段，以`multipart/form-data`的格式来传递参数。\n\n**注意，SpringMVC也有个@RequestBody注解，两者的包名不同，SpringMVC的@RequestBody注解可以加在接口方法的参数前面，表示请求参数是在请求体中以json的格式进行传递，springdoc会自动解析出来。**\n\n### @ApiResponses和@ApiResponse\n\n这两个注解用于描述接口的响应内容，默认情况下，springdoc会根据接口方法的返回值自动推断出要返回什么类型的数据。如果想要自定义响应内容，就可以使用这两个注解，@ApiResponses中可以有多个@ApiResponse。\n\n```java\nimport org.springframework.web.bind.annotation.*;\nimport io.swagger.v3.oas.annotations.tags.Tag;\nimport io.swagger.v3.oas.annotations.Operation;\nimport io.swagger.v3.oas.annotations.Parameter;\nimport io.swagger.v3.oas.annotations.Parameters;\nimport io.swagger.v3.oas.annotations.enums.ParameterIn;\nimport io.swagger.v3.oas.annotations.responses.ApiResponse;\nimport io.swagger.v3.oas.annotations.responses.ApiResponses;\n\n@RestController\n@Tag(name = \"测试接口\", description = \"这个controller里的都是测试接口\")\npublic class TestController {\n  \n    @Operation(summary = \"修改用户id\", description = \"上传用户id和用户信息\")\n    @Parameters({\n            @Parameter(name = \"id\", description = \"要修改的用户id\", in = ParameterIn.PATH, example = \"123\")\n    })\n    @ApiResponses({\n            @ApiResponse(responseCode = \"200\", description = \"成功，返回用户信息\"),\n            @ApiResponse(responseCode = \"400\", description = \"请求错误\", content = @Content)\n    })\n    @PutMapping(\"/api/user/{id}\")\n    public CommonResponse<User> user(@RequestBody User user, @PathVariable(\"id\") int id) {\n        System.out.println(user);\n        // 修改用户信息...\n        return CommonResponse.result(ResultEnum.SUCCESS, user);\n    }\n\n}\n```\n\n### @Schema\n\n这个注解用于描述数据模型，一般加在类的成员属性上，用于springdoc解析数据，比如上面那些例子中的`CommonResponse`和`User`类：\n\n```java\nimport com.fasterxml.jackson.annotation.JsonFormat;\nimport io.swagger.v3.oas.annotations.media.Schema;\nimport lombok.Data;\n\nimport java.util.Date;\n\n@Data // Lombok\npublic class User {\n\n    private int id;\n\n    @Schema(description = \"用户名字\", example = \"zunhuier\", requiredMode = Schema.RequiredMode.REQUIRED)\n    private String username;\n\n    @JsonFormat(pattern = \"yyyy-MM-dd\")\n    @Schema(description = \"用户生日\", example = \"1996-6-6\", format = \"date\", type = \"string\")\n    private Date birthday;\n\n}\n```\n\n```java\nimport com.paxsz.operation.entity.constant.ResultEnum;\nimport io.swagger.v3.oas.annotations.media.Schema;\nimport lombok.Data;\n\n@Data\npublic class CommonResponse<T> {\n\n    @Schema(description = \"响应的状态码\")\n    private int code;\n\n    @Schema(description = \"响应的消息\")\n    private String message;\n\n    @Schema(description = \"响应的数据\")\n    private T data;\n\n}\n```\n\n经过springdoc解析后，在OpenAPI中生成的Schema如下：\n\n![Schema](https://cdn.jsdelivr.net/gh/shallowhui/cdn/picgo/openapi-schema.png)\n\n**被红星标记的属性说明是必需的。**\n\n### @Hidden\n\n这个注解可以加在接口方法或者实体类的属性上，用于隐藏接口和不必要返回的属性，比如某个接口还没开发完成，就可以加个@Hidden注解隐藏起来，不显示在接口文档上。\n\n## 接口调试\n\nSwagger有一个很方便的功能，就是可以直接在接口文档页面上进行调试，类似Postman，只需要点击接口旁边的`Try it out`按钮即可打开调试页面，填好参数后即可发送请求进行调试：\n\n![Test](https://cdn.jsdelivr.net/gh/shallowhui/cdn/picgo/swagger-test.png)\n\n## 权限验证\n\n通常接口都会有权限验证，比如要携带token啥的，那接口调试怎么办？OpenAPI和Swagger提供了解决办法。\n\n首先在OpenAPI的配置类中定义`SecurityScheme`，然后通过`GlobalOpenApiCustomizer`给每个接口加上需要进行权限验证的Security OpenAPI属性：\n\n```java\n@Configuration\npublic class OpenAPIConfig {\n    @Bean\n    public OpenAPI openAPI() {\n        return new OpenAPI()\n                .info(new Info()\n                        .title(\"接口文档的标题\")\n                        .description(\"接口文档的介绍\")\n                        .version(\"接口文档的版本 V1\")\n                        .license(new License().name(\"接口文档的许可协议 License\").url(\"https://zunhuier.top\"))\n                        .contact(new Contact().name(\"联系人 zunhuier\").email(\"联系人邮箱\")));\n                .components(new Components().addSecuritySchemes(\"Token\", new SecurityScheme()\n                        .type(SecurityScheme.Type.APIKEY)\n                        .in(SecurityScheme.In.HEADER)\n                        .name(\"Authorization\"))); // 需要携带token的Authorization请求头\n    }\n\n    /**\n     * 给每个接口都加上权限验证\n     */\n    @Bean\n    public GlobalOpenApiCustomizer globalOpenApiCustomizer() {\n        return openApi -> {\n            if (openApi.getPaths() != null) {\n                openApi.getPaths().forEach((path, pathItem) -> {\n                    // 这里可以判断path\n                    pathItem.readOperations().forEach(operation -> {\n                        operation.addSecurityItem(new SecurityRequirement().addList(\"Token\"));\n                    });\n                });\n            }\n        };\n    }\n}\n```\n\n上面的配置表示，每次请求都需要在请求头中携带`Authorization`标头的api key。`SecurityScheme.Type`还有其它支持的验证方法，比如http basic认证，http bearer认证，oauth2认证等等。\n\n如果不是所有接口都需要验证，可以在`globalOpenApiCustomizer`方法的代码中，对path进行判断，排除掉某些接口。或者麻烦点，不全局添加，而是在每个需要的接口方法或者Controller类上添加@SecurityRequirement注解：\n\n```java\n@SecurityRequirement(name = \"Token\")\npublic CommonResponse<String> hello(User user, int abc) {\n    return CommonResponse.result(ResultEnum.SUCCESS, \"hello\");\n}\n```\n\n配置完成后，接口文档上的效果如图所示：\n\n![Authorization](https://cdn.jsdelivr.net/gh/shallowhui/cdn/picgo/swagger-lock.png)\n\n页面上就会多了小锁的图标，最上面的绿色那个是全局验证，接口旁边的灰色小锁是每个接口单独的验证，点击图标就可以添加验证了，比如输入token。\n\n## JSR-303规范注解\n\n一般我们需要对请求参数进行校验，常用的是`JSR-303规范`下的一套Bean Validation注解，比如：\n\n```java\nimport com.fasterxml.jackson.annotation.JsonFormat;\nimport io.swagger.v3.oas.annotations.media.Schema;\nimport lombok.Data;\n\nimport javax.validation.constraints.Size;\nimport java.util.Date;\n\n@Data\npublic class User {\n\n    @Schema(description = \"主键\")\n    private int id;\n\n    @Schema(description = \"用户名字\", example = \"zunhuier\", requiredMode = Schema.RequiredMode.REQUIRED)\n    @Size(min = 3, max = 100) // 规定长度最小为3，最大为100\n    private String username;\n    \n    @JsonFormat(pattern = \"yyyy-MM-dd\")\n    @Schema(description = \"用户生日\", example = \"1996-6-6\", format = \"date\", type = \"string\")\n    private Date birthday;\n\n}\n```\n\n```java\nimport org.springframework.validation.annotation.Validated;\n\n// 记得添加@Validated注解\npublic CommonResponse<User> user(@Validated @RequestBody User user, @PathVariable(\"id\") int id) {\n    // 修改用户信息...\n    return CommonResponse.result(ResultEnum.SUCCESS, user);\n}\n```\n\n类似的注解还有@Min、@Max、@NotNull和@NotBlank等等，springdoc会自动检测到这些校验注解，并解析到接口文档上：\n\n![Validation](https://cdn.jsdelivr.net/gh/shallowhui/cdn/picgo/swagger-validation.png)\n\n## 总结\n\nspringdoc的官方文档对如何使用这些注解解释的比较少，不够全面，造成了可能接口文档上的内容跟自己预期的不太一样，需要多查看OpenAPI的规范文档，来了解OpenAPI中具体有哪些属性，跟注解中的属性对不对得上，是否可以用来输出自己想要的自定义内容。","tags":["OpenAPI","Swagger"],"categories":["技术"]},{"title":"EventSoruce简介","url":"/posts/1242/","content":"## 简介\n\n由于HTTP协议只是一个请求和响应的协议，所以实现服务器与客户端之间长时间的实时通信需要其他技术。`WebSocket`应该是较广为人知的一种技术，它定义了一个可以全双工通信的协议，但这篇文章主要介绍的是另外一种技术，`EventSource`。\n\n**EventSource是Web内容与`服务器发送事件`（Server Sent Event，SSE）的一个接口**。一个EventSource的实例对象会与HTTP服务器开启一个持久化（keep-alive）的连接，以`text/event-stream`的格式发送事件消息，此连接会一直保持开启，并且在发生错误时会自动尝试重连，直到通过调用`EventSource.close()`来关闭这个长连接。\n\n具体的API可以查看[MDN文档](https://developer.mozilla.org/zh-CN/docs/Web/API/EventSource)。\n\n### 与WebSocket的比较\n\n简单与WebSocket协议比较一下：\n\n+ 基于的协议：WebSocket在初始化连接时需要先通过HTTP协议来进行协议升级，之后就是基于TCP协议来进行通信的。EventSource就是基于一个HTTP长连接来进行通信。\n+ 通信方式：WebSocket是全双工通信，也就是服务器和客户端之间可以互相发送消息。而EventSource只能由服务器发送消息给客户端来进行单向通信，所以叫`SSE`。\n+ 复杂性：EventSource是纯文本的简单协议，API比较简单，容易实现。WebSocket除了能发送文本消息，还有自定义数据帧和传输二进制数据等其它功能，API相对比较复杂。\n+ 服务器支持：WebSocket需要服务器实现WebSocket协议。而EventSource只需要服务器按`text/event-stream`的格式往HTTP连接中写数据并发送就可以了。\n+ 兼容性：EventSource和WebSocket在大多数现代浏览器中都得到了广泛的支持，但WebSocket可能在一些比较旧的浏览器中支持得不太好或者直接不支持。\n\n总结一下，使用EventSource来实现通信比较简单，如果网站只是需要服务器往客户端发送数据，不需要客户端往服务器发送数据，比如天气消息推送服务、股票数据实时更新，那么EventSource就非常适用了。如果需要实现服务器和客户端的交互，进行实时双向通信，或者自定义协议等更高级的功能场景，那就要使用WebSocket。\n\n## 实现SSE\n\n下面简单实现一个SSE的Demo。\n\n### 服务器实现\n\n使用SpringBoot框架搭建一个HTTP服务，在Controller中定义一个专门处理SSE的方法：\n\n```java\n@Controller\npublic class SSEController {\n\n    @GetMapping(\"/sse\")\n    public void sse(HttpServletResponse response) {\n\n        System.out.println(\"客户端连接...\");\n\n        response.setContentType(\"text/event-stream\");\n        response.setCharacterEncoding(\"UTF-8\");\n\n        try (PrintWriter writer = response.getWriter()) {\n\n            while (!writer.checkError()) {\n                double random = Math.random();\n                System.out.println(\"生成随机数字：\" + random);\n                writer.write(\"event:test\\n\");\n                writer.write(\"data:随机数字：\" + random + \"\\n\\n\");\n                writer.flush();\n                TimeUnit.SECONDS.sleep(3L);\n            }\n\n            System.out.println(\"客户端断开连接!\");\n\n        } catch (IOException | InterruptedException e) {\n            e.printStackTrace();\n        }\n    }\n\n}\n```\n\n由于EventSource要建立的是一个HTTP长连接，不能直接return返回数据，这样Spring MVC是会关闭这个连接的，客户端那边的EventSource对象又会自动尝试重连，就会不断地请求这个接口，创建多个连接，所以要用循环来维持这一个长连接，并用`HttpServletResponse`实例对象发送数据。\n\n首先设置`text/event-stream`和`UTF-8`编码的响应头，然后获取`response`对象的字符输出流，在循环中不断地通过`writer.checkError()`方法来检测客户端是否关闭了这个连接，如果连接没有关闭，就随机生成一些数据写入到输出流中，发送给客户端。\n\n注意`write()`方法中写入数据的格式，EventSource定义一个事件由4个字段组成：`event`、`data`、`id`、`空行`，也就是说在EventSource的连接中，一个事件消息的数据格式应该是这样的：\n\n```text\nevent:{事件类型的名字}\ndata:{消息内容}\nid:{事件id}\n\nevent:{事件类型的名字}\ndata:{消息内容}\nid:{事件id}\n\nevent:{事件类型的名字}\ndata:{消息内容}\nid:{事件id}\n```\n\n**每个事件消息中间都要有个空行作为分隔标识**。`event`字段是事件类型的名字，与EventSource对象上的事件监听器相对应，可以没有这个字段，没有就是无名事件，默认由EventSource的`message`事件监听器来处理。`id`字段是事件的id，主要用于确认该类型事件的最后一个消息的id，也可以没有。\n\n**另外，EventSource建立连接是通过`GET`请求的。**\n\n### 客户端实现\n\nEventSource是浏览器原生支持的，可以在js中直接使用，这里简单在SpringBoot中写了个`index.html`静态页面：\n\n```html\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <title>SSE</title>\n    <script>\n        var source\n\n        function start() {\n            source = new EventSource(\"/sse\");\n            source.onmessage = function(event) {\n                console.log('接收message事件:' + event.data)\n                document.getElementById('result').innerText = event.data\n            }\n            source.onerror = function() {\n                console.log('连接失败')\n                source.close()\n            }\n            source.addEventListener('test', (event) => {\n                console.log('接收test事件:' + event.data)\n                document.getElementById('result').innerText = event.data\n            })\n        }\n\n        function stop() {\n            source.close()\n            console.log('关闭连接')\n        }\n    </script>\n</head>\n<body>\n    <div id=\"result\"></div>\n    <hr>\n    <button onclick=\"start()\">开启连接</button>\n    <button onclick=\"stop()\">关闭连接</button>\n</body>\n</html>\n```\n\n在js代码中，通过`new EventSource()`实例化一个EventSource对象，参数是HTTP服务的URL。`source.onmessage`和`source.onerror`是在设置EventSource默认监听器的回调函数，EventSource有三个默认的监听器，分别是：\n\n+ `error`：与服务器建立连接失败时触发。\n+ `message`：处理无名事件。\n+ `open`：与服务器建立连接时触发。\n\n如果想处理自定义事件的话，可以通过`addEventListener()`函数自己添加一个监听器。\n\n## 过程解析\n\n启动SpringBoot，在浏览器中打开页面并点击开启连接按钮，F12查看EventSource建立连接的请求：\n\n![Header](https://cdn.jsdelivr.net/gh/shallowhui/cdn/picgo/eventsourceheader.png)\n\n因为响应的是`text/event-stream`格式的数据，所以这里看不到普通HTTP响应的响应体之类的数据，要在`EventStream`选项卡中才能看到响应的数据：\n\n![EventStream](https://cdn.jsdelivr.net/gh/shallowhui/cdn/picgo/eventstream.png)\n\n可以看到一行行的事件消息形成的事件流，最终页面效果如下：\n\n![HTML](https://cdn.jsdelivr.net/gh/shallowhui/cdn/picgo/eventsourcehtml.png)","tags":["JavaScript","EventSource"],"categories":["技术"]},{"title":"OAuth 2.0协议简介","url":"/posts/5824/","content":"## 简介\n\n`OAuth 2.0`是一种授权框架，一个协议，它可以让第三方应用获得互联网上一个HTTP服务的有限访问权限，从而可以访问受保护的资源。例如授权某个应用获得你微信的头像、用户名等基本信息。\n\n> OAuth协议还有个OAuth 1.0协议，是一个小范围内的社区进行实践的结果，OAuth 2.0是基于1.0的实践经验以及更多实际使用案例和扩展性要求而建立的。两者可以在网络上共存，但2.0不向后兼容1.0，两者有各自的实现。\n\nOAuth 2.0是基于HTTP协议的，有关于OAuth 2.0协议的详细文档，可以参考[RFC 6749](https://datatracker.ietf.org/doc/html/rfc6749)。\n\n## 角色\n\nOAuth 2.0定义了四种角色：\n\n1. resource owner：能够授予对受保护资源的访问权限的实体。当资源所有者是一个人时，它被称为最终用户。\n2. resource server：托管受保护资源的服务器，能够响应携带访问令牌的受保护资源请求。\n3. client：代表资源所有者并经其授权进行受保护资源请求的应用程序。\n4. authorization server：在成功验证资源所有者的身份并获得授权后向客户端发放访问令牌的服务器。\n\n类似上面的例子，用户即是资源所有者，第三方应用即是客户端，微信则是即充当了授权服务器又充当了资源服务器。\n\n除此之外，还有个重要的组成`user agent`，用户是通过它与客户端进行交互的，一般来说，user agent指的就是浏览器、App。\n\n## Authorization Grant\n\n**OAuth 2.0协议的授权许可(Authorization Grant)，指的是一种凭证，代表着资源所有者对客户端的授权，被客户端用于获取访问令牌。**\n\nOAuth 2.0协议定义了四种授权许可的类型：\n\n1. Authorization Code Grant：授权码。\n2. Implicit：隐式授权。\n3. Resource Owner Password Credentials：资源所有者密码凭证。\n4. Client Credentials：客户端凭证。\n\n由于后面三种授权类型使用得不是很多，而且第一种授权码类型使用得最广泛，也是最安全的，所以，下面只重点介绍一下授权码类型的授权流程。\n\n## 授权码许可\n\n完整的流程图：\n\n![Authorization Code Grant](https://cdn.jsdelivr.net/gh/shallowhui/cdn/picgo/authorizationcode.png)\n\n简单来说，就两大步：\n\n1. 获取授权码 (code)。\n2. 根据授权码去获取访问令牌 (access_token)。\n\n### 客户端注册\n\n首先，客户端需要到授权服务器上面进行注册，一般都是登录授权服务器的网站，然后填写表单信息进行注册的。\n\n客户端需要告诉授权服务器所需的各种信息，比如应用类型、应用名、应用的回调地址、应用logo等等，这些都需要授权服务器去进行审核以此判断该应用是否正规，就比如微信也不可能随便就允许任意一个第三方应用来请求获得自身微信用户的信息。\n\n**最后，客户端会获得授权服务器给予的一个应用id和应用密钥，这是用来对客户端进行认证的，客户端需要将这两个数据保存好，不能泄露。**\n\n### 授权请求\n\n**当用户希望在第三方应用上，使用自己其它平台的信息时，比如想要在第三方应用上使用微信进行登录，就需要由第三方应用也就是客户端，引导用户向授权服务器发起一个授权请求，也就是去访问授权服务器。**\n\n先是由客户端根据授权服务器的授权端点构造好一个请求地址，这个地址以`application/x-www-form-urlencoded`的方式携带以下参数：\n\n| | 参数名 | 描述 |\n| :------: | :------: | :------: |\n| 必须 | response_type | 响应类型，这里必须为`code` |\n| 必须 | client_id | 上面注册客户端时获取到的应用id |\n| 可选 | redirect_uri | 回调地址，如果为空，则使用注册时填的回调地址 |\n| 可选 | scope | 访问请求的范围 |\n| 可选 | state | 客户端用来维护状态的一个随机值，用于防止CSRF攻击 |\n\n再让用户通过`GET`请求去访问这个地址。\n\n请求示例：\n\n```text\nGET /authorize?response_type=code&client_id=s6BhdRkqt3&state=xyz&redirect_uri=https%3A%2F%2Fclient%2Eexample%2Ecom%2Fcode HTTP/1.1\n\nHost: authorize_server.example.com\n```\n\n**值得注意的是，这里介绍的都是OAUth 2.0的规范步骤，至于具体的实现细节需要结合实际情况自己考虑。**\n\n比如，如何让用户发起授权请求？具体对于一个第三方Web应用来说，用户要想使用微信进行登录，浏览器就会跳转到微信自身的授权网站，这个网站上会显示一个二维码，用户使用手机微信扫码后就授权登录了。那一般的，可以这样实现：用户点击一个链接，浏览器就向应用的后端接口发送一个请求，后端返回一个重定向响应，重定向的目标地址就是上面构造好的地址，这样用户的浏览器就会跳转到授权服务器自身的授权页面了。\n\n**总之，客户端通过重定向或者其它方式，让用户代理跳转到授权服务器的授权端点。**一般的，授权服务器会先对用户进行一个认证，认证成功后，再显示是否允许对客户端的授权，以及确认授予客户端哪些权限，这个权限范围对应的就是`scope`参数。用户同意之后，授权服务器也会返回给用户代理一个重定向响应，目标地址就是`redirect_url`参数指定的地址，一般是跳转回客户端。\n\n### 授权响应\n\n授权服务器返回的重定向响应中，会在目标地址后面添加几个特定的参数，响应示例如下：\n\n```text\nHTTP/1.1 302 Found\n\nLocation: http://client.example.com/code?code=SplxlOBeZQQYbYS6WxSbIA&state=xyz\n```\n\n**其中`code`参数表示授权码，就是授权服务器返回给客户端的授权许可，客户端需要根据这个授权码，再去授权服务器获取访问令牌。**\n\n#### 为什么不直接返回访问令牌\n\n这里可能会产生一个疑问，为什么授权服务器不直接返回访问令牌，还要客户端根据授权码再去获取？\n\n这是因为安全问题，因为授权服务器是通过让用户代理重定向到客户端来传递参数，也就是通过`HTTP`请求，但不是所有客户端都支持`HTTPS`访问的，所以如果授权服务器直接返回访问令牌，那在用户代理重定向访问到客户端的时候，访问令牌就有可能泄露出去。\n\n而如果只有授权码泄露出去的话，是没什么问题的，因为要获取到访问令牌，除了授权码，还要有客户端的应用密钥，也就是之前注册的时候得到的密钥，而应用密钥是保存在客户端的，还有授权码一般是只能使用一次。\n\n反之，授权服务器是一定(要)支持`HTTPS`访问的，所以，客户端用授权码和应用密钥去访问授权服务器是安全的，不用担心应用密钥泄露。\n\n### 访问令牌请求\n\n客户端拿到授权码之后，可以通过`POST`请求访问授权服务器的令牌端点，并以`application/x-www-form-urlencoded`的方式携带以下参数：\n\n| | 参数名 | 描述 |\n| :------: | :------: | :------: |\n| 必须 | grant_type | 授权类型，这里必须为`authorization_code` |\n| 必须 | code | 授权码 |\n| 必须 | secret | 应用密钥 |\n| 必须 | client_id | 应用id |\n\n请求示例如下：\n\n```text\nPOST /token HTTP/1.1\n\nHost: authorize_server.example.com\nContent-Type: application/x-www-form-urlencoded\n\ngrant_type=authorization_code&code=SplxlOBeZQQYbYS6WxSbIA&secret=czZCaGRSa3F0MzpnWDFmQmF0M2JW&client_id=s6BhdRkqt3\n```\n\n### 访问令牌响应\n\n授权服务器如果对访问令牌请求校验成功了，会返回如下成功的响应示例：\n\n```text\nHTTP/1.1 200 OK\n\nContent-Type: application/json;charset=UTF-8\nCache-Control: no-store\nPragma: no-cache\n\n{\n    \"access_token\":\"2YotnFZFEjr1zCsicMWpAA\",\n    \"token_type\":\"example\",\n    \"expires_in\":3600,\n    \"refresh_token\":\"tGzv3JOkF0XG5Qx2TlKWIA\",\n    \"example_parameter\":\"example_value\"\n}\n```\n\n`access_token`就是访问令牌，客户端可以用这个令牌去访问资源服务器，从而在相应权限下，获得用户也就是资源所有者的相关信息。访问令牌有时效，可以通过`refresh_token`去重置时效。\n\n**注意，访问令牌一般是只保存在客户端，由客户端来跟资源服务器进行交互的，不会保存到用户代理那里。**\n\n## 总结\n\n正如上面所说，`RFC`只是一个建议标准，一种规范，具体的实现细节需要自己考虑。比如上面的访问令牌请求的参数，会跟`RFC`文档里的有点不太一样，这是因为可能每个授权服务器的具体接口实现不太一样，这里参考了微信开放平台的[文档](https://developers.weixin.qq.com/doc/oplatform/Website_App/WeChat_Login/Wechat_Login.html)，其访问令牌请求参数是自己定义的，而且微信用的是`GET`请求。如果想要自己实现一个OAuth 2.0的客户端，接入第三方登录的话，需要去参考实际授权平台的OAuth接入文档。\n\n但总的来说，OAuth 2.0协议授权的流程、步骤，是在`RFC`中定义好的规范。","tags":["OAuth2"],"categories":["技术"]},{"title":"Python数据分析","url":"/posts/12550/","content":"## NumPy\n\nNumPy是Python中进行科学计算的基础包，它提供了一个多维的数组对象，这比Python基本的列表数据结构强大的多，以及可以对其执行各种科学计算的方法，包括矩阵、逻辑、排序、线性代数、基本统计等等运算。\n\nNumPy已经成为Python中处理数值数据的通用标准，几乎用于科学和工程的每个领域。NumPy的数据结构和API广泛应用于科学Python包。\n\n### 安装NumPy并导入\n\n安装：\n\n```bash\n$ pip install numpy\n```\n\n导入：\n\n```python\nimport numpy as np # 简写为np比较方便\n```\n\n### n维数组\n\nNumPy中多维数组对象由`ndarray`类提供，它描述了`相同类型`元素的集合，即数组中每个元素占用的内存大小是相同的，数据类型由`dtype`属性定义。数组通常是固定大小的容器，数组中的维数和项数由其形状决定，数组的形状是一个指定了`每个维度的大小`的`非负整数元组`，由`shape`属性定义。\n\n在NumPy中，维度称为`轴`，例如下面这个二维数组：\n\n    [[0, 0, 0], \n     [1, 1, 1]]\n    \n这个数组具有2个轴，第一个轴的长度大小为2，第二个轴的长度大小为3，形状可以用一个元组表示为：`(2, 3)`。\n\n### 创建数组\n\n要创建`ndarray`数组对象，可以使用`np.array()`函数。\n\n可以将一个列表或元组传递给这个函数，返回一个转换后的数组对象：\n\n```python\n>>> np.array((1,2,3))\narray([1, 2, 3])\n\n>>> np.array([[0,0,0],[1,1,1]])\narray([[0, 0, 0],\n       [1, 1, 1]])\n\n>>> a = np.array([[1,2], [3,4]])\n>>> a.dtype\ndtype('int64')\n>>> a.shape\n(2, 2)\n```\n\n除此之外，还有很多高级函数可以用来创建数组对象，下面简单介绍两个。\n\n指定创建一个内容是给定区间`[start, stop)`内均匀分布的值的一维数组：\n\n```python\n>>> np.arange(10)\narray([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n```\n\n`np.arange()`函数的区间start默认为0，步长默认为1，可以自定义：\n\n```python\n>>> np.arange(1, 5, step=0.5)\narray([1. , 1.5, 2. , 2.5, 3. , 3.5, 4. , 4.5])\n```\n\n`np.linspace`函数可以生成在给定区间`[start, stop]`内，均匀分布的若干个样本值，`num`默认为50：\n\n```python\n>>> np.linspace(0, 10, num=3)\narray([ 0.,  5., 10.])\n```\n\nNumPy的数组对象中默认数据类型是浮点型（`np.float64`），但创建数组时可以通过`dtype`指定数据类型：\n\n```python\n>>> np.linspace(0, 10, num=3, dtype=np.int64)\narray([ 0,  5, 10], dtype=int64)\n```\n\nNumPy数据类型有一套自己的定义，与C语言的类型紧密联系，可以参考：\n\n[basics.types](https://numpy.org/doc/stable/user/basics.types.html)\n\n### 索引和切片\n\n数组对象中的元素可以通过索引和切片来访问。\n\n正如Python列表可以通过形如`list[index]、list[m:n]`的方式进行索引和切片一样，`ndarray`也可以通过这样的方式进行索引和切片。\n\n比如，有这样一个一维数组：\n\n```python\n>>> a = np.array([1, 2, 3, 4, 5, 6])\n```\n\n访问数字6：\n\n```python\n>>> a[5]\n6\n```\n\n访问数字3及后面的数字：\n\n```python\n>>> a[2:]\narray([3, 4, 5, 6])\n```\n\n**NumPy扩展了`[]`语法的能力，使得支持多维数组的索引和切片**。比如有这样一个二维数组：\n\n```python\n>>> b = np.array([[1,2,3], [4,5,6], [7,8,9]])\n>>> b\narray([[1, 2, 3],\n       [4, 5, 6],\n       [7, 8, 9]])\n```\n\n把它当成一个矩阵，如果想访问第二行第三列的元素：\n\n```python\n>>> b[1,2]\n6\n```\n\n访问第二行所有元素：\n\n```python\n>>> b[1,:]\narray([4, 5, 6])\n```\n\n不止如此，NmuPy还扩展出了高级索引的能力，功能非常强大。\n\n比如有这样一个数组：\n\n```python\n>>> x = np.arange(10, 0, -1)\n>>> x\narray([10,  9,  8,  7,  6,  5,  4,  3,  2,  1])\n```\n\n可以通过一个整数数组去索引访问x，这样可以一次性返回多个元素：\n\n```python\n>>> x[np.array([3,4,9])]\narray([7, 6, 1])\n```\n\n还可以通过布尔数组去索引访问x：\n\n```python\n>>> x[x>6]\narray([10,  9,  8,  7])\n```\n\n这是因为通过比较运算符，数组对象的逻辑运算会返回一个相同形状的布尔数组：\n\n```python\n>>> x>6\narray([ True,  True,  True,  True, False, False, False, False, False, False])\n```\n\n然后，根据布尔数组中为`True`的元素，对应位置上的数组`x`的元素就会被索引到。\n\n### 基本数组操作\n\n数组对象之间可以进行加、减、乘、除等运算。\n\n例如：\n\n```python\n>>> a = np.array([1,2])\n>>> b = np.array([3,4])\n\n>>> a + b\narray([4, 6])\n\n>>> a - b\narray([-2, -2])\n\n>>> a * b\narray([3, 8])\n\n>>> a / b\narray([0.33333333, 0.5       ])\n```\n\n数组还可以与单个数字之间进行运算，这在NumPy中被称为向量与标量的运算：\n\n```python\n>>> a + 1\narray([2, 3])\n\n>>> a * 3\narray([3, 6])\n```\n\n### 广播\n\n上面数组对象之间运算，是发生在两个形状相同的数组之间的。如果想要两个不同形状的数组之间进行运算，需要用到NumPy的`广播`概念，实际上，上面的数组与一个数字进行运算，正是用到了广播。\n\n**NumPy认为对数组的运算操作应该发生在数组中的每一个元素上，即每一个元素都需要有另一个数组上对应位置上的元素与它进行运算，这个概念叫做`广播`。广播是一种允许NumPy对不同形状的数组进行操作的机制，但是，数组的维度必须兼容，即两个数组从最小(最右)的维度开始比较大小，要么相等要么其中一个为1，否则报错。**\n\n例如，下面这个形状为(2, 2)的数组a：\n\n```python\n>>> a = np.array([[1,2], [3,4]])\n>>> a * np.array([[3], [2]])\narray([[3, 6],\n       [6, 8]])\n\n>>> a * np.array([3,6])\narray([[ 3, 12],\n       [ 9, 24]])\n```\n\n(2, 2)和(2, 1)形状的数组相乘，通过广播，相当于进行了下面这样的一个运算：\n\n```\n[1, 2] * [3] = [1, 2] * [3, 3] = [3, 6]\n[3, 4]   [2]   [3, 4]   [2, 2]   [6, 8]\n```\n\n可以理解为(2, 1)的数组被横向拉伸为了(2, 2)的数组。另外，可以自己想象一下下面那个形状为(2,)的一维数组是如何广播到与(2, 2)形状的二维数组相乘的。\n\n而这个例子就会报错：\n\n```python\n>>> a * np.array([[3], [2], [1]])\nValueError: operands could not be broadcast together with shapes (2,2) (3,1)\n```\n\n这是广播的一般规则，广播还有一个简单的规则，也就是上面提到的一个数组与一个数字相乘，这是最简单的一个广播。**一个数字标量可以看成一个形状为(1，)的数组，可以被拉伸到任何形状与其他数组进行运算。**\n\n### 数组方法\n\nNumPy还提供了很多便利的函数对数组进行操作，下面进行一些简单的介绍：\n\n#### 求和\n\n```python\n>>> a = np.array([1,2,3,4])\n>>> a.sum()\n10\n```\n\n不仅可以求全部元素的和，还可以按指定维度进行求和：\n\n```python\n>>> a = np.array([[1,2,3], [4,5,6]])\n>>> a.sum(axis=0)\narray([5, 7, 9])\n\n>>> a.sum(axis=1)\narray([6, 15])\n\n>>> a.sum()\n21\n```\n\n#### 排序\n\n```python\n>>> a = np.array([9,8,7,6,5,4,3,2,1])\n>>> np.sort(a)\narray([1, 2, 3, 4, 5, 6, 7, 8, 9])\n```\n\n#### 求平均值和最值\n\n```python\n>>> a = np.array([[1,2,3], [4,5,6]])\n>>> a.max()\n6\n\n>>> a.min()\n1\n\n>>> a.mean()\n3.5\n```\n\n同求和一样，也可以指定维度进行运算：\n\n```python\n>>> a.max(axis=1)\narray([3, 6])\n\n>>> a.min(axis=1)\narray([1, 4])\n\n>>> a.mean(axis=1)\narray([2., 5.])\n```\n\n### NumPy的数学\n\n前面提到过，NumPy是Python中科学计算的基础，使用非常广泛。这是因为NumPy提供了很多适用于数组的简便方法，使得其实现数学公式的计算非常容易。比如下面这些：\n\n#### 均方误差公式\n\n$$ MSE(y,y^{’}) = {\\sum_{i=1}^{n} (y_i-y’_i)^2 \\over n} $$\n\n求方差在数学计算中非常普遍，在NumPy中，实现这个公式简单明了：\n\n```python\nvar = (1/n) * np.sum(np.square(y2 - y1))\n```\n\n简单演示一下：\n\n```python\n>>> y1 = np.arange(6)\n>>> y1\narray([0, 1, 2, 3, 4, 5])\n\n>>> y2 = y1 + np.array([-0.1, 0.2, -0.8, 1, -0.1, 0])\n>>> y2\narray([-0.1,  1.2,  1.2,  4. ,  3.9,  5. ])\n\n>>> (1/6) * np.sum(np.square(y2 - y1))\n0.2833333333333333\n```\n\n其中，`y1`相当于函数`y=x`，`y2`相当于一些有误差的样本数据，最后的值就是两者之间的方差。\n\n## Pandas\n\nPandas是Python的核心数据分析支持库，提供了快速、灵活、明确的数据结构，旨在简单、直观地处理**关系型、标记型**数据。\n\nPandas是基于NumPy开发的，可以与其它第三方科学计算支持库完美集成。Pandas适合处理以下类型的数据：\n\n+ 与SQL或者Excel表类似的，含异构（不同数据类型）列的表格数据。\n+ 有序或无序（非固定频率）的时间序列数据。\n+ 带行列标签的矩阵数据，包括同构或异构型数据。\n+ 任意其它形式的观测、统计数据集。\n\n### 安装和导入Pandas\n\n安装：\n\n```bash\n$ pip install pandas\n```\n\n导入：\n\n```python\nimport numpy as np # 一般连同numpy一起导入\nimport pandas as pd\n```\n\n### 数据结构\n\n与NumPy的n维数组结构不同，Pandas的主要数据结构就是`Series`（一维数据）和`DataFrame`（二维数据），因为这两种数据结构已经足以处理金融、统计、社会科学、工程等领域内的大部分典型数据了。\n\n#### Series\n\nSeries是带标签的一维数组，可以存储整数、浮点数、字符串、Python对象等类型的数据。Series的标签被称为索引（`index`），一个标签对应一个数据。\n\n调用`pd.Series`函数即可创建Series：\n\n```python\n>>> s = pd.Series(data, index=index)\n```\n\n`data`参数支持以下几种方式传入数据：\n\n+ Python字典：\n\n```python\n>>> d = {'b': 1, 'a': 0, 'c': 2}\n>>> s = pd.Series(d)\n>>> s\nb    1\na    0\nc    2\ndtype: int64\n```\n\n如果以字典的方式传入数据，并且`index`参数缺省，则默认会以字典中相应的key作为数据的标签，可以通过`s.index`查看Series对象的标签：\n\n```python\n>>> s.index\nIndex(['b', 'a', 'c'], dtype='object')\n```\n\n如果设置了`index`参数，则会把`index`参数当作key，去提取字典中的值：\n\n```python\n>>> d = {'b': 1, 'a': 0, 'c': 2}\n>>> s = pd.Series(d, index=['b', 'c', 'd', 'a'])\n>>> s\nb    1.0\nc    2.0\nd    NaN\na    0.0\ndtype: float64\n```\n\n由于字典中没有`d`这个key，所以Series中`d`标签对应的数据为`NaN`。**注意，Pandas中用NaN（Not a Number）表示数据缺失。**\n\n+ numpy对象：\n\n当`data`参数是一个numpy对象时，标签长度必须与numpy对象的长度一致：\n\n```python\n>>> s = pd.Series(np.random.randn(5), index=['a', 'b', 'c', 'd', 'e'])\n>>> s\na    0.085665\nb    0.339841\nc   -1.257418\nd    0.706560\ne    1.096948\ndtype: float64\n```\n\n如果没有指定`index`参数，则默认会创建一个整数索引：\n\n```python\n>>> s = pd.Series(np.random.randn(5))\n>>> s\n0   -0.094684\n1    0.528470\n2    0.202291\n3    0.919904\n4   -0.309003\ndtype: float64\n>>> s.index\nRangeIndex(start=0, stop=5, step=1)\n```\n\n+ 列表：\n\n```python\n>>> s = pd.Series([1, 3, 5, np.nan, 6, 8])\n>>> s\n0    1.0\n1    3.0\n2    5.0\n3    NaN\n4    6.0\n5    8.0\ndtype: float64\n```\n\n+ 标量值：\n\n如果是标量值的话，必须提供索引，Pandas会自动根据索引长度重复该标量值：\n\n```python\n>>> s = pd.Series(5, index=['a', 'b', 'c', 'd', 'e'])\n>>> s\na    5\nb    5\nc    5\nd    5\ne    5\ndtype: int64\n```\n\nSeries的操作与NumPy的ndarrary对象类似，支持大多数NumPy函数，还可以进行各种花式索引和切片：\n\n```python\n>>> s = pd.Series(np.random.randn(5))\n>>> s\n0   -0.713951\n1    1.830373\n2   -0.481400\n3   -2.423198\n4    0.556725\ndtype: float64\n# 索引\n>>> s[0]\n-0.7139514490641597\n# 切片\n>>> s[:3]\n0   -0.713951\n1    1.830373\n2   -0.481400\ndtype: float64\n# 布尔索引，返回大于中位数的数据\n>>> s[s > s.median()]\n1    1.830373\n4    0.556725\ndtype: float64\n# 列表索引\n>>> s[[4, 3, 1]]\n4    0.556725\n3   -2.423198\n1    1.830373\ndtype: float64\n```\n\n#### DataFrame\n\nDataFrame是由`多种类型的列`构成的二维标签数据结构，类似于Excel、SQL表。**DataFrame是最常用的Pandas对象。**\n\nDataFrame的行标签被称为`index`，列标签被称为`columns`。\n\n调用`pd.DataFrame()`函数即可创建DataFrame对象：\n\n```python\n>>> d = pd.DataFrame(data, index=index, columns=columns)\n```\n\n+ 使用numpy二维数组创建DataFrame对象：\n\n```python\n>>> dates = pd.date_range('20230101', periods=6)\n>>> dates\nDatetimeIndex(['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04',\n               '2023-01-05', '2023-01-06'],\n              dtype='datetime64[ns]', freq='D')\n\n>>> df = pd.DataFrame(np.random.randn(6, 4), index=dates, columns=list('ABCD'))\n>>> df\n                   A         B         C         D\n2023-01-01 -0.724145  0.934182 -0.606031 -0.381919\n2023-01-02 -0.763000  0.906290  0.571081 -1.462929\n2023-01-03  0.709972  1.604800 -0.156911  0.680411\n2023-01-04 -0.214652 -0.415641  0.173664  0.181625\n2023-01-05 -0.191492  1.166249  0.748061 -0.868161\n2023-01-06 -0.528732 -0.870868  1.056890 -1.509378\n```\n\n先使用`pd.date_range()`函数生成一个时间序列作为DataFrame的行标签，再调用`pd.DataFrame()`创建DataFrame对象，并传入随机的二维数组数据和列标签参数。可以查看DataFrame对象的index和columns属性：\n\n```python\n>>> df.index\nDatetimeIndex(['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04',\n               '2023-01-05', '2023-01-06'],\n              dtype='datetime64[ns]', freq='D')\n>>> df.columns\nIndex(['A', 'B', 'C', 'D'], dtype='object')\n```\n\n+ 使用字典创建DataFrame对象：\n\n```python\n>>> data = {'AAA':[1,2,3], 'BBB':['a','b','c']}\n>>> df = pd.DataFrame.from_dict(data)\n>>> df\n   AAA BBB\n0    1   a\n1    2   b\n2    3   c\n```\n\nPandas默认是将字典的键设为列标签，可以通过设置`orient`参数将字典的键设为行标签：\n\n```python\n>>> df = pd.DataFrame.from_dict(data, orient='index')\n>>> df\n     0  1  2\nAAA  1  2  3\nBBB  a  b  c\n```\n\n### DataFrame常用操作\n\n#### 提取、添加、删除列\n\n**DataFram可以看成是由一个个Series对象组成的，一列就是一个Series对象**。提取、添加、删除DataFrame的列与操作字典类似：\n\n```python\n>>> df\n                   A         B         C         D\n2023-01-01  0.427900 -1.317100 -0.348818 -2.344505\n2023-01-02  0.404621 -1.270579  2.182677 -0.334435\n2023-01-03  0.943640 -1.205705  0.038978  1.774918\n2023-01-04 -0.062885  0.207681 -0.756341 -0.267351\n2023-01-05  1.522414 -1.371567  1.605561  0.264726\n2023-01-06 -0.345359 -0.771864  0.391735 -1.446381\n\n# 提取列\n>>> df['A']\n2023-01-01    0.427900\n2023-01-02    0.404621\n2023-01-03    0.943640\n2023-01-04   -0.062885\n2023-01-05    1.522414\n2023-01-06   -0.345359\nFreq: D, Name: A, dtype: float64\n# 列的对象类型就是Series类型\n>>> type(df['A'])\n<class 'pandas.core.series.Series'>\n# 除了字典方式，还可以通过DataFrame的属性直接提取列，前提是要列标签为字符串类型\n>>> df.A\n2023-01-01    0.427900\n2023-01-02    0.404621\n2023-01-03    0.943640\n2023-01-04   -0.062885\n2023-01-05    1.522414\n2023-01-06   -0.345359\nFreq: D, Name: A, dtype: float64\n\n# 添加列，用A列的值加上B列的值生成E列\n>>> df['E'] = df['A'] + df['B']\n>>> df\n                   A         B         C         D         E\n2023-01-01  0.427900 -1.317100 -0.348818 -2.344505 -0.889200\n2023-01-02  0.404621 -1.270579  2.182677 -0.334435 -0.865958\n2023-01-03  0.943640 -1.205705  0.038978  1.774918 -0.262065\n2023-01-04 -0.062885  0.207681 -0.756341 -0.267351  0.144796\n2023-01-05  1.522414 -1.371567  1.605561  0.264726  0.150847\n2023-01-06 -0.345359 -0.771864  0.391735 -1.446381 -1.117223\n\n# 删除列\n>>> del df['E']\n>>> p = df.pop('D')\n>>> df\n                   A         B         C\n2023-01-01  0.427900 -1.317100 -0.348818\n2023-01-02  0.404621 -1.270579  2.182677\n2023-01-03  0.943640 -1.205705  0.038978\n2023-01-04 -0.062885  0.207681 -0.756341\n2023-01-05  1.522414 -1.371567  1.605561\n2023-01-06 -0.345359 -0.771864  0.391735\n# 可以同时指定多个列标签来删除列，drop()函数返回的是删除后的结果，对原对象无副作用\n>>> df.drop(columns=['B', 'C'])\n                   A\n2023-01-01  0.427900\n2023-01-02  0.404621\n2023-01-03  0.943640\n2023-01-04 -0.062885\n2023-01-05  1.522414\n2023-01-06 -0.345359\n```\n\n#### 索引\n\n可以通过行或者列两个维度去对DataFrame中的数据进行索引，有多种方式可以进行。\n\n+ 用列标签选择列\n\n通过`df['col']`或者`df.col`进行，这在上面演示过，返回的是一个Series对象。\n\n+ 用行标签对行进行选择和切片\n\n通过`df.loc['label']`进行：\n\n```python\n>>> df\n                   A         B         C         D\n2023-01-01 -1.465884 -2.307865  1.422948 -0.568402\n2023-01-02  0.623038  0.212868 -1.230473  1.132214\n2023-01-03  1.147305 -0.790069  0.470447  2.206363\n2023-01-04  0.186357 -0.255402 -1.256893  0.200379\n2023-01-05  0.462334  0.326236  0.592972 -0.261374\n2023-01-06  0.518177 -0.080145 -1.326405  1.150453\n>>> df.loc['2023-01-01']\nA   -1.465884\nB   -2.307865\nC    1.422948\nD   -0.568402\nName: 2023-01-01 00:00:00, dtype: float64\n>>> df.loc['2023-01-01':'2023-01-03']\n                   A         B         C         D\n2023-01-01 -1.465884 -2.307865  1.422948 -0.568402\n2023-01-02  0.623038  0.212868 -1.230473  1.132214\n2023-01-03  1.147305 -0.790069  0.470447  2.206363\n```\n\n+ 用整数位置对行进行选择和切片\n\n通过`df.iloc[loc]`进行：\n\n```python\n>>> df.iloc[0]\nA   -1.465884\nB   -2.307865\nC    1.422948\nD   -0.568402\nName: 2023-01-01 00:00:00, dtype: float64\n>>> df.iloc[0:3]\n                   A         B         C         D\n2023-01-01 -1.465884 -2.307865  1.422948 -0.568402\n2023-01-02  0.623038  0.212868 -1.230473  1.132214\n2023-01-03  1.147305 -0.790069  0.470447  2.206363\n# 或者\n>>> df[0:3]\n                   A         B         C         D\n2023-01-01 -1.465884 -2.307865  1.422948 -0.568402\n2023-01-02  0.623038  0.212868 -1.230473  1.132214\n2023-01-03  1.147305 -0.790069  0.470447  2.206363\n```\n\n仅选择一行返回的是一个Series对象，通过切片选择多行就返回一个DataFrame对象。\n\n#### 运算\n\nDataFrame对象可以进行多种运算，包括转置和各种聚合。\n\n+ 转置\n\nDataFrame对象的`T`属性可以转置DataFrame：\n\n```python\n>>> df\n                   A         B         C         D\n2023-01-01 -1.465884 -2.307865  1.422948 -0.568402\n2023-01-02  0.623038  0.212868 -1.230473  1.132214\n2023-01-03  1.147305 -0.790069  0.470447  2.206363\n2023-01-04  0.186357 -0.255402 -1.256893  0.200379\n2023-01-05  0.462334  0.326236  0.592972 -0.261374\n2023-01-06  0.518177 -0.080145 -1.326405  1.150453\n>>> df.T\n   2023-01-01  2023-01-02  2023-01-03  2023-01-04  2023-01-05  2023-01-06\nA   -1.465884    0.623038    1.147305    0.186357    0.462334    0.518177\nB   -2.307865    0.212868   -0.790069   -0.255402    0.326236   -0.080145\nC    1.422948   -1.230473    0.470447   -1.256893    0.592972   -1.326405\nD   -0.568402    1.132214    2.206363    0.200379   -0.261374    1.150453\n```\n\n+ 合并\n\nPandas对DataFrame可以进行`SQL风格`的合并，即join：\n\n```python\n>>> ldf = pd.DataFrame({'key': ['foo', 'yoo'], 'lval': [1, 2]})\n>>> ldf\n   key  lval\n0  foo     1\n1  yoo     2\n>>> rdf = pd.DataFrame({'key': ['foo', 'zoo'], 'rval': [4, 5]})\n>>> rdf\n   key  rval\n0  foo     4\n1  zoo     5\n\n# 等值连接\n>>> pd.merge(ldf, rdf, on='key')\n   key  lval  rval\n0  foo     1     4\n\n# 左连接\n>>> pd.merge(ldf, rdf, on='key', how='left')\n   key  lval  rval\n0  foo     1   4.0\n1  yoo     2   NaN\n\n# 右连接\n>>> pd.merge(ldf, rdf, on='key', how='right')\n   key  lval  rval\n0  foo   1.0     4\n1  zoo   NaN     5\n```\n\n+ 分组\n\n通过`df.groupby()`函数进行分组：\n\n```python\n>>> df = pd.DataFrame({'A':['x','y','z','y','z','x'], 'B':np.random.randn(6), 'C':np.random.randn(6)})\n>>> df\n   A         B         C\n0  x -0.956121 -1.465992\n1  y  0.387068  0.140719\n2  z -0.711084 -1.684878\n3  y -0.000911  1.797802\n4  z -0.043587  0.594897\n5  x -0.118352  0.136071\n\n# 先分组，再通过sum()函数计算每组的总和\n>>> df.groupby('A').sum()\n          B         C\nA\nx -1.074473 -1.329921\ny  0.386157  1.938521\nz -0.754671 -1.089981\n```\n\n### 操作CSV\n\nPandas对CSV格式的数据提供了很便利的支持，`Series`和`DataFrame`对象都有个`to_csv()`的方法，可以将对象的值写入到一个csv文件中：\n\n```python\n>>> df\n   A         B         C\n0  x  0.101737  0.133423\n1  y  0.149723 -0.082645\n2  z  1.973025  0.651403\n3  y  0.934236  0.107589\n4  z -0.653397 -1.817398\n5  x -0.039525 -0.654297\n>>> df.to_csv('test.csv', index_label='index')\n```\n\n生成的csv文件：\n\n```text\nindex,A,B,C\n0,x,0.10173694674988926,0.1334227832707775\n1,y,0.14972291881982086,-0.08264462105273167\n2,z,1.973025056752442,0.6514030299492489\n3,y,0.9342361944456802,0.10758879368220652\n4,z,-0.6533969543321673,-1.817398232489989\n5,x,-0.03952526261690382,-0.6542973020515079\n```\n\n反过来还可以通过`pd.read_csv()`函数读取一个csv文件生成DataFrame对象：\n\n```python\n>>> pd.read_csv('test.csv', index_col=0)\n       A         B         C\nindex\n0      x  0.101737  0.133423\n1      y  0.149723 -0.082645\n2      z  1.973025  0.651403\n3      y  0.934236  0.107589\n4      z -0.653397 -1.817398\n5      x -0.039525 -0.654297\n```","tags":["Python高级","NumPy","Pandas"],"categories":["Python"]},{"title":"基于Grafana的可视化监控搭建","url":"/posts/16707/","content":"## Prometheus\n\n### 简介\n\nPrometheus，翻译成中文叫普罗米修斯，是一个开源的系统监控和告警工具包，在许多企业和组织中都非常流行。**Prometheus可以对需要监控的目标进行相关指标数据的采集，并以时间序列的方式保存到时序数据库中，还可以给数据打上标签（Label）一起存储。**\n\nPrometheus具有如下特点：\n\n1. 具有由指标名称和多维度键值对标签标识的时间序列数据的数据模型。\n2. 支持PromQL，一种灵活的查询语言。\n3. 不依赖分布式存储；单个服务器节点是自治的。\n4. 时间序列数据的收集通过HTTP上的拉模型进行。\n5. 支持通过中间网关推送时间序列数据。\n6. 支持通过服务发现或静态配置发现目标。\n\n这是Prometheus的架构图：\n\n![Prometheus](https://cdn.jsdelivr.net/gh/shallowhui/cdn/picgo/prometheus_architecture.png)\n\nPrometheus是一个开源的完整监控解决方案，其对传统监控系统的测试和告警模型进行了彻底的改进，形成了基于中央化的规则计算、统一分析和告警的新模型。 相比于传统监控系统Prometheus具有以下优点：\n\n+ 易于部署和管理：Prometheus核心部分只有一个单独的二进制文件，不存在任何的第三方依赖(数据库，缓存等等)。唯一需要的就是本地磁盘，因此不会有潜在级联故障的风险。\n\n+ 工作模式清晰灵活：Prometheus基于Pull模型的架构方式，可以在任何地方（本地机器，开发环境，测试环境）上搭建监控系统。对于一些复杂的情况，还可以使用Prometheus服务发现(Service Discovery)的能力动态管理监控目标。\n\n+ 强大的数据模型：Prometheus可以很好地记录任何纯数字时间序列，所有采集到的监控数据均以指标和标签进行区分并保存在内置的时间序列数据库（TSDB）当中。一组时间序列数据除了基本的指标名称以外，还包含一组用于描述该时间序列数据特征的标签。\n\nPrometheus比较适合：\n\n以机器为中心的监控，也适合监控高度动态的面向服务的架构。在微服务的世界中，它对多维数据收集和查询的支持是一个特别的优势。\n\n不适合：\n\nPrometheus重视可靠性。用户始终可以查看有关系统的可用统计信息，即使在出现故障的情况下也是如此。因此如果用户需要百分之百的准确性，例如云厂商按请求计费，Prometheus不是一个好的选择，因为它收集的数据可能不够详细和完整。\n\n### metric\n\n指标（metric），表示一种数字测量（numeric measurements），一个用户想要观测的数据。对于一个Web服务器来说，接口请求时间是一个指标，对于数据库来说，活动连接数是一个指标。\n\n**这些指标的数据随着时间的推移而变化，具有同一指标名称和标签的数据形成一组时间序列，Prometheus就记录这种变化，监控的目的就是分析这些变化所反映出来的信息。**\n\n### exporter\n\nexporter，可以翻译成导出器或者出口商，是受监控的目标暴露相关指标数据的地方。前面提到过，Prometheus是通过HTTP去拉取数据，也就是说受监控目标要提供一个HTTP接口供Prometheus访问。\n\n**这个HTTP接口不是可以返回任意数据模型给Prometheus的，要符合Prometheus的数据模型规范。**\n\n接口的端点一般是`/metrics`，接口可以由受监控目标系统自己通过引入Prometheus的[客户端库](https://prometheus.io/docs/instrumenting/clientlibs/)实现，也可以通过第三方库将系统现有的一些指标数据转换成Prometheus指标数据，这对于无法直接提供 Prometheus指标数据（例如，HAProxy或Linux系统统计信息）的情况很有用。\n\n这些提供Prometheus指标数据的HTTP接口，以及第三方库就被称为`exporter`。\n\n下面的链接列出了一些官方和第三方提供的exporter：\n\n[exporters](https://prometheus.io/docs/instrumenting/exporters/)\n\n### Docker运行Prometheus\n\nPrometheus支持多种安装方式，二进制的安装方式是直接去[官网](https://prometheus.io/download/)下载二进制包，解压后运行可执行文件就好了。这里介绍一种比较方便的安装方法，在Linux系统上，用Docker运行Prometheus。\n\n创建`docker-compoes.yml`文件：\n\n```yaml\nversion: '3'\n\nservices:\n\n  prometheus:\n    image: prom/prometheus:main\n    volumes:\n      - prometheus_data:/prometheus\n      - /monitor/prometheus:/etc/prometheus\n    ports:\n      - 9090:9090\n\nvolumes:\n  prometheus_data:\n```\n\n在`/monitor/prometheus`目录下创建`prometheus.yml`文件，这是Prometheus的配置文件：\n\n```yaml\nglobal:\n  scrape_interval: 15s\n  evaluation_interval: 15s\nalerting:\n  alertmanagers:\n    - static_configs:\n        - targets:\nrule_files:\nscrape_configs:\n  - job_name: \"prometheus\"\n    static_configs:\n      - targets: [\"localhost:9090\"]\n```\n\n可以看到，Prometheus默认就配置了一个`job`，也就是监控任务，监控目标是Prometheus本身，Prometheus自己暴露了一个HTTP接口在9090端口供自己采集指标数据。\n\n启动容器：\n\n```bash\n$ docker-compose -d up\n```\n\n通过`curl`访问`exporter`，可以看到返回的**当前时间戳**关于Prometheus自身的一些指标数据：\n\n```bash\n[root@master ~]# curl localhost:9090/metrics\n# HELP go_gc_duration_seconds A summary of the pause duration of garbage collection cycles.\n# TYPE go_gc_duration_seconds summary\ngo_gc_duration_seconds{quantile=\"0\"} 6.5769e-05\ngo_gc_duration_seconds{quantile=\"0.25\"} 0.000110023\ngo_gc_duration_seconds{quantile=\"0.5\"} 0.000145212\ngo_gc_duration_seconds{quantile=\"0.75\"} 0.000187285\ngo_gc_duration_seconds{quantile=\"1\"} 0.002173752\ngo_gc_duration_seconds_sum 0.354465776\ngo_gc_duration_seconds_count 2070\n# HELP go_goroutines Number of goroutines that currently exist.\n# TYPE go_goroutines gauge\ngo_goroutines 50\n# HELP go_info Information about the Go environment.\n# TYPE go_info gauge\ngo_info{version=\"go1.19.5\"} 1\n# HELP go_memstats_alloc_bytes Number of bytes allocated and still in use.\n# TYPE go_memstats_alloc_bytes gauge\ngo_memstats_alloc_bytes 4.108912e+07\n# HELP go_memstats_alloc_bytes_total Total number of bytes allocated, even if freed.\n# TYPE go_memstats_alloc_bytes_total counter\ngo_memstats_alloc_bytes_total 2.8383517224e+10\n# HELP go_memstats_buck_hash_sys_bytes Number of bytes used by the profiling bucket hash table.\n# TYPE go_memstats_buck_hash_sys_bytes gauge\ngo_memstats_buck_hash_sys_bytes 2.548734e+06\n\t\n...\n\t\n```\n\n**Prometheus的数据模型就是这样：`<metric name>{<label name>=<label value>, ...} value}`。**\n\n在浏览器中输入`http://ip:9090`可以访问Prometheus的可视化界面：\n\n![target](https://cdn.jsdelivr.net/gh/shallowhui/cdn/picgo/prometheus_target.png)\n\n可以看到Prometheus本身就是受监控目标。\n\n## Grafana\n\n### 简介\n\nGrafana是一个监控仪表系统，它是由`Grafana Labs`公司开源的的一个系统监测（System Monitoring）工具。Grafana可以大大地简化监控的复杂度，用户只需要提供监控得到的数据，Grafana就可以帮助用户生成各种各样的可视化仪表。同时Grafana还具有告警功能，可以在系统出现问题时通知用户。\n\n\n### 数据源\n\nGrafana本身不负责监控、采集数据，它只是提供一个通用的接口，让底层的数据库将数据传送给它（比如Prometheus），然后它再通过一系列仪表盘将数据可视化地展示出来。\n\nGrafana的数据源不仅仅支持Prometheus这样的时序数据库，还支持关系数据库，比如MySQL，以及NoSQL，比如ElasticSearch。\n\n### Dashboard\n\n目前较新版本的Grafana，是通过Dasboard（仪表盘）和Panel（仪表、面板）来组织和展示数据的。\n\n一般来说，一个受监控系统的各项指标由一个Dashboard来进行展示，在Dashboard中，一个Panel展示一项指标。\n\n用户可以手动一个个Panel进行配置，最终形成一个Dashboard。也可以在Grafana的[社区](https://grafana.com/grafana/dashboards/)中寻找合适的Dashboard模板，然后直接引入使用。\n\n**要想熟练配置Panel的话，需要对各种数据源的查询语言有所了解。**\n\n### Docker运行Grafana\n\n`docker-compose.yml`文件中进行配置：\n\n```yaml\nversion: '3'\n\nservices:\n\n  grafana:\n    image: grafana/grafana:main\n    container_name: grafana\n    ports:\n      - 3000:3000\n```\n\n通过命令运行：\n\n```bash\n$ docker-compose -d up grafana\n```\n\n运行成功后可以在浏览器中输入`http://ip:3000`进行访问Grafana，默认的初始账号密码均为`admin`，登录成功之后会让重设密码。\n\n## 主机性能监控搭建\n\n比较常见的监控，就是对服务器节点进行监控，以便可以实时地查看机器上的CPU、内存、硬盘以及网络流量等信息。\n\n### 安装exporter\n\nLinux系统信息很多都是以文件的方式进行查看的，比如查看内存信息：`cat /proc/meminfo`，所以需要一个`exporter`来对这些信息进行采集并转换成Prometheus指标数据，Prometheus官方专门提供了一个exporter来采集并暴露类Uninx系统的硬件和操作系统相关指标：\n\n[node_exporter](https://github.com/prometheus/node_exporter)\n\n在`Release`页面下载相应架构的压缩包，上传到服务器后解压运行：\n\n```bash\n$ tar -zxvf node_exporter-1.5.0.linux-amd64.tar.gz\n$ cd node_exporter-1.5.0.linux-amd64\n$ nohup ./node_exporter &\n```\n\n让exporter以后台进程的方式运行，打印出来的日志可以在同目录下的`nohup.out`文件中进行查看。通过下列命令查看exporter是否正常工作：\n\n```bash\n$ curl localhost:9100/metrics\n```\n\n如果正常，就会像上面的Prometheus自身相关的指标数据一样，返回操作系统和硬件相关的指标数据。\n\n### 修改Prometheus配置\n\n修改Prometheus配置文件，添加job：\n\n```yaml\n\t\n...\n\t\nscrape_configs:\n  - job_name: \"prometheus\"\n\tstatic_configs:\n      - targets: [\"localhost:9090\"]\n\t\n  - job_name: \"监控主机\"\n    static_configs:\n\t  - targets: [\"instance1_ip:9100\", \"instance2_ip:9100\"]\n```\n\n重新启动Prometheus容器：\n\n```bash\n$ docker-compose restart prometheus\n```\n\n### Grafana配置\n\n#### 添加Prometheus数据源\n\n以admin身份登录Grafana，点击设置->数据源->添加数据源：\n\n![datasource](https://cdn.jsdelivr.net/gh/shallowhui/cdn/picgo/grafana_datasource.png)\n\n选择Prometheus数据源：\n\n![prometheus_datasource](https://cdn.jsdelivr.net/gh/shallowhui/cdn/picgo/grafana_prometheus_datasource.png)\n\n添加Prometheus的地址：\n\n![prometheus_datasource_config](https://cdn.jsdelivr.net/gh/shallowhui/cdn/picgo/prometheus_datasource.png)\n\n然后点击保存并测试，如果测试成功了就说明数据源配置完成了：\n\n![grafana_save](https://cdn.jsdelivr.net/gh/shallowhui/cdn/picgo/grafana_save.png)\n\n#### 添加仪表盘\n\n有关于如何展示操作系统和硬件相关的指标数据，Grafana社区中有很多现成的仪表盘模板，可以直接引用。\n\n选择引入仪表盘：\n\n![dashboard_import](https://cdn.jsdelivr.net/gh/shallowhui/cdn/picgo/grafana_dashboard_import.png)\n\n输入一串数字，这是Grafana社区中一个比较流行的模板的编号，然后点击右边的Load：\n\n![import_id](https://cdn.jsdelivr.net/gh/shallowhui/cdn/picgo/grafana_dashboard_import_config.png)\n\n修改一下仪表盘名称，并选择刚刚配置的Prometheus数据源，然后点击import：\n\n![dashboard_import_config](https://cdn.jsdelivr.net/gh/shallowhui/cdn/picgo/grafana_dashboard_config.png)\n\n这样就能看到主机性能的各项指标了：\n\n![dashboard](https://cdn.jsdelivr.net/gh/shallowhui/cdn/picgo/dashboard.png)","tags":["DevOps","Prometheus","Grafana"],"categories":["DevOps"]},{"title":"Maven仓库详细配置","url":"/posts/47345/","content":"## Maven仓库\n\nMaven是一个软件项目的依赖管理和构建工具。\n\nMaven可以根据需要，从一个仓库中下载依赖到本地上。Maven的仓库分为两种类型：\n\n+ 本地仓库：本地仓库是本地机器上的一个目录，默认是`${user.home}/.m2/repository`。Maven下载依赖的时候是先去本地仓库找有没有这个依赖，没有才去互联网上下载。\n\n可以在Maven的全局配置文件`settings.xml`中进行配置：\n\n```xml\n<settings>\n...\n\t<localRepository>{custom_path}</localRepository>\n...\n</settings>\n```\n\n+ 远程仓库：Maven在本地仓库上找不到依赖时，就会去远程仓库上下载依赖并保存到本地仓库中。\n\n互联网上有很多Maven仓库是公开给人下载依赖的，比如阿里云就提供了很多仓库的镜像地址和源地址：\n\n![repo](https://cdn.jsdelivr.net/gh/shallowhui/cdn/picgo/maven_repo.png)\n\n但是这么多远程仓库，Maven怎么知道去哪个仓库下载依赖呢？\n\n在Maven中，有一个“超级POM”([Super POM](https://maven.apache.org/ref/3.8.6/maven-model-builder/super-pom.html))，其它Maven项目默认都是继承这个POM的，其中有这么一个配置：\n\n```xml\n<repositories>\n\t<repository>\n\t\t<id>central</id>\n\t\t<name>Central Repository</name>\n\t\t<url>https://repo.maven.apache.org/maven2</url>\n\t\t<layout>default</layout>\n\t\t<snapshots>\n\t\t\t<enabled>false</enabled>\n\t\t</snapshots>\n\t</repository>\n</repositories>\n```\n\n可以看到，Maven给所有项目配置了一个默认的远程仓库，id为`central`，所以这个官方的仓库也被称为`中央仓库`。\n\nMaven默认从中央仓库下载依赖。\n\n## 给中央仓库设置镜像\n\n由于众所周知的原因，从中央仓库下载依赖可能下载得会很慢甚至失败，所以需要为中央仓库设置一个镜像仓库，相当于代理了中央仓库，以后会直接从镜像仓库下载中央仓库的依赖，而不会去中央仓库下载了。\n\n在Maven的全局配置文件`settings.xml`中配置如下阿里云镜像：\n\n```xml\n<mirrors>\n...\n\t<mirror>\n\t\t<id>aliyunmaven</id>\n\t\t<mirrorOf>central</mirrorOf>\n\t\t<name>阿里云公共仓库</name>\n\t\t<url>https://maven.aliyun.com/repository/public</url>\n\t</mirror>\n...\n</mirrors>\n```\n\n注意`<mirrorOf>`的值必须跟中央仓库的id一样为`central`，这样才能设置为中央仓库的镜像。\n\n`<mirrorOf>`就是给一个远程仓库设置镜像的关键。当然，`<mirrorOf>`的值也可以设置得跟远程仓库的id不一样，比如设置成`*`，代表匹配任意远程仓库的id，这样一来，所有远程仓库的依赖都会从这个镜像下载。具体参考如下：\n\n[mirror settings](https://maven.apache.org/guides/mini/guide-mirror-settings.html)\n\n**给中央仓库或者其它一个远程仓库，即单个仓库，设置多个镜像是没有用的，Maven只会简单地找到第一个匹配这个远程仓库id的镜像。**\n\n## 添加远程仓库\n\n一个依赖，可能在中央仓库中没有，在其它远程仓库中才有。或者自己搭建了一个Maven仓库，专门用来存储自己项目的制品(`Artifact`)供自己下载使用且不公开。\n\n基于种种原因，需要为Maven添加远程仓库，有两种添加方式：\n\n+ 在项目的`pom.xml`文件中添加，只对当前项目生效：\n\n```xml\n<project>\n...\n\t<repositories>\n\t\t<repository>\n\t\t\t<id>jcenter</id>\n\t\t\t<name>jcenter仓库</name>\n\t\t\t<url>http://jcenter.bintray.com/</url>\n\t\t</repository>\n\t\t<repository>\n\t\t\t<id>google</id>\n\t\t\t<name>谷歌仓库</name>\n\t\t\t<url>https://maven.google.com/</url>\n\t\t</repository>\n\t</repositories>\n...\n</project>\n```\n\n+ 在Maven的全局配置文件`settings.xml`中添加，对所有项目生效：\n\n```xml\n<profiles>\n...\n\t<profile>\n\t\t<id>repo</id>\n\t\t<activation>\n\t\t\t<activeByDefault>true</activeByDefault> <!-- 默认激活这个profile -->\n\t\t</activation>\n\t\t<repositories>\n\t\t\t<repository>\n\t\t\t\t<id>jcenter</id>\n\t\t\t\t<name>jcenter仓库</name>\n\t\t\t\t<url>http://jcenter.bintray.com/</url>\n\t\t\t\t<!-- 启用发布版本 -->\n\t\t\t\t<releases>\n\t\t\t\t\t<enabled>true</enabled>\n\t\t\t\t</releases>\n\t\t\t\t<!-- 启用快照版本，允许下载version带-SNAPSHOT后缀的依赖 -->\n\t\t\t\t<snapshots>\n\t\t\t\t\t<enabled>true</enabled>\n\t\t\t\t\t<!-- 更新策略，每次构建项目都会去Nexus下载最新快照版本的依赖 -->\n\t\t\t\t\t<updatePolicy>always</updatePolicy>\n\t\t\t\t</snapshots>\n\t\t\t</repository>\n\t\t\t<repository>\n\t\t\t\t<id>google</id>\n\t\t\t\t<name>谷歌仓库</name>\n\t\t\t\t<url>https://maven.google.com/</url>\n\t\t\t</repository>\n\t\t</repositories>\n\t</profile>\n...\n</profiles>\n```\n\n**当Maven在一个远程仓库或者这个远程仓库的镜像中(如果这个仓库有匹配的镜像的话)找不到某个依赖时，就会去另一个远程仓库中找。如果配置的所有远程仓库都找不到，Maven就会报错。**\n\n## 上传制品到Maven仓库\n\n如果想把我们构建完项目后得到的制品(通常是一个jar包)，共享给其他人，让别人可以在项目中依赖并下载使用，就需要把我们的制品上传到Maven仓库中，有如下两种方式可以配置上传到哪个Maven仓库中：\n\n+ 在项目的`pom.xml`文件中配置，只对当前项目生效：\n\n```xml\n<project>\n...\n\t<distributionManagement>\n\t\t<repository>\n\t\t\t<id>maven-releases</id>\n\t\t\t<name>正式版本发布仓库</name>\n\t\t\t<url>http://repo_url/repository/releases/</url>\n\t\t</repository>\n\t\t<snapshotRepository>\n\t\t\t<id>maven-snapshots</id>\n\t\t\t<name>快照版本发布仓库</name>\n\t\t\t<url>http://repo_url/repository/snapshots/</url>\n\t\t</snapshotRepository>\n\t</distributionManagement>\n...\n</project>\n```\n\n+ 在Maven的全局配置文件`settings.xml`中配置，对所有项目生效且覆盖项目自身的配置：\n\n```xml\n<profiles>\n...\n\t<profile>\n\t\t<id>upload</id>\n\t\t<activation>\n\t\t\t<activeByDefault>true</activeByDefault>\n\t\t</activation>\n\t\t<properties>\n\t\t\t<!-- 正式版本发布仓库 -->\n\t\t\t<altReleaseDeploymentRepository>maven-releases::default::http://repo_url/repository/maven-releases/</altReleaseDeploymentRepository>\n\t\t\t<!-- 快照版本发布仓库 -->\n\t\t\t<altSnapshotDeploymentRepository>maven-snapshots::default::http://repo_url/repository/maven-snapshots</altSnapshotDeploymentRepository>\n\t\t</properties>\n\t</profile>\n...\n</profiles>\n```\n\n>`<altReleaseDeploymentRepository>`这里的写法是：`id::layout::url`。\n\n注意，如果要把制品上传到快照版本发布仓库，那项目的GAV坐标中的`version`必须带有`-SHAPSHOT`后缀，正式版本发布仓库倒是没有什么限制。\n\n另外，如果Maven仓库的管理员对仓库设置了权限保护，那么上传制品的时候就需要验证，可以在Maven的全局配置文件`settings.xml`中添加如下配置：\n\n```xml\n<servers>\n...\n\t<server>\n\t\t<id>maven-releases</id>\n\t\t<username>...</username>\n\t\t<password>...</password>\n\t</server>\n\t<server>\n\t\t<id>maven-snapshots</id>\n\t\t<username>...</username>\n\t\t<password>...</password>\n\t</server>\n...\n</servers>\n```\n\n**注意，`<server>`的`id`必须和上面两种配置方法中的仓库id一致，例如，`id::layout::url`中的id必须和`<server>`的id一致。**\n\n## 通用做法\n\n在企业或者大型组织中，关于如何管理Maven仓库，一种比较简单通用的做法是：\n\n1. 以上关于仓库的配置均在`settings.xml`文件中配置，而不是`pom.xml`文件。\n\n2. 集中管理`settings.xml`文件，并通过自动化分发它们。\n\n具体参考：[Guide to Large Scale Centralized Deployments](https://maven.apache.org/guides/mini/guide-large-scale-centralized-deployments.html)","tags":["Maven"],"categories":["Java"]},{"title":"DevOps简介","url":"/posts/46701/","content":"## DevOps\n\nDevOps是目前较为流行的一种软件开发理念、开发流程。有人说DevOps是软件工程领域的第三次革命。\n\n下面是维基百科对DevOps的定义：\n\n>DevOps（开发`Development`与运维`Operations`的组合词）是一种文化、一场运动或实践，强调在自动化软件交付流程及基础设施变更过程中，软件开发人员与其他信息技术（IT）专业人员彼此之间的协作与沟通。它旨在建立一种文化与环境，使构建、测试、软件发布得以快速、频繁以及更加稳定地进行。\n\n但DevOps从来就没有什么官方定义，DevOps之父Patrick用一个词来形容DevOps——“盲人摸象”，说明了项目团队需要结合自身实际情况，去探索和实践DevOps。\n\n下面介绍一下软件工程三个重要发展阶段：\n\n### 瀑布开发模式\n\n![瀑布模型](https://cdn.jsdelivr.net/gh/shallowhui/cdn/picgo/waterfallmodel.png)\n\n瀑布式开发模式将软件交付过程划分成几个阶段，**从需求到设计，再到开发、测试、运维，**它的理念是软件开发的规模越来越大，必须以一种工程管理的方式来定义每个阶段，以及相应的交付产物和交付标准，以期通过一种重流程，重管控的方式，按照计划一步步推进整个项目的交付过程，**中间一旦出错，就要返工重做。**\n\n### 敏捷开发模式\n\n![敏捷模型](https://cdn.jsdelivr.net/gh/shallowhui/cdn/picgo/agilemodel.png)\n\n敏捷开发的核心理念是，既然我们无法充分了解用户的真实需求是怎样的，那么不如将一个大的目标不断拆解，把它变成一个个可交付的小目标，然后通过不断迭代，以小步快跑的方式持续开发。\n\n与此同时，将测试工作从开发之后的一个独立环节注入到整个开发活动中，对开发每次交付的内容进行测试验证。**这样的持续迭代和验证节省了大量不必要的时间浪费和返工工作。**\n\n### DevOps\n\n![DevOps](https://cdn.jsdelivr.net/gh/shallowhui/cdn/picgo/devopsmodel.png)\n\n敏捷开发的应用使得开发和测试团队抱团取暖。可是问题又来了，开发和测试团队发现，现在软件交付效率的瓶颈出现在了运维上。毕竟，无论开发了多少新功能，如果没有经过运维环节的发布、部署上线给最终用户使用，那么软件交付便是失败的。\n\n于是，DevOps最开始想要打破的就是开发和运维之间的对立和隔阂，让团队中的每个人都紧密结合起来。\n\n在DevOps的流程下，运维人员会在项目开发期间就介入到开发过程中，了解开发人员使用的系统架构和技术路线，从而制定适当的运维方案。而开发人员也会在运维的初期参与到系统部署中，并提供系统部署的优化建议。\n\n![DevOps](https://cdn.jsdelivr.net/gh/shallowhui/cdn/picgo/devops.png)\n\n### 总结\n\n所以综上，我个人对DevOps的理解是：\n\nDevOps要解决的问题或者说目标是：**如何提高软件交付的效率和质量**。\n\nDevOps提供一个平台，一个团队成员可以在上面进行**紧密协作**的平台，只需要成员们遵守共同的**标准流程和规则**。\n\nDevOps的行动准则可以说是：为了改进软件的开发流程，需要**让流程中一切可以自动化的地方进行自动化**。\n\n## DevOps和CI/CD\n\nDevOps是一组技术和方法，包括：持续交付、自动化运维、高频部署、容器技术等多个方面的内容。\n\nDevOps是一种文化，推倒Dev与Ops之间的阻碍墙，加强团队协作。\n\nDevOps是一种组织架构，将Dev和Ops置于一个团队内，一同工作，同化目标，以达到DevOps文化的彻底贯彻。\n\n### 团队协作的关键\n\n现代软件开发讲究效率和质量，大多依赖于多团队间的协作来实现。对于一些大型软件来说，即便是百人团队规模的协作也没什么奇怪的。如果软件架构没有良好的拆分，很有可能出现几百人在同一个代码仓库里面工作的情况。这时，代码分支管理就成了不可或缺的功能，这也是DevOps的基础。\n\n我个人比较熟悉Git，Git常见的几种分支管理（工作流`WorkFlow`）方式如下：\n\n1. Git Flow\n2. GitHub Flow\n3. GitLab Flow\n\n可以自己去网上了解一下，这里就不作详细介绍了。\n\n### Continuous Integration\n\n简称CI，持续集成。\n\n在20世纪90年代，软件开发还是瀑布模式的天下，人们发现，在很长一段时间里，软件是根本无法完整运行的。因为按照项目计划，软件的功能被拆分成各个模块，由不同的团队分别开发，只有到了开发完成之后的集成阶段，软件才会被真正地组装到一起。可是，往往几个月开发下来，到了集成的时候，大量分支合并带来的冲突和功能问题集中爆发，团队疲于奔命，各种救火，甚至有时候发现压根集成不起来，就让开发人员很头痛。\n\nCI采用了一种反常规的思路来解决软件集成的困境，其核心理念就是：**越是痛苦的事情，就要越频繁地做**。\n\n如果开发周期末端的一次性集成有这么大的风险和不确定性，那不如**把集成的频率提高，让每次集成的内容减少**，这样即便失败，影响的也仅仅是一次小的集成内容，问题定位和修复都可以更加快速地完成。**每次开发人员提交了新代码之后，都自动地完成编译构建、自动化测试（单元测试或者集成测试）、代码质量扫描等等流程，并反馈结果给开发人员。这样一来，可以防止分支大幅偏离主干，导致日后难以集成，还可以让最新的代码保持可用的状态，以供测试、发布使用。**\n\n这个从编码到构建再到测试，开发人员修复问题后再构建......，这样反复持续的过程，就叫作“持续集成”。\n\n### Continuous Delivery\n\n简称CD，持续交付。\n\n代码进行了持续集成后，说明这个代码是可以交付的，但这不代表这个代码是完美无缺、最优的，代码还需要根据用户的使用来逐步进行优化。这里的用户并不一定是指真实的最终用户，还可以是测试团队、QA（质量保证）团队、安全团队、产品等等，需要他们来对软件进行测试检查或者使用，然后反馈发现的问题。**这样不断获取外部反馈结果，再通过持续集成来对软件进行优化的过程，就叫作持续交付。**\n\n**持续交付是一种软件工程手法，让软件的产出过程在一个短周期内完成，以保证软件可以稳定、持续的保持在随时可以发布的状态。**\n\n### Continuous Deployment\n\n简称CD，持续部署。\n\n通常来说，最终软件的发布和部署是最艰难的一个步骤。而持续部署就是将可交付的软件产品，**自动、安全、快速地交付给最终真实用户使用的一套方法和系统**，它是持续交付的最后“一公里”。\n\n### 总结\n\n总的来说，我们没必要纠结于具体的语义，只需理解CI/CD其实就是一个流程（通常形象地表述为管道`Pipeline`），**用于实现软件开发流程的高度持续和自动化**。\n\n可以通过下面这幅图，大概理解DevOps和CI/CD的关系：\n\n![DevOps & CI/CD](https://cdn.jsdelivr.net/gh/shallowhui/cdn/picgo/devopsandcicd.jpg)\n\n## Jenkins + Pipeline\n\nJenkins是一个基于Java开发的CI/CD软件工具，在CI/CD领域上非常流行，可以用于实现和编译构建、测试、部署软件相关的各种自动化任务。\n\nPipeline是Jenkins在2.0版本后推出的一个功能，是一套运行于Jenkins之上的工作流框架。可以将独立运行于单个节点或者多个节点的任务连接起来，共同完成一系列复杂的软件交付流程。\n\nPipeline不同于以往的Jenkins，需要在Web页面上配置构建任务和步骤，它的实现方式是基于Groovy语言定义的一个领域特定语言（DSL），有一套自己的语法进行CI/CD流程脚本的编写。并且Jenkins支持从代码库中直接读取Pipeline的脚本，这样可以将脚本也纳入版本控制，从而实现`pipeline as code`的理念。\n\nPipeline脚本支持两种编写方式，一种是声明式，一种是脚本式。官方推荐使用声明式，可以在其中嵌入Groovy的代码。\n\n声明式的Pipeline脚本如下：\n\n```groovy\n// pipeline声明式定义\npipeline {\n\n    agent any // 指定pipeline在哪个node上运行，any为任意，也可以在stage块中配置指定阶段在哪个node上运行\n\n    // 通过键值对的方式定义整个pipeline或者stage中使用的环境变量\n    environment {\n        key = \"value\"\n    }\n\n    // 定义全局工具，要先在Jenkins的Web页面上配置好\n    tools {\n\t\t\n    }\n\n    // 实现参数化构建，根据用户指定的参数，执行不同的构建操作\n    parameters {\n\t\t\n    }\n\n    // 设置一些配置\n    options {\n        disableConcurrentBuilds() // 禁止pipeline并发执行\n        timeout(time:6, unit:'HOURS') // 设置pipeline执行时间，超时则终止整个pipeline的执行\n    }\n\n    stages {\n        // 阶段定义\n        stage(\"delivery\") {\n\t\t\t// 步骤定义\n            steps {\n\t\t\t\t// 执行脚本或者命令\n\t\t\t\techo key\n\t\t\t\t// 在script块中编写Groovy脚本，进行编程\n\t\t\t\tscript {\n\t\t\t\t\tdef var = x\n\t\t\t\t}\n            }\n        }\n    }\n\n    // 配置pipeline执行完后的收尾工作，可以根据本次构建状态进行不同操作\n    post {\n        // 总是执行\n        always {\n            echo \"pipeline done\"\n        }\n        // 构建成功\n        success {\n            echo \"pipeline success\"\n        }\n        // 构建失败\n        failure {\n            echo \"pipeline failure\"\n        }\n        // 构建中断\n        aborted {\n            echo \"pipeline aborted\"\n        }\n    }\n}\n```\n\n## 后记\n\n以上都是我个人对DevOps的浅薄理解，欢迎在评论区中进行交流~","tags":["DevOps","CI/CD","Jenkins"],"categories":["DevOps"]},{"title":"基于redis实现分布式锁","url":"/posts/13760/","content":"## 前言\n\n在多线程或者多进程的情况下，对于共享资源的访问进行控制是非常有必要的，加锁（互斥量）是一种对并发程序进行同步控制的有效方式。\n\n## 单机锁和分布式锁\n\n在日常业务开发中，经常会出现多个请求同时对同一共享资源进行访问的场景，比如下面的购买商品的场景：\n\n```java\n@RestController\npublic class GoodsController {\n\n    @Autowired\n    StringRedisTemplate redisTemplate; // 使用 spring-boot-starter-data-redis\n\n    private static final String GOODS = \"GOODS\"; // 商品\n\n    @GetMapping(\"/buygoods\")\n    public String buyGoods() {\n        try {\n            String s = redisTemplate.opsForValue().get(GOODS);\n            int n = s == null ? 0 : Integer.parseInt(s);\n            if (n > 0) {\n                redisTemplate.opsForValue().set(GOODS, String.valueOf(n-1));\n                return \"成功购买到商品！\";\n            } else {\n                return \"购买商品失败！\";\n            }\n        } finally {\n            // ...\n        }\n    }\n\n}\n```\n\n这里简单起见，没有写什么Dao、Service层之类的，直接在Controller处理业务。业务比较简单，就是从redis中取出商品的剩余数量，如果大于0还有剩，就返回购买成功的结果并将redis中的商品数量减一。考虑到程序的健壮性，通过try-catch块捕获异常，而且后面需要在finally块中释放锁。\n\n商品是共享资源，显然如果不对其加以限制，那么在多个请求的多个线程同时进行访问时，很容易就会出现超买超卖的现象。在传统的单机环境下，即这个服务只部署一个实例，对于多线程的同步控制，我们一般可以通过`synchronized`或者`ReentrantLock`进行加锁。\n\n通过synchronized关键字：\n\n```java\n@RestController\npublic class GoodsController {\n\n    @Autowired\n    StringRedisTemplate redisTemplate;\n\n    private static final String GOODS = \"GOODS\";\n\n    @GetMapping(\"/buygoods\")\n    public String buyGoods() {\n        synchronized(this) {\n            try {\n                String s = redisTemplate.opsForValue().get(GOODS);\n                int n = s == null ? 0 : Integer.parseInt(s);\n                if (n > 0) {\n                    redisTemplate.opsForValue().set(GOODS, String.valueOf(n-1));\n                    return \"成功购买到商品！\";\n                } else {\n                    return \"购买商品失败！\";\n                }\n            } finally {\n                // ...\n            }\n        }\n    }\n\n}\n```\n\n使用ReentrantLock：\n\n```java\n@RestController\npublic class GoodsController {\n\n    @Autowired\n    StringRedisTemplate redisTemplate;\n\n    private static final String GOODS = \"GOODS\";\n\n    private final ReentrantLock lock = new ReentrantLock();\n\n    @GetMapping(\"/buygoods\")\n    public String buyGoods() {\n        lock.lock();\n        try {\n            String s = redisTemplate.opsForValue().get(GOODS);\n            int n = s == null ? 0 : Integer.parseInt(s);\n            if (n > 0) {\n                redisTemplate.opsForValue().set(GOODS, String.valueOf(n-1));\n                return \"成功购买到商品！\";\n            } else {\n                return \"购买商品失败！\";\n            }\n        } finally {\n            lock.unlock(); // 不管业务处理结果如何，最后一定要解锁\n        }\n    }\n\n}\n```\n\n但是，如果是在分布式环境下，上面这两种方法就无效了。在如今微服务架构大行其道的情况下，一个服务可能同时部署多份实例，那么一个JVM实例进程中的锁，显然管不到其它JVM实例、其它进程的运行了。**所以，需要使用更进一步的分布式锁，来保证不同进程对共享资源的互斥访问。**\n\n## 分布式锁的特性\n\n保证一个分布式锁的有效性，至少需要满足以下三个条件：\n\n+ 互斥：在任何时刻，锁只能被一个客户端持有。\n\nredis提供一个`setnx`命令，让用户在redis中不存在这个key时，才可以创建该key。一个用户先创建了key，其它用户就无法再创建同一个key了。这就是redis实现分布式锁的关键，这个key就相当于锁，只能被一个用户持有，可以有效保证锁的互斥使用。\n\n+ 无死锁：需要保证即使当前持有锁的客户端发生崩溃，其它用户还可以继续获得锁，整个系统还能继续运行下去。\n\n正常来说，谁持有锁，那么在完成任务后就要负责解锁。但可能这个客户端在执行任务的时候，机器崩溃了，那之后一直没人去解锁（删除redis中的key）导致其它客户端永远也无法获得锁了，整个系统就陷入了死锁的状态。所以需要给锁设置一个过期时间（redis支持设置key的过期时间），这样即使锁的持有者崩溃了，一定时间后锁过期被redis自动删除，其它客户端就可以继续去获取锁了。但这样会引入一个新的问题，这在下文会详细解释。\n\n+ 高可用。\n\n显然，不仅客户端可能发生崩溃，redis自己也可能发生崩溃，只使用一个redis实例支撑一个分布式系统的风险较大，所以需要使用redis集群来保证锁的高可用性，只要集群中的大多数redis节点存活，客户端就能加锁解锁。\n\n## 原子性加锁、解锁\n\n**redis自身保证命令执行的原子性，所以我们只需在编写操作redis的代码时保证操作的原子性即可：**\n\n```java\n@RestController\npublic class GoodsController {\n\n    @Autowired\n    StringRedisTemplate redisTemplate; // 使用 spring-boot-starter-data-redis\n\n    private static final String GOODS = \"GOODS\";\n\n    private static final String LOCK_KEY = \"LOCK\"; // 分布式锁在redis中的key\n\n    @GetMapping(\"/buygoods\")\n    public String buyGoods() {\n        String value = UUID.randomUUID().toString(); // 生成随机值，作为key的value\n        Boolean isLock = redisTemplate.opsForValue().setIfAbsent(LOCK_KEY, value); // 加锁\n        if (!isLock) {\n            return \"抢锁失败！\";\n        }\n        try {\n            String s = redisTemplate.opsForValue().get(GOODS);\n            int n = s == null ? 0 : Integer.parseInt(s);\n            if (n > 0) {\n                redisTemplate.opsForValue().set(GOODS, String.valueOf(n-1));\n                return \"成功购买到商品！\";\n            } else {\n                return \"购买商品失败！\";\n            }\n        } finally {\n            redisTemplate.delete(LOCK_KEY); // 解锁\n        }\n    }\n\n}\n```\n\n这里抢锁失败就简单地直接返回了，实际业务中可能要不断地去尝试加锁。\n\n## 设置锁过期时间\n\n`redisTemplate`提供这样的设置过期时间的方式：\n\n```java\nBoolean isLock = redisTemplate.opsForValue().setIfAbsent(LOCK_KEY, value); // 加锁\nredisTemplate.expire(LOCK_KEY, 10L, TimeUnit.SECONDS); // 给锁设置过期时间\n```\n\n但这样操作显然不是原子性的，会出现这样一个问题：当一个服务实例成功执行完加锁语句后，突然宕机了，那么锁是加上了，但还没来得及给锁设置过期时间，其它实例也动不了这把锁，这样就又会造成死锁问题了。\n\n所以redis提供了一个命令，可以在set一个key的同时，给key设置过期时间，redis自身保证其原子性。对应于Java代码的实现如下：\n\n```java\nBoolean isLock = redisTemplate.opsForValue().setIfAbsent(LOCK_KEY, value, 10L, TimeUnit.SECONDS); // 加锁并同时设置过期时间\n```\n\n这里给锁设置了10秒的过期时间，但实际上，对于业务的预估处理时间是不可能很精确的。比如业务中有RPC，但由于网络延迟的问题，业务处理时间花了15秒，超过了锁的过期时间，这就会造成上面所说的，设置了锁过期时间后会引入新问题。\n\n## 误删锁\n\n比如有A、B两个实例，A先获取到了锁并设置过期时间为10秒，但A超过10秒还没处理完业务。这时，锁就过期被redis删除了，B马上获取到锁并设置过期时间，开始处理业务。然后又过了几秒，A处理完业务了，要进行解锁，但此时锁是被B持有的并且没有过期，B还正在处理业务，这时A就会把B的锁给删除了，导致其它实例可以获取锁了，可能会产生与B的同步问题，当然，B可能也会与A产生同步问题。\n\n如果一个实例只能删除自己的锁，不能删除其它实例加的锁，那么可能只会在A和B实例之间产生同步问题，但如果可以误删锁，那么可能就会在之后一系列的实例中都出现问题。所以，两者取其轻，需要在`finally`块中，对解锁操作加以限制。\n\nkey的value可以设置为一个随机值，用于区分是不是自身持有的锁：\n\n```java\nString value = UUID.randomUUID().toString() + \"-\" + Thread.currentThread().getName(); // 随机生成一个UUID加上当前线程的名字\nBoolean isLock = redisTemplate.opsForValue().setIfAbsent(LOCK_KEY, value, 10L, TimeUnit.SECONDS); // 加锁并同时设置过期时间\n\n...\n\nfinally {\n    // 只有当前锁的value是自己设置的，才能进行解锁\n    if (value.equals(redisTemplate.opsForValue().get(LOCK_KEY))) {\n        redisTemplate.delete(LOCK_KEY);\n    }\n}\n```\n\n但这样的解锁操作不是原子性的，想象一下，当一个实例刚判断完这个锁是自己加的，然后锁就到期了，另一个实例马上获得锁，那接下来这个实例就会误删了其它实例的锁。所以还是需要原子性的解锁，有如下两种方法可以参考。\n\n### 利用Lua脚本\n\n最常见的方法是让redis执行Lua脚本，将判断和删除操作写在一个Lua脚本中，redis自身保证可以原子性地执行一个Lua脚本。redis官方文档中也对分布式锁的实现有说明：[Correct Implementation with a Single Instance](https://redis.io/docs/reference/patterns/distributed-locks/#correct-implementation-with-a-single-instance)。\n\n```java\nfinally {\n    // Lua脚本，直接返回0说明已经不是自己的锁了，不能删，返回1说明删锁成功\n    String lua = \"if redis.call('get',KEYS[1]) == ARGV[1] then \" +\n                    \"return redis.call('del',KEYS[1]) \" +\n                    \"else \" +\n                    \"return 0 \" +\n                    \"end\";\n    DefaultRedisScript<Long> defaultRedisScript = new DefaultRedisScript<>(lua, Long.class);\n    Long result = redisTemplate.execute(defaultRedisScript, Collections.singletonList(LOCK_KEY), value);\n    if (result == 1L) {\n        System.out.println(\"删锁成功！\");\n    } else {\n        System.out.println(\"删锁失败！\");\n    }\n}\n```\n\n### 利用redis事务\n\nredis支持事务：[Transactions](https://redis.io/docs/manual/transactions)，并且redis支持一个命令：`watch`，可以用于在提交事务的过程中，监听跟事务相关的key是否发生改变，如果发生改变，那么提交完事务后进行执行，事务会执行失败。\n\n所以，可以利用redis事务的隔离性和`watch`命令，实现一种`乐观锁`（[Optimistic locking using check-and-set](https://redis.io/docs/manual/transactions/#optimistic-locking-using-check-and-set)）式的原子性删锁方式。\n\n```java\nfinally {\n    redisTemplate.watch(LOCK_KEY); // 监听锁\n    // 先判断是否是自己加的锁\n    if (value.equals(redisTemplate.opsForValue().get(LOCK_KEY))) {\n        // 然后乐观锁式地进行解锁\n        // 由于redisTemplate不能保证一个事务中的命令都在同一个redis连接中执行，所以匿名实现下面的接口\n        List<Object> execResult = redisTemplate.execute(new SessionCallback<List<Object>>() {\n            @Override\n            public List<Object> execute(RedisOperations operations) throws DataAccessException {\n                operations.multi(); // 开启事务\n                operations.delete(LOCK_KEY);\n                List<Object> exec = operations.exec();// 提交事务进行执行\n                return exec;\n            }\n        });\n        // 如果事务执行成功，会返回事务中每条命令的执行结果并包装成List，如果List长度为0，则说明事务执行失败\n        if (execResult.size() == 0) {\n            System.out.println(value + \": 删锁失败！\");\n        } else {\n            System.out.println(value + \": 删锁成功！\");\n        }\n    }\n}\n```\n\n## 锁续期\n\n给锁设置过期时间始终会导致误删锁的问题，那有什么办法可以解决这个问题呢？\n\n由于问题是业务的处理时间超过了锁过期时间造成的，那么可以设置这样一种机制：当一个线程获取到锁之后，再开启一个线程用于监听这个业务线程，监听线程负责定时去查看业务线程是否处理完业务，如果没有处理完，监听线程就会去延长锁的过期时间。这种机制叫做`看门狗`机制。\n\n虽然方法看起来简单，但具体实现起来要考虑很多因素，自己写的话也难免会存在一些Bug。所以redis官方推荐了一种Java实现的redis客户端：[Redisson](https://redis.io/docs/clients/#java)，它内部实现了一套完善的基于redis的分布式锁，里面就包含有这种机制。\n\n## redis集群\n\n前面说了，为了分布式锁的高可用，redis必须以集群的形式进行部署。但由于redis集群不保证`强一致性`（[Redis Cluster consistency guarantees](https://redis.io/docs/manual/scaling/#redis-cluster-101)），所以分布式锁可能会出现问题。\n\n想象一下这样一个场景：一个实例往redis集群中的一个主节点A加锁，由于redis主从模型默认采用的是异步复制，所以A可能先回复实例加锁成功，但还没来得及把数据复制到它的副本，A就挂掉了，A的副本被其它主节点推选上位，而实例加的锁已经被丢弃不见了。\n\n为了缓解集群模式下分布式锁的问题，redis官方提出了一种算法：[The Redlock Algorithm](https://redis.io/docs/reference/patterns/distributed-locks/#the-redlock-algorithm)。上面提到的`Redisson`就是用这种算法来进行加锁解锁的。\n\n## 总结\n\n通过这次对分布式锁的学习，了解了redis的集群模式，还加深了对并发安全的理解，对并发程序进行同步控制就是为了让其执行结果看起来跟串行执行的结果一样。","tags":["Redis"],"categories":["C/C++"]},{"title":"Elasticsearch入门","url":"/posts/12781/","content":"## Elasticsearch介绍\n\n在其[官网](https://www.elastic.co/guide/en/elasticsearch/reference/current/elasticsearch-intro.html)中，有如下介绍：\n\n>Elasticsearch是位于Elastic Stack核心的分布式搜索和分析引擎。Logstash和Beats有助于收集、聚合和丰富您的数据并将其存储在Elasticsearch中。Kibana使您能够以交互方式探索、可视化和分享对数据的见解，并管理和监控Stack。Elasticsearch是进行索引、搜索和分析的地方。\n>\n>Elasticsearch为所有类型的数据提供近乎实时的搜索和分析。无论您拥有结构化或非结构化文本、数字数据还是地理空间数据，Elasticsearch都能以支持快速搜索的方式高效地存储和索引它。您可以进行数据检索和聚合信息来发现数据中的趋势和模式。随着您的数据和查询量的增长，Elasticsearch的分布式特性使您的部署能够随之无缝增长。\n\n显然，Elasticsearch不仅可以存储数据，还可以对数据进行`近实时`的搜索和分析，正如它的口号：`You konw, for search`。\n\n不同于传统的关系型数据库，通过SQL对结构化数据进行查询（搜索），Elasticsearch通过DSL（特定领域语言），不仅可以对结构化数据进行查询，比如匹配查询、范围查询，还可以对非结构化的文本数据进行全文搜索，这是关系型数据库很难完成的任务。\n\n存储到Elasticsearch中的数据，会近乎实时地（1秒内）被建立索引然后就完全可以对其进行搜索。**这是因为Elasticsearch会为每一个字段建立索引，每个被索引的字段都有一个专用的优化数据结构，例如，文本（text）字段存储在`倒排索引`中，而数字和地理字段存储到`BKD`树中。**\n\n  Elasticsearch会为文档中的每一个`text`类型的字段建立倒排索引，通过倒排索引，可以找到包含某个关键词（Term）的所有文档（Posting List）。\n\nElasticsearch是基于Apache旗下的`Lucene`进行开发的，Lucene才是真正工作的搜索和分析引擎，Elasticsearch在其之上做了个封装，隐藏其复杂性，主要负责管理Elasticsearch集群，并对外提供基于HTTP的RESTful接口。\n\n这篇文章简单介绍一下`8.x`版本的Elasticsearch。\n\n## 下载启动\n\n下面是下载页面的链接，下载按钮后面还跟有Elasticsearch的启动步骤：\n\n[https://www.elastic.co/cn/downloads/elasticsearch](https://www.elastic.co/cn/downloads/elasticsearch)\n\n**注意，较新版本的Elasticsearch都是默认启用security的，要注意命令行启动Elasticsearch时输出的信息：**\n\n```bash\n---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------> Elasticsearch security features have been automatically configured!\n-> Authentication is enabled and cluster connections are encrypted.\n\n->  Password for the elastic user (reset with `bin/elasticsearch-reset-password -u elastic`):\n  CFhKpGiQiKtcYLnzKVAT\n\n->  HTTP CA certificate SHA-256 fingerprint:\n  9e890980d426fb3ed8a55faf1314a30d88713c339c4d3eabb48893dedfc81bae\n\n->  Configure Kibana to use this cluster:\n* Run Kibana and click the configuration link in the terminal when Kibana starts.\n* Copy the following enrollment token and paste it into Kibana in your browser (valid for the next 30 minutes):\n  eyJ2ZXIiOiI4LjMuMyIsImFkciI6WyIxNzIuMTYuMTMuMjk6OTIwMCJdLCJmZ3IiOiI5ZTg5MDk4MGQ0MjZmYjNlZDhhNTVmYWYxMzE0YTMwZDg4NzEzYzMzOWM0ZDNlYWJiNDg4OTNkZWRmYzgxYmFlIiwia2V5IjoiQzhYdDA0SUJoaTR1eHNnU0l0ajY6UHhGLS0tOVNUcS1ybk1kY3F1ZHpldyJ9\n\n->  Configure other nodes to join this cluster:\n* On this node:\n  - Create an enrollment token with `bin/elasticsearch-create-enrollment-token -s node`.\n  - Uncomment the transport.host setting at the end of config/elasticsearch.yml.\n  - Restart Elasticsearch.\n* On other nodes:\n  - Start Elasticsearch with `bin/elasticsearch --enrollment-token <token>`, using the enrollment token that you generated.\n--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n```\n\n由于开启了security，所以通过RESTful接口（默认端口是`9200`）访问Elasticsearch时，协议必须是`HTTPS`，并且访问之前要通过身份验证。默认内建的超级账号名为`elastic`，密码可以在启动时输出的信息中找到。\n\n在集群中，Elasticsearch通过TCP与其它Elasticsearch节点进行通信，默认端口为`9300`。\n\n## 数据存储\n\nElasticsearch可以用来存储数据，但与传统关系型数据库不同的是，它存储数据不是按行列进行存储，而是存储`文档`。\n\n### 文档\n\n其实，这里说的文档就是一个JSON对象，Elasticsearch使用JavaScript Object Notation（JSON）作为文档的序列化格式。JSON序列化为大多数编程语言所支持，并且已经成为`NoSQL`领域的标准格式：\n\n```json\n{\n    \"email\":      \"zunhuier@google.com\",\n    \"first_name\": \"\",\n    \"last_name\":  \"\",\n    \"info\": {\n        \"age\":         26,\n        \"interests\": [ \"\", \"\" ]\n    },\n    \"join_date\": \"\"\n}\n```\n\n一个文档由多个`filed`（字段）组成，正如前面所说，一旦文档被存储到Elasticsearch中，Elasticsearch默认就会为文档的每一个字段建立相应的索引，并且可以自动识别不同的数据类型。\n\n### 索引\n\n以关系型数据库作为对比，那么文档就相当于表中的一条数据记录，而索引就相当于数据库。本来中间是还有一个`type`（类型），相当于数据表的，但Elasticsearch从8开始弃用type这个概念。\n\n这里可能对索引的概念的有点迷糊，需要对其在不同语境下的含义进行明确：\n\n1. 作名词：如前所述，相当于关系型数据库中的数据库概念，指Elasticsearch中，**具有大致相同结构和含义的一组文档的逻辑集合**。\n\n2. 作动词：将文档存储到Elasticsearch中，也可以表述为：将文档索引到Elasticsearch中，因为Elasticsearch马上就会为文档建立索引。\n\n3. 作名词：为文档建立索引，这里的索引就是指那些索引结构了，比如倒排索引。\n\n## RESTful接口\n\n简单介绍一下通过RESTful接口与Elasticsearch进行交互。\n\n### 添加删除索引\n\n添加索引：\n\n`PUT /{index}`\n\n```\nPUT /test\n\n返回结果：\n{\n  \"acknowledged\": true,\n  \"shards_acknowledged\": true,\n  \"index\": \"test\"\n}\n```\n\n删除索引：\n\n`DELETE /{index}`\n\n```\nDELETE /test\n\n返回结果：\n{\n  \"acknowledged\": true\n}\n```\n\n### 添加删除文档\n\n添加文档，通过在请求体中携带JSON数据：\n\n`PUT /{index}/_doc/{id}`\n\n```\nPUT /test/_doc/1\n{\n  \"name\": \"zunhuier\",\n  \"age\": 26\n}\n\n返回结果：\n{\n  \"_index\": \"test\",\n  \"_id\": \"1\",\n  \"_version\": 1,\n  \"result\": \"created\",\n  \"_shards\": {\n    \"total\": 2,\n    \"successful\": 1,\n    \"failed\": 0\n  },\n  \"_seq_no\": 0,\n  \"_primary_term\": 1\n}\n```\n\n路径参数中的`test`是指索引，如果不存在，Elasticsearch会自动创建。`1`用于指定文档的ID，如果不指定，Elasticsearch会为文档自动生成一个ID。\n\n删除文档：\n\n`DELETE /{index}/_doc/{id}`\n\n```\nDELETE /test/_doc/1\n\n返回结果：\n{\n  \"_index\": \"test\",\n  \"_id\": \"1\",\n  \"_version\": 2,\n  \"result\": \"deleted\",\n  \"_shards\": {\n    \"total\": 2,\n    \"successful\": 1,\n    \"failed\": 0\n  },\n  \"_seq_no\": 8,\n  \"_primary_term\": 1\n}\n```\n\n### 查看索引\n\n`GET /{index}`\n\n```\nGET /test\n\n返回结果：\n{\n  \"test\": {\n    \"aliases\": {},\n    \"mappings\": {\n      \"properties\": {\n        \"age\": {\n          \"type\": \"long\"\n        },\n        \"name\": {\n          \"type\": \"text\",\n          \"fields\": {\n            \"keyword\": {\n              \"type\": \"keyword\",\n              \"ignore_above\": 256\n            }\n          }\n        }\n      }\n    },\n    \"settings\": {\n      \"index\": {\n        \"routing\": {\n          \"allocation\": {\n            \"include\": {\n              \"_tier_preference\": \"data_content\"\n            }\n          }\n        },\n        \"number_of_shards\": \"1\",\n        \"provided_name\": \"test\",\n        \"creation_date\": \"1661419717653\",\n        \"number_of_replicas\": \"1\",\n        \"uuid\": \"0m_-NwEpQfqTeaa259yg4g\",\n        \"version\": {\n          \"created\": \"8030399\"\n        }\n      }\n    }\n  }\n}\n```\n\n### 查看文档\n\n`GET /{index}/_doc/{id}`\n\n```\nGET /test/_doc/1\n\n返回结果：\n{\n  \"_index\": \"test\",\n  \"_id\": \"1\",\n  \"_version\": 1,\n  \"_seq_no\": 21,\n  \"_primary_term\": 1,\n  \"found\": true,\n  \"_source\": {\n    \"name\": \"zunhuier\",\n    \"age\": 26\n  }\n}\n```","tags":["Elasticsearch"],"categories":["Java"]},{"title":"自己动手写一个线程池","url":"/posts/39995/","content":"## 线程池的定义\n\n首先来看一下什么是线程池，根据百度百科：\n\n>线程池是一种多线程处理形式，处理过程中将任务添加到队列，然后在创建线程后自动启动这些任务。\n\n简单来说，线程池可以接受我们提交的任务，然后为每一个任务分配一个线程去完成它。通常我们创建一个异步任务，是开启一个线程：\n\n``` java\nnew Thread(Runnable r);\n```\n\n但这样写会让程序中到处都是创建线程的代码，所以我们需要一个线程池这样的工具类，统一去提交、执行任务。\n\n## 定义线程池相关的接口\n\n既然线程池可以执行我们提交的任务，那给线程池定义一个接口：\n\n``` java\npublic interface Executor {\n    public void execute(Runnable r); // Runnable对象是我们提交的任务，会执行其中的run()方法\n}\n```\n\n受资源限制，线程池中的线程数量当然是有限的，那当线程池的承载能力满了之后，我们再提交任务时，线程池应该如何处理？最粗暴的做法就是直接丢弃这个任务，但最好可以让用户自己决定如何处理来拒绝这个任务，这叫执行拒绝策略，我们定义一个接口：\n\n``` java\n// 处理线程池拒绝提交任务的策略\npublic interface RejectedExecutionHandler {\n    /**\n     * 任务提交失败时执行的方法\n     * @param executor Executor的实现类\n     * @param r 任务对象\n     */\n    public void rejectedHandle(Executor executor, Runnable r);\n}\n```\n\n嗯，既然拒绝策略可以自定义，那线程池中，线程的创建也让用户自定义吧，我们定义一个用户自定义创建线程的接口：\n\n``` java\n// 线程工厂类，用户可以自定义线程的创建\npublic interface ThreadFactory {\n    public Thread newThread(Runnable r);\n}\n```\n\n## 实现线程池\n\n### 最简单的线程池\n\n好了，准备工作完成，我们来写一个最简单的线程池，也就是Executor接口的实现类：\n\n``` java\npublic class ThreadPool implements Executor {\n    public void execute(Runnable r) {\n        new Thread(Runnable r).start();\n    }\n}\n```\n\n别看它简单，就是直接创建一个线程去执行传入的Runnable对象，没有什么拒绝策略、线程工厂之类的，但JDK中线程池的作者举的例子就是这个，从这个开始构建线程池，一步步添加功能。\n\n### 引入CorePoolSize\n\n正如前面所说，资源是有限的，不可能传入一个任务就创建一个线程去执行。所以我们考虑对线程池中的线程数量进行限制，引入两个参数：\n\n1. CorePoolSize：核心线程数\n2. BlockingQueue：任务的等待阻塞队列\n\n引入参数后线程池的代码如下：\n\n``` java\npublic class ThreadPool implements Executor {\n\n    private final int corePoolSize; // 核心线程数\n    private final AtomicInteger workCount = new AtomicInteger(0); // 正在工作的线程数，初始化为零\n    private final RejectedExecutionHandler rejectedExecutionHandler; // 拒绝策略\n    private final BlockingQueue<Runnable> blockingQueue; // 任务的等待阻塞队列\n    private final ThreadFactory threadFactory; // 线程工厂\n\n    // 构造方法\n    public ThreadPool(int corePoolSize, RejectedExecutionHandler rejectedExecutionHandler, BlockingQueue<Runnable> blockingQueue, ThreadFactory threadFactory) {\n        this.corePoolSize = corePoolSize;\n        this.rejectedExecutionHandler = rejectedExecutionHandler;\n        this.blockingQueue = blockingQueue;\n        this.threadFactory = threadFactory;\n    }\n\n    /**\n     * 工作线程类，即线程池中具体运行的线程对象是Worker类的实例对象\n     */\n    private final class Worker implements Runnable {\n\n        private Runnable task; // 工作线程的任务\n\n        public final Thread thread; // 以Worker实例对象自身通过ThreadFactory创建一个Thread，再保存到实例中\n\n        /**\n         * Worker类的构造方法\n         * @param firstTask 创建工作线程时，设置要运行的第一个任务\n         */\n        public Worker(Runnable firstTask) {\n            this.task = firstTask;\n            this.thread = threadFactory.newThread(this);\n            workCount.getAndIncrement(); // 工作线程数量加一\n        }\n\n        // 执行任务\n        public void run() {\n            while (true) {\n                if (task != null)\n                    task.run();\n                task = blockingQueue.poll(); // 不断尝试从等待队列中取出新任务\n            }\n        }\n    }\n}\n```\n\n简单实现RejectedExecutionHandler和ThreadFactory接口：\n\n``` java\npublic class RejectedImpl implements RejectedExecutionHandler {\n\n    public void rejectedHandle(Executor executor, Runnable r) {\n        // 直接输出线程池和任务的信息\n        System.out.println(\"Task: \" + r.toString() + \" rejected from: \" + executor.toString());\n    }\n\n}\n```\n\n``` java\npublic class ThreadFactoryImpl implements ThreadFactory {\n\n    public Thread newThread(Runnable r) {\n        // 可以设置线程对象的各个属性，这里就直接返回一个线程了\n        return new Thread(r);\n    }\n\n}\n```\n\n**引入这两个参数之后，可以想象一下，一开始线程池中是空的，没有线程在工作。然后每传入一个任务就通过线程工厂创建一个新线程去执行任务，同时workCount加一。当workCount等于corePoolSize时，再传入一个任务，这时就不会去创建新的线程了，而是把这个任务丢进等待队列中，等待工作中的线程执行完当前任务后从队列中取出新任务去执行。如果队列满了，线程池就执行拒绝策略，拒绝这个任务。**\n\n**workCount记录正在工作的线程数，当创建新线程时+1，当后面会讲到的非核心线程因为没有任务执行就销毁时-1，因为有多个线程对这个成员变量进行操作，所以需要使用JUC提供的原子类。同理，多个线程对等待队列进行操作，所以使用线程安全的BlockingQueue。**\n\n按照上面的思路，线程池类中的execute()方法很容易就可以实现，这里就不展示了，可以尝试自己完善线程池类~\n\n重点在下面的弹性扩展。\n\n### 可弹性扩展的线程池\n\n引入上面的参数后，线程池就会逐步创建出corePoolSize个核心线程，并且等待队列中可能有任务在等待。如果恰好这时核心线程都在工作并且等待队列满了，又来了个新任务，那么线程池只能拒绝这个任务了。\n\n考虑这么一个场景：任务在某一段时间正常提交，不是很频繁，线程池的大小足够支撑这种并发量。但突然有一段时间，任务提交非常频繁，提交了非常多的任务，线程池只能丢弃超出其承载能力的任务，这该如何解决？\n\n可以考虑将corePoolSize设置得很大，提高线程池的容量。但这显然有个问题，当提交任务的高峰期过去，就会有若干个核心线程在那“空转”：不断尝试从等待队列中取出新任务，但队列中又没有那么多任务。\n\n为此，特意再引入几个参数：\n\n1. MaxPoolSize：最大工作线程数，指线程池允许的最大工作线程数\n2. TimeUnit：时间单位\n3. KeepAliveTime：非核心线程的空闲时间，与时间单位一起，就是指非核心线程的最大空闲时间\n\n**maxPoolSize将工作中的线程分为了核心线程和非核心线程：核心线程是常驻内存的，如果当前任务执行完，会不断尝试从等待队列中取出新任务去执行，而非核心线程如果执行完当前任务，没有在空闲时间内从等待队列中取出新任务，就会被销毁。**\n\n**引入maxPoolSize参数后，可以这样理解线程池的最大容量 = maxPoolSize + 等待队列的大小。**\n\n改进后的线程池代码如下：\n\n``` java\npublic class ThreadPool implements Executor {\n\n    private final int corePoolSize; // 核心线程数（常驻内存）\n    private final int maxPoolSize; // 最大工作线程数（核心线程+非核心线程）\n    private final AtomicInteger workCount = new AtomicInteger(0); // 正在工作的线程数\n    private final RejectedExecutionHandler rejectedExecutionHandler; // 拒绝策略\n    private final TimeUnit timeUnit; // 时间单位\n    private final long keepAliveTime; // 非核心线程的空闲时间（非核心线程不常驻内存，空闲时间内未能从等待队列中获得任务则结束运行）\n\n    private final BlockingQueue<Runnable> blockingQueue; // 任务的等待阻塞队列\n    private final ThreadFactory threadFactory; // 线程工厂\n\n    /**\n     * 通过此方法给线程池提交任务\n     * @param r 要执行的任务对象\n     */\n    public void execute(Runnable r) {\n        if (workCount.get() < corePoolSize) {\n            // 创建核心线程\n            Worker coreWorker = new Worker(r, true);\n            coreWorker.thread.start();\n        } else {\n            // 如果任务进入等待队列失败, 判断是否可以创建非核心线程，不能创建则走拒绝策略\n            if (!blockingQueue.offer(r)) {\n                if (workCount.get() < maxPoolSize) {\n                    Worker nonCoreWorker = new Worker(r, false);\n                    nonCoreWorker.thread.start();\n                } else {\n                    rejectedExecutionHandler.rejectedHandle(this, r);\n                }\n            }\n        }\n    }\n\n    // 构造方法\n    public ThreadPool(int corePoolSize, int maxPoolSize, RejectedExecutionHandler rejectedExecutionHandler,\n                      TimeUnit timeUnit, long keepAliveTime, BlockingQueue<Runnable> blockingQueue, ThreadFactory threadFactory) {\n        this.corePoolSize = corePoolSize;\n        this.maxPoolSize = maxPoolSize;\n        this.rejectedExecutionHandler = rejectedExecutionHandler;\n        this.timeUnit = timeUnit;\n        this.keepAliveTime = keepAliveTime;\n\n        this.blockingQueue = blockingQueue;\n        this.threadFactory = threadFactory;\n    }\n\n    /**\n     * 工作线程类，即线程池中具体运行的线程对象是Worker的实例\n     */\n    private final class Worker implements Runnable {\n\n        private Runnable task; // 工作线程的任务\n        private boolean core;\n\n        public final Thread thread; // 以Worker实例对象自身通过ThreadFactory创建一个Thread，再保存到实例中\n\n        /**\n         * Worker的构造方法，可以判断要创建的是不是核心线程\n         * @param firstTask 创建工作线程时，设置要运行的第一个任务\n         * @param core 判断是否为核心线程\n         */\n        public Worker(Runnable firstTask, boolean core) {\n            this.task = firstTask;\n            this.core = core;\n            this.thread = threadFactory.newThread(this);\n\n            workCount.getAndIncrement(); // 工作线程数量加一\n        }\n\n        // 执行任务\n        public void run() {\n            if (core)\n                runCoreWorker();\n            else\n                runNonCoreWorker();\n        }\n\n        // 核心线程常驻内存\n        public void runCoreWorker() {\n            while (true) {\n                if (task != null)\n                    task.run();\n                task = blockingQueue.poll();\n            }\n        }\n\n        // 非核心线程会结束运行\n        public void runNonCoreWorker() {\n            while (task != null) {\n                task.run();\n                try {\n                    // 要在空闲时间内从队列中取出新任务\n                    task = blockingQueue.poll(keepAliveTime, timeUnit);\n                } catch (InterruptedException e) {\n                    task = null;\n                    e.printStackTrace();\n                }\n            }\n            workCount.getAndDecrement(); // 非核心线程结束运行，工作线程数量减一\n        }\n    }\n}\n```\n\n**这时，当队列满了，线程池就不是直接丢弃任务了，而是继续创建非核心线程去执行任务，同时workCount继续增加，超过corePoolSize。当workCount等于maxPoolSize时，再提交任务，线程池才执行拒绝策略。这样，当任务的提交量变小时，随着等待队列中的任务一个个被取出来执行完毕，非核心线程会一一销毁，workCount就逐步减小，但workCount是不会小于corePoolSize的，因为核心线程一旦被创建出来就常驻内存。**\n\n### 使用线程池\n\n首先定义一个任务类，再将任务传入线程池中：\n\n``` java\npublic class Main {\n\n    /**\n     * 编写一个Runnable接口的实现类，run方法内定义了要执行的任务\n     */\n    static class Task implements Runnable {\n\n        public long x;\n\n        public Task(long x) {\n            this.x = x;\n        }\n\n        public String toString() {\n            return \"休眠\" + x + \"秒\";\n        }\n\n        public void run() {\n            try {\n                TimeUnit.SECONDS.sleep(x);\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n            System.out.println(\"========================================================================>休眠\" +\n                    x + \"秒的任务已由\" + Thread.currentThread().getName() + \"线程完成\");\n        }\n    }\n\n    public static void main(String[] args) throws Exception {\n        RejectedExecutionHandler rejectedExecutionHandler = new RejectedImpl();\n        ThreadFactory threadFactory = new ThreadFactoryImpl();\n        BlockingQueue<Runnable> blockingQueue = new ArrayBlockingQueue<>(9); // 这里new的队列大小就是线程池中等待队列的大小\n\n        ThreadPool threadPool = new ThreadPool(3, 6, rejectedExecutionHandler, TimeUnit.MILLISECONDS, 100L, blockingQueue, threadFactory);\n\n        // 提交任务\n        threadPool.execute(new Task(56L));\n        threadPool.execute(new Task(86L));\n        threadPool.execute(new Task(76L));\n    }\n}\n```\n\n## 总结\n\n这篇文章讲解了一下线程池的核心参数和基本工作原理，但还不够完善，像JDK中的`ThreadPoolExecutor`线程池还有对线程池状态进行控制的参数。\n\n对于上面可弹性扩展的线程池的完整代码可以参考如下链接：\n\n[https://github.com/ShallowHui/interesting-small-project/tree/master/ThreadPool](https://github.com/ShallowHui/interesting-small-project/tree/master/ThreadPool)","tags":["线程池"],"categories":["Java"]},{"title":"剑指Offer-day4：矩阵中的路径","url":"/posts/22740/","content":"## 题目\n\n给定一个 m x n 二维字符网格 board 和一个字符串单词 word 。如果 word 存在于网格中，返回 true ；否则，返回 false 。\n\n单词必须按照字母顺序，通过相邻的单元格内的字母构成，其中“相邻”单元格是那些水平相邻或垂直相邻的单元格。同一个单元格内的字母不允许被重复使用。\n\n示例：\n\n输入：board = [[\"A\",\"B\",\"C\",\"E\"],[\"S\",\"F\",\"C\",\"S\"],[\"A\",\"D\",\"E\",\"E\"]], word = \"ABCCED\"\n\n输出：true\n\n如图所示：\n\n![二维网格](https://cdn.jsdelivr.net/gh/shallowhui/cdn/img/reflection/matrix.PNG)\n\n## 解题\n\n根据题目要求，同一个单元格不能被重复使用，可以想到，在开始寻找一个符合word字符串的路径的时候可以用深度优先遍历。当然，只用一次深度优先遍历肯定是找不全二维网格中所有可能路径的，毕竟深度优先遍历是每个网格只遍历一次，有些路径是要走到之前遍历过的网格的。\n\n所以思路是，先用两个for循环遍历每一个网格，一旦网格中的字符是word字符串的首字符，就从这个网格开始进行深度优先遍历，寻找可能存在的路径。\n\n代码实现如下：\n\n```java\nclass Solution {\n    public boolean exist(char[][] board, String word) {\n        int m = board.length, n = board[0].length;\n        int[][] arr = new int[m][n];\n        for (int i = 0 ; i < m ; i++) {\n            for (int j = 0 ; j < n ; j++) {\n                if (DFS(board,word,0,arr,i,j)) {\n                    return true;\n                }\n            }\n        }\n        return false;\n    }\n\n    public boolean DFS(char[][] board, String word, int index, int[][] path, int i, int j) {\n        if (board[i][j] != word.charAt(index)) {\n            return false;\n        }else {\n            path[i][j] = index + 1;\n\t    //下面四个if判断表示往当前网格可达的东南西北四个方向遍历，并且这个递归是一旦寻找到了一个可行性方案，就递归返回结果了\n            if (++index < word.length()) {\n                if (j < board[0].length-1 && path[i][j+1] == 0) {\n                    if (DFS(board,word,index,path,i,j+1))\n                        return true;\n                }\n                if (i < board.length-1 && path[i+1][j] == 0) {\n                    if (DFS(board,word,index,path,i+1,j))\n                        return true;\n                }\n                if (j > 0 && path[i][j-1] == 0) {\n                    if (DFS(board,word,index,path,i,j-1))\n                        return true;\n                }\n                if (i > 0 && path[i-1][j] == 0) {\n                    if (DFS(board,word,index,path,i-1,j))\n                        return true;\n                }\n                path[i][j] = 0;\n                return false;\n            }else {\n                return true;\n            }\n        }\n    }\n}\n```\n\n时间复杂度是O(m×n×3^k)，m是二维网格的行数，n是列数，k是word字符串的长度。","tags":["数据结构与算法"],"categories":["Java"]},{"title":"Java反射和注解","url":"/posts/39821/","content":"## 什么是反射\n\n反射，就是在程序运行的时候，可以获取某个类，某个对象的全部信息。\n\n## 反射的原理\n\n我们知道，Java源代码是先编译为字节码(.class)文件后，再交由JVM去解释执行。\n\n在Java中，除了int、float等基本数据类型之外，一切皆对象，都有自己的class，即类，代表这一类抽象数据类型。那么，在Java中，有这么一个类：`Class`，代表了Java中的其它类，你可以把`Class`理解为“类的类”。\n\nJVM在执行Java程序的时候是动态加载的，并不是一次性把所有用到的class全部加载到内存中，而是第一次需要用到class时才加载。\n\n**当JVM把某个类加载进内存的时候，就会为其创建一个`Class`类的实例对象，并把这个对象与加载进来的类关联起来。所以，JVM中所有的Class实例对象，都指向一个类，这个类可以是自己编写的，也可以是JDK的。**\n\n既然JVM为每个类都创建了一个Class实例对象，那么通过这个对象，就可以访问到对应的类的全部信息了。\n\n这种通过Class实例对象获取class信息的方法就称为反射(Reflection)。\n\n## 反射API\n\n### 获取具体的类对应的Class实例对象\n\n有三种方式获取。\n\n+ 每个类都有一个静态变量class，就是其对应的Class实例对象：\n\n```java\nClass cls = String.class;\n```\n\n+ 可以通过一个类的实例对象，获取这个类的Class实例对象：\n\n```java\nString s = \"Hello，world！\";\nClass cls = s.getClass();\n```\n\n+ 如果知道一个类的完整类名，可以通过Class类的静态方法获取：\n\n```java\nClass cls = Class.forName(\"java.lang.String\");\n```\n\n### 访问成员属性\n\n通过Class实例对象获取某个类的成员属性：\n\n```java\nField f = String.class.getDeclaredField(\"value\");\nf.getName(); //\"value\"\nf.getType(); //class [B    //表示byte[]类型\n```\n\n可以看出需要知道具体的属性名才能访问到相应的属性。`getDeclaredField`方法返回了一个属性的封装对象，通过`Field`对象就可以获取这个属性的名字和类型了。\n\n注意，`getDeclaredField`方法只能获取这个类自己声明的属性，还有其它方法可以获取从父类继承下来的属性，可以自行去查阅资料。\n\n#### 获取属性值\n\n上面，我们只是获取了某个类的成员属性，那我们想获取这个类的一个具体实例对象的属性值呢？\n\n可以通过上面提到的`Field`对象：\n\n```java\nf.get(object); //传进去一个具体的对象就行了\n```\n\n既然可以通过`Filed`获取值，那当然也可以设置值：\n\n```java\nf.set(object, value);\n```\n\n注意，如果`Field`对象所代表的属性是`private`权限的话，直接获取、设置值会报错，需要先调用：\n\n```java\nf.setAccessible(true); //允许访问\n```\n\n### 访问成员方法\n\n```java\nMethod method = cls.getDeclaredMethod(name, Class...);\n```\n\n同样返回方法的封装对象，`getDeclaredMethod`方法的参数是不定长的，第一个是指定要访问的方法名，之后是这个方法的各个参数的类型，需要传入Class实例对象。比如某个参数是String类型的，就需要传入String.class。\n\n#### 调用方法\n\n获取方法的封装后，我们可以在具体的实例对象上调用这个方法：\n\n```java\nString s = \"Hello，world！\";\n// 获取String类的substring(int)方法，参数为int类型\nMethod m = String.class.getMethod(\"substring\", int.class);\n// 在s对象上调用该方法并获取结果，需要强制转型\nString r = (String) m.invoke(s, 6);\n```\n\n对了，虽然Java中的基本数据类型没有class，但也可以通过int.class这样的方式指明。\n\n如果方法是静态方法，那么`invoke`方法的第一个参数传入null就可以了。\n\n### 获取构造函数\n\n常规的实例化一个对象是通过new，那非常规的就是通过反射机制。\n\n```java\nConstructor constructor = cls.getDeclaredConstructor(Class...);\n```\n\n`getDeclaredConstructor`方法获取某个类自己声明的构造方法，参数传入构造方法的参数类型，需要传入Class实例对象。\n\n获取了构造方法的封装对象后，就可以实例化这个类的一个具体对象了：\n\n```java\nObject object = (Object) constructor.newInstance(parameters...); //需要强制转型\n```\n\n`newInstance`方法的参数传入实际构造方法的参数就行了。\n\n## 什么是注解\n\n注解，可以看成是一种特殊的注释，都是用来对源代码来进行说明解释的。只不过注释会被编译器忽略，而注解，则可以被一起编译到.class文件中。\n\n注解作为一种标记，可以放在类、属性、方法、方法参数前面，注解本身对代码的逻辑没有影响，标记了之后起什么作用，完全由谁使用这个注解决定。\n\n注解有如下几类：\n\n+ **由编译器使用的注解。**\n\n例如经常见到的@Override注解，是加在方法上面的，这是告诉编译器在编译的时候检查这个方法是否正确地实现了覆写。\n\n这类注解就不会被一起编译到.class文件中，在编译完成后就丢掉了。\n\n+ **由一些特殊工具处理.class文件时使用的注解。**\n\n有些工具会在加载.class文件的时候，对.class文件做动态修改，实现一些特殊的功能。\n\n这类注解会被编译进入.class文件，但加载结束后并不会存在于内存中。这类注解只被一些底层库使用，一般开发不必理会。\n\n+ **在程序运行期间可以读取的注解。**\n\n这类注解会被编译进.class文件中，JVM加载.class后会存在于内存中，这时我们就可以读取这个注解了，怎么读取？\n\n当然是上面讲的反射机制，读取之后就可以用代码来处理这个注解，实现它标记之后应有的功能。\n\n**所以，看到这里应该可以理解了，Java的注解并不是什么黑魔法，看起来注解一标上去，就可以实现功能了。注解能实现的功能，背后都是有代码支撑的。**\n\n## 定义注解\n\nJava使用@interface语法来定义注解（Annotation），就像定义一个接口：\n\n```java\nimport java.lang.annotation.ElementType;\nimport java.lang.annotation.Retention;\nimport java.lang.annotation.RetentionPolicy;\nimport java.lang.annotation.Target;\n\n@Target({ElementType.METHOD,ElementType.TYPE})\n@Retention(RetentionPolicy.RUNTIME)\npublic @interface PersonalA {\n    String name() default \"\";\n}\n```\n\n注解里面可以定义参数，参数类型可以是基本数据类型、String、Class、枚举类型的数组。格式如上面的代码所示，default后面跟默认值。\n\n**如果有一个参数在使用注解时是经常要配置的，可以将参数名设为value，这样在配置参数时，就可以直接写值，不用写成“参数名=值”这种形式了。**\n\n### 元注解\n\n上面的代码可以看到，定义的`PersonalA`注解上面，还标有其它注解。像这些可以修饰其它注解的注解，称为元注解。一般来说，元注解都是JDK自带的，我们不用编写元注解，只需使用就好了，元注解的使用对我们编写的自定义注解非常重要。\n\n下面是一些常用的元注解：\n\n+ **@Target：最常用的元注解。**\n\n使用这个元注解去修饰其它注解，用来定义被修饰的注解可以被用在源代码的哪些位置。\n\n下面是这个元注解的源代码：\n\n```java\n@Documented\n@Retention(RetentionPolicy.RUNTIME)\n@Target(ElementType.ANNOTATION_TYPE)\npublic @interface Target {\n    /**\n     * Returns an array of the kinds of elements an annotation type\n     * can be applied to.\n     * @return an array of the kinds of elements an annotation type\n     * can be applied to\n     */\n    ElementType[] value();\n}\n```\n\n可以看到参数是个ElementType枚举类型的数组，ElementType枚举源代码如下：\n\n```java\npublic enum ElementType {\n    /** Class, interface (including annotation type), or enum declaration */\n    TYPE,\n\n    /** Field declaration (includes enum constants) */\n    FIELD,\n\n    /** Method declaration */\n    METHOD,\n\n    /** Formal parameter declaration */\n    PARAMETER,\n\n    /** Constructor declaration */\n    CONSTRUCTOR,\n\n    /** Local variable declaration */\n    LOCAL_VARIABLE,\n\n    /** Annotation type declaration */\n    ANNOTATION_TYPE,\n\n    /** Package declaration */\n    PACKAGE,\n\n    /**\n     * Type parameter declaration\n     *\n     * @since 1.8\n     */\n    TYPE_PARAMETER,\n\n    /**\n     * Use of a type\n     *\n     * @since 1.8\n     */\n    TYPE_USE\n}\n```\n\n从注释可以看出，ElementType.METHOD说明可以被用在方法上，ElementType.TYPE说明可以被用在类或接口上。所以上面定义的`PersonalA`注解既可以被用在类或接口上，也可以被用到方法上。\n\n+ **@Retention：定义其它注解的生命周期。**\n\n这个元注解的参数也是枚举类型，有如下几种取值：\n\n1. RetentionPolicy.SOURCE：仅编译器起作用\n2. RetentionPolicy.CLASS：仅存在于.class文件中\n3. RetentionPolicy.RUNTIME：运行期间起作用\n\n如果一个自定义注解没有加@Retention，则默认是CLASS的，即这个自定义注解只会被编译进.class文件中，而不会被加载进内存中。\n\n**因此，如果我们想要自定义的注解在程序运行期间可以被读取到并起作用，务必要用@Retention(RetentionPolicy.RUNTIME)去修饰它。**\n\n## 使用注解\n\n上面我们定义了`PersonalA`注解，现在来使用它：\n\n```java\n@PersonalA(name = \"zunhuier\")\npublic class User {\n\n    public String name;\n\n    public User(String name) {\n        this.name = name;\n    }\n}\n```\n\n## 处理注解\n\n我们想要`PersonalA`注解实现这样一个功能：检查每个User对象的属性值name，是否与加在User类上面的注解参数指定的值一样。那我们编写如下处理注解的代码：\n\n```java\npublic class Main {\n    \n    public static void main(String[] args) {\n        User user1 = new User(\"zunhuier\");\n        checkUser(user1);\n        User user2 = new User(\"zzz\");\n        checkUser(user2);\n    }\n\n    //根据注解检查的方法\n    private static void checkUser(User user) {\n        //获取User类的Class对象\n        Class cls = user.getClass();\n        //通过反射读取注解\n        PersonalA personalA = (PersonalA) cls.getAnnotation(PersonalA.class);\n        if (personalA != null) {\n            String nameA = personalA.name();\n            try {\n                //通过反射获取实例对象的属性值\n                Field name = cls.getDeclaredField(\"name\");\n                String realName = (String) name.get(user);\n                if (!nameA.equals(realName)) {\n                    System.out.println(\"成员属性值\" + name.getName() + \"不是\" +  nameA);\n                }else {\n                    System.out.println(\"成员属性值\" + name.getName() + \"是\" + realName);\n                }\n            } catch (Exception e) {\n                e.printStackTrace();\n            }\n        }\n    }\n\n}\n```\n\n结果：\n\n```text\n成员属性值name是zunhuier\n成员属性值name不是zunhuier\n```\n\n## 总结\n\n反射机制是Java的基本特性，而注解技术是基于反射的。Spring框架就大量采用了注解技术。","tags":["反射","注解"],"categories":["Java"]},{"title":"剑指Offer-day3：从尾到头打印链表","url":"/posts/63873/","content":"## 题目\n\n输入一个链表的头节点，从尾到头反过来返回每个节点的值（用数组返回）。\n\n示例：\n\n有这样一个链表：（1，3，2），则head指向1，输入head，返回[2,3,1]。\n\n## 解题\n\n注意这是一个单向链表，不是双向，更不是循环链表哦~\n\n```java\n/*\n\t链表的节点类\n*/\nclass ListNode {\n    int val;\n    ListNode next;\n    ListNode(int x) { \n        val = x; \n    }\n}\n```\n\n这是让我们求现有链表的逆序嘛，可以想到用栈，从头节点开始将链表的每个节点放入栈，再依次取出栈中元素，由于栈先进后出的特性，出来的元素就是逆序的了。\n\n用栈是以空间换时间的方法，时间和空间复杂度均为O(n)。\n\n我们可不可以不用额外的空间呢？可以，反正都是要进行遍历链表的操作，那么干脆就在在遍历链表的时候，修改每个节点的next指针，让其指向前一个节点，这样就完成了链表的反转，再顺序输出这个链表就是原来链表的逆序了。\n\n但反转链表需要的操作有点麻烦，而且一般来说也不建议修改输入的数据。我后来突然醒悟了，不必去反转链表，题目让我们返回的是一个跟链表顺序相反的数组，那么我们直接就可以顺序遍历链表，将节点的值倒序填入数组就行了......\n\n原来这么简单......\n\n代码实现如下：\n\n```java\nclass Solution {\n    public int[] reversePrint(ListNode head) {\n        ListNode node = head;\n        int count = 0;\n\t//要先获取链表长度\n        while(node != null){\n            count++;\n            node = node.next;\n        }\n        int[] arr = new int[count];\n        node = head;\n        for(int i = count-1 ; i >= 0 ; i--){\n            arr[i] = node.val;\n            node = node.next;\n        }\n        return arr;\n    }\n}\n```\n\n这个方法遍历了两次链表，时间复杂度为O(n)，空间复杂度为O(1)。","tags":["数据结构与算法"],"categories":["Java"]},{"title":"剑指Offer-day2：二维数组中的查找","url":"/posts/12002/","content":"## 题目\n\n在一个`n * m`的二维数组中，每一行都按照从左到右递增的顺序排序，每一列都按照从上到下递增的顺序排序。请完成一个高效的函数，输入这样的一个二维数组和一个整数，判断数组中是否含有该整数。\n\n示例：\n\n有如下二维数组：\n\n\t[\n  \t\t[1,   4,  7, 11, 15],\n  \t\t[2,   5,  8, 12, 19],\n  \t\t[3,   6,  9, 16, 22],\n  \t\t[10, 13, 14, 17, 24],\n  \t\t[18, 21, 23, 26, 30]\n\t]\n\n给定 target = 5，返回`true`。\n\n给定 target = 20，返回`false`。\n\n## 解题\n\n容易想到，暴力解法就是遍历这个二维数组，这样时间复杂度为O(mn)。\n\n所以我们要注意到这个二维数组从左到右，从上到下均递增的性质。如果是在一维的递增序列中，我们可以用二分查找这个算法，那么二维呢？\n\n其实，如果从右上角看示例中的这个二维数组，不难看出这有点像一颗二叉搜索树。15的左边11比15小，15的下边19比15大，11、19的左，下边也是。当然，并不是说这个二维数组是一棵真的二叉搜索树，但我们可以利用这个性质。\n\n应该说，一个元素作为根结点，与它的同一行和同一列元素构成一颗二叉搜索树。所以，当要找的target不是根结点时，根据target与根结点的大小关系，我们可以放弃左子树或者右子树不用去查找，也就是抛弃了一行或者一列的元素不用去检索了。\n\n具体代码实现如下：\n\n```java\nclass Solution {\n    public boolean findNumberIn2DArray(int[][] matrix, int target) {\n        int raw, col;\n        if(matrix.length == 0){\n            return false;\n        }else{\n            raw = 0;\n            col = matrix[0].length-1;\n        }\n        while(col >= 0 && raw < matrix.length){\n            if(target == matrix[raw][col]){\n                return true;\n            } else if(target < matrix[raw][col]){\n                col--;\n            } else{\n                raw++;\n            }\n        }\n        return false;\n    }\n}\n```\n\n**一共有n行，m列，所以算法时间复杂度为O(m+n)。**\n\n+ while循环前面的if-else判断是为了通过Leetcode测试时一个输入为空数组的测试用例，~~有点坑哈~~。","tags":["数据结构与算法"],"categories":["Java"]},{"title":"剑指Offer-day1：数组中的重复元素","url":"/posts/17920/","content":"## 前言\n\n这个系列的文章就用来记录我在Leetcode上刷的剑指Offer算法题目。\n\n## 题目\n\n找出数组中重复的数字。\n\n在一个长度为`n`的数组`nums`里的所有数字都在`0～n-1`的范围内。数组中某些数字是重复的，但不知道有几个数字重复了，也不知道每个数字重复了几次。请找出数组中任意一个重复的数字。\n\n示例：\n\n\t输入：\n\t[2, 3, 1, 0, 2, 5, 3]\n\t输出：2 或者 3\n\n## 解题\n\n找重复元素很容易想到暴力解法，即遍历每个元素看它是否与其它元素重复。容易知道暴力解法的时间复杂度为O(n^2)。\n\n进一步优化思路，要注意到题目中的说明，长度为n的数组中每个元素值为0~n-1，也就是说，x为数组中的元素，而访问nums[x]不会越界。\n\n所以，我们可以使用哈希的思想进行解题，具体做法也不用使用哈希表这个数据结构，而是用一个布尔数组来实现哈希的效果。\n\n**初始化一个长度相等的布尔数组flag，默认值全为false。然后用i循环遍历nums，flag[nums[i]]就可以看成是nums[i]的哈希值，如果当遍历nums[i]时，发现flag[nums[i]]的值已经为true了，说明之前已经有重复的元素进行\"哈希\"了。**\n\n代码如下：\n\n```java\nclass Solution {\n    public int findRepeatNumber(int[] nums) {\n        int n = nums.length;\n        boolean[] flag = new boolean[n];\n        for(int i = 0 ; i < n ; i++){\n            if(flag[nums[i]]){\n                return nums[i];\n            }\n            flag[nums[i]] = true;\n        }\n        return -1; //返回-1是找不到重复元素\n    }\n}\n```\n\n这个方法的时间和空间复杂度均为O(n)，还可以进一步改进。\n\n**前面说了，nums[x]不会越界，那我们遍历nums，将nums中的元素放回与它的值相对应的数组下标位置，即nums[i]=i，如果在放回nums[i]的时候，发现nums[i]的值与要放回位置上的元素值相同，就说明元素重复了。这可以看成是一种原地排序。**\n\n代码如下：\n\n```java\nclass Solution {\n    public int findRepeatNumber(int[] nums) {\n        for(int i = 0 ; i < nums.length ; i++){\n            while(nums[i] != i){\n                if(nums[i] == nums[nums[i]]){\n                    return nums[i];\n                }\n\t\t//放回的时候要交换\n                int temp = nums[i];\n                nums[i] = nums[temp];\n                nums[temp] = temp;\n            }\n        }\n        return -1;\n    }\n}\n```\n\n时间复杂度仍为O(n)，空间复杂度优化成了O(1)。","tags":["数据结构与算法"],"categories":["Java"]},{"title":"Mybatis入门","url":"/posts/63107/","content":"## Mybatis简介\n\n百度百科：\n\n> MyBatis是一款优秀的持久层框架，它支持定制化SQL、存储过程以及高级映射。MyBatis避免了几乎所有的JDBC代码和手动设置参数以及获取结果集。MyBatis可以使用简单的XML或注解来配置和映射原生信息，将接口和Java的POJOs(Plain Ordinary Java Object，普通的Java对象)映射成数据库中的记录。\n\n**Mybatis框架也是一个ORM框架，使用ORM框架后，应用程序不再直接访问底层数据库，而是以面向对象的方式来操作持久化对象(Persisent Object，PO)，而ORM框架则会通过映射关系将这些面向对象的操作转换成底层的SOL操作。**\n\n当前的ORM框架有很多，常见的有Hibernate、Mybatis。我们选择的是Mybatis，因为Mybatis在国内开发中更加常见，并且Mybatis更加适合复杂和需要SQL性能优化的项目。\n\n### Mybatis官方\n\n[Mybatis's Github](https://github.com/mybatis)\n\n可以在github上面查看Mybatis官方的各种项目和文档，并下载release版本的mybatis3使用。当然，如果是用`Maven`构建项目的话，通过坐标就可以引入Mybatis框架了。\n\n## Mybatis的工作原理\n\n**Mybatis是一种框架，本质上还是对JDBC的一层封装。**\n\n### Mybatis的核心组件\n\n+ SqlSessionFactory：SQL连接的会话工厂，用来和数据库之间创建SQL会话的。\n\n```java\nInputStream inputStream = Resources.getResourceAsStream(\"配置文件\"); //读取Mybatis配置文件\nSqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); //单例模式创建会话工厂\n```\n\n+ SqlSession：一个SQL会话对象，就是用来执行SQL语句的。\n\n```java\nSqlSession sqlSession = sqlSessionFactory.openSession();\nsqlSession.insert(\"SQL语句\");\nsqlSession.close();\n```\n\n### 工作流程\n\n1. Mybatis首先读取配置文件，配置文件中配置了数据源（可以是DBCP、Hikari等等）以及其它的Mybatis相关配置信息。\n2. 读取映射文件，映射文件是Mybatis中十分重要的文件，其中定义了映射关系和要执行的SQL语句。\n3. 创建SqlSessionFactory，即会话工厂。\n4. 获得SqlSession对象，就可以执行SQL语句了。\n5. 在Mybatis底层，SqlSession是通过一个**Executor**接口来操作数据库的。\n6. Mybatis在底层设置了**MappedStatement**对象，其就是对映射信息的封装。\n\n## Mybatis与Spring的整合\n\nMybatis与Spring的整合需要一个中间jar包：\n\n[mybatis-spring.jar](https://mvnrepository.com/artifact/org.mybatis/mybatis-spring)\n\n然后在Spring的IoC容器中添加Mybatis的SqlSessionFactory组件：\n\n```xml\n    <!-- 读取数据库配置 -->\n    <context:property-placeholder location=\"classpath:db.properties\"></context:property-placeholder>\n    <!-- 配置dbcp2数据池 -->\n    <bean id=\"dataSource\" class=\"org.apache.commons.dbcp2.BasicDataSource\">\n        <property name=\"driverClassName\" value=\"${jdbc.driver}\"/>\n        <property name=\"url\" value=\"${jdbc.url}\"/>\n        <property name=\"username\" value=\"${jdbc.username}\"/>\n        <property name=\"password\" value=\"${jdbc.password}\"/>\n        <property name=\"maxTotal\" value=\"${jdbc.maxTotal}\"/>\n        <property name=\"maxIdle\" value=\"${jdbc.maxIdle}\"/>\n        <property name=\"initialSize\" value=\"${jdbc.initialSize}\"/>\n    </bean>\n    <!-- 开启事务管理 -->\n    <bean id=\"transactionManager\" class=\"org.springframework.jdbc.datasource.DataSourceTransactionManager\">\n        <property name=\"dataSource\" ref=\"dataSource\"/>\n    </bean>\n    <tx:annotation-driven transaction-manager=\"transactionManager\"/>\n    <!-- 配置Mybatis -->\n    <bean id=\"sqlSessionFactory\" class=\"org.mybatis.spring.SqlSessionFactoryBean\">\n        <property name=\"dataSource\" ref=\"dataSource\"/>\n        <property name=\"configLocation\" value=\"classpath:mybatis-config.xml\"/>\n    </bean>\n    <!-- 配置Mybatis的映射扫描器 -->\n    <bean class=\"org.mybatis.spring.mapper.MapperScannerConfigurer\">\n        <property name=\"basePackage\" value=\"\"/>\n    </bean>\n```\n\n+ 其中数据源就不用在Mybatis的配置文件中配了，直接在Spring的配置文件中配置。\n\n## Mybatis的日志功能\n\nMybatis拥有日志功能，可以对SQL语句的执行过程和结果进行日志记录和打印，具体的使用可以参考下面的链接：\n\n[Mybatis日志](https://www.w3cschool.cn/mybatis/ogqn1im5.html)\n\n## Mybatis的开发方式\n\n在与Spring整合后，我们使用Mybatis不用通过SqlSession之类的了，而是通过映射接口，接口中可以定义各种各样的SQL相关的方法，查询结果就封装到方法的返回值中。\n\n基于映射接口，我们有两种开发方式如下。\n\n### 纯注解的开发方式\n\n如果用纯注解的方式，那就可以不用编写映射文件了，直接就在映射接口的各个方法上添加注解，来定义映射关系和要执行的SQL语句:\n\n```java\nimport org.apache.ibatis.annotations.Insert;\nimport org.apache.ibatis.annotations.Mapper;\nimport org.apache.ibatis.annotations.Options;\nimport org.apache.ibatis.annotations.Select;\n\n@Mapper //可以用MapperScannerConfigurer来扫描，不加Mapper注解\npublic interface CityMapper {\n\n  @Insert(\"INSERT INTO city (name, state, country) VALUES(#{name}, #{state}, #{country})\")\n  @Options(useGeneratedKeys = true, keyProperty = \"id\")\n  void insert(City city);\n\n  @Select(\"SELECT id, name, state, country FROM city WHERE id = #{id}\") //要执行的SQL语句\n  City findById(long id);\n\n}\n```\n\nMybatis提供了各种各样的注解来完成映射关系的定义。\n\n### 编写映射文件进行开发\n\n使用纯注解的方式固然方便，但如果编写一些复杂的SQL语句会很麻烦。所以，我们还是需要编写映射文件来进行开发。\n\n**这里顺便说一句，这两种开发方式是可以同时混合使用的，不是只能用一种方式。**\n\n#### 映射文件模板\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\">\n<mapper namespace=\"映射接口的全类名\">\n\n    <select id=\"映射接口中的方法名\" resultType=\"返回的查询结果映射为Java实体类型的全类名\">\n        SQL语句\n    </select>\n\n</mapper>\n```\n\n+ 注意`<mapper>`标签的`namespace`属性一定要写正确完整的全类名，这样才能让映射接口和映射文件绑定。\n\n**通常来说，一个映射文件就对应并操作数据库中的一张关系表，这个映射文件就完成一个实体类型到一个关系表的映射。**\n\n#### 映射文件常用的标签及其属性\n\n+ `<select>`标签：定义一个用来查询的SQL语句\n\n`<select>`标签中常用的属性有：\n\n|属性|作用|\n|-------|-------|\n|id|表示命名空间中的唯一标识符，常与命名空间组合起来使用。组合后如果不唯一，MyBatis会抛出异常。|\n|parameterType|该属性表示传入SQL语句的参数类的全类名或者别名。这是一个可选属性，因为MyBatis可以通过`TypeHandler`推断出具体传入语句的参数。|\n|resultType|SQL语句执行完后返回的全部数据对应映射的类的全类名或者别名。如果返回多条记录，那么应该是对应映射的类本身，不用考虑集合类型。|\n|resultMap|表示外部`resultMap`的命名引用。指定SQL语句返回的类型可以使用resultType或resultMap。|\n\n+ `<insert>`、`<update>`、`<delete>`标签：见名知义~\n\n+ `<sql>`标签：定义可重用的SQL语句片段：\n\n```xml\n<sql id= \"customerColumns\">id,username,jobs,phone</sql>\n...\n<select id=\"findCustomerByld\" parameterType=\"int\" resultType=\"club.zunhuier.po.Customer\">\n\tselect <include refid=\"customerColumns\"/>\n\tfrom customer\n\twhere id = #(id)\n</select>\n\n<!-- SQL语句中用#(参数名)来取出映射接口方法中的参数 -->\n```\n\n+ `<resultMap>`标签：最重要的的一个标签，可以定义映射关系，被别的标签使用：\n\n```xml\n<resultMap type=\"指定要映射的实体类型\" id=\"唯一标识\">\n\t<id property=\"实体类型中的属性\" column=\"数据库中关系表的列名\"/>\t<!-- 指定主键 -->\n\t<result property=\"name\" column=\"t_name\"/>\t<!-- 其它字段的映射关系 -->\n\t<result property=\"age\" cOlumn=\"t_age\"/>\n\t<association property=\"类型为其它实体类的属性\" />\t<!-- 用于一对一关联 -->\n\t<collection property=\"\" />\t<!-- 用于一对多关联 -->\n</resultMap>\n```\n\n#### 动态SQL语句\n\n动态SQL是Mybatis的强大特性之一，它允许在映射文件中像写有逻辑的程序一样，对传过来的参数进行判断，符合条件的SQL语句就拼接起来，动态地生成最终要执行的SQL语句。\n\n常用的标签及其作用如下：\n\n|标签|作用|\n|-------|-------|\n|`<if>`|判断语句，用于单条件分支判断。|\n|`<choose>`、`<when>`、`<otherwise>`|相当于java程序中的switch...case...default语句，用于多条件分支判断。|\n|`<foreach>`|循环语句，常用于in语句等列举条件中。|\n|`<where>`、`<trim>`、`<set>`|辅助元素，用于处理一些SQL语句拼装、特殊字符问题。|\n\n例子：\n\n```xml\n<select id=\"findCustomerByNameOrJobs\" parameterType=\"club.zunhuier.po.Customer\" resultType=\"club.zunhuier.po.Customer\">\n\t<!-- 一定执行的SQL语句 -->\n\tselect * from t customer where 1=1\n\t<choose>\n\t\t<when test=\"username !=null and username !=\" \">\n\t\t\t<!-- 拼接上模糊查询的SQL语句 -->\n\t\t\tand username like concat('%' , #{username} , '%')\n\t\t</when>\n\t\t<when test=\"jobs !=null and jobs !=''\">\n\t\t\tand jobs= #{jobs}\n\t\t</when>\n\t\t<otherwise>\n\t\t\tand phone is not null\n\t\t</otherwise>\n\t</choose>\n</select>\n```\n\n### Mybatis关联映射\n\n通常来说，一个映射文件对应一张表。但实际上，SQL查询经常是多表查询，即查询出来的结果是多张表联合查询出来的结果。\n\n数据库中的表存在一对一、一对多、多对多的关系，这是我们学过的关系数据库基本理论。\n\n这些关系反映在Java代码的实体类型中如下：\n\n```java\n//一对一\nclass A {\n\tB b;\n}\n\nclass B {\n\tA a;\n}\n\n//一对多\nclass A {\n\tList<B> b;\n}\n\nclass B {\n\tA a;\n}\n\n//多对多\nclass A {\n\tList<B> b;\n}\n\nclass B {\n\tList<A> a;\n}\n```\n\n+ **比如用户和订单的关系是一对多的，查询一个用户下的所有订单会返回多条记录结果，需要将用户信息封装到一个实体类型的相应属性中，然后这个实体类型中还有一个集合类型的订单类属性，用来封装多条订单记录。称这个实体类型是复杂的，即一个实体类型中包含其它实体类型。**\n\n那么，如何在一个映射文件中实现SQL多表查询返回的结果，可以被正确地映射到相应的实体类型？\n\n这就要用到上面介绍`<resultMap>`标签时，出现的`<association>`和`<collection>`标签。\n\n+ `<association>`标签：映射一对一关系：\n\n```xml\n<!-- 嵌套结果 -->\n<association property=\"card\" javaType=\"club.zunhuier.po.Card\">\n\t<id property=\"id\" column=\"card_id\" />\n\t<result property=\"code\" column=\"card_code\" />\n</association>\n```\n\n+ `<collection>`标签：映射一对多关系：\n\n```xml\n<!-- 嵌套结果 -->\n<collection property=\"items\" ofType=\"club.zunhuier.po.Item\">\n\t<id property=\"id\" column=\"item_id\" />\n\t<result property=\"time\" column=\"item_time\" />\n</collection>\n```\n\n## 总结\n\nMybatis的功能十分强大，需要深入体会Mybatis的映射原理。","tags":["Mybatis","Spring"],"categories":["Java"]},{"title":"Docker入门","url":"/posts/11205/","content":"## Docker简介\n\n官网介绍：\n\n>Docker提供了在松散隔离的环境（称为容器）中打包和运行应用程序的功能。隔离和安全性使您可以在给定主机上同时运行多个容器。容器是轻量级的，因为它们不需要管理程序的额外负载，而是直接在主机的内核中运行。这意味着与使用虚拟机相比，在给定的硬件组合上可以运行更多的容器。您甚至可以在实际上是虚拟机的主机中运行Docker容器！\n\n传统的虚拟化技术，最经典的就是虚拟机技术了，虚拟机技术就不用我过多介绍了吧。而Docker作为一种容器化技术，对比虚拟机技术，更加的轻量，高效：\n\n+ 虚拟机技术是通过某种技术手段，虚拟出一套硬件，再安装一个OS，然后在OS上面运行应用，开销较大。\n\n+ Docker是将应用程序和应用所依赖的环境打包到容器中，应用在容器中运行。而每个容器之间，除了共享宿主机的内核外，是相互隔离，互不影响的。\n\nDocker采用C/S架构，下面是它的架构图：\n\n![Docker架构](https://cdn.jsdelivr.net/gh/shallowhui/cdn/img/docker/dockerfk.png)\n\n+ Client：Docker客户端，是与Docker进行交互的主要方式，通过命令我们可以和Docker的守护进程进行通信。\n\n+ Images(镜像)：可以说是Docker容器的一个只读模板，镜像规定了容器里面配置什么环境、运行什么程序。Docker基于镜像启动容器。\n\n+ Containers(容器)：容器是镜像的一个可运行实例，在容器里面就可以运行各种应用了。\n\n**镜像通常是基于另一个镜像，并进行一些自定义配置。比如可以基于centOS镜像，这个centOS镜像是打包配置好的一个精简的centOS系统，然后再打包进去一些应用程序，比如Tomcat，基于这些环境就可以构建出一个新的Tomcat镜像，Docker基于这个镜像启动一个容器后，你就可以在这个容器中运行你的Web应用了。**\n\n所以，镜像可以类比于我们安装操作系统时要用到的系统镜像文件，容器可以当作是一个简易版的Linux系统。\n\n另外，Docker还有一个重要的东西，那就是`仓库`。Docker仓库就是存放镜像的地方，你可以自己建，也可以去网上的公共仓库下载镜像，镜像都是别人配置好的，用起来特别方便。下面是一个知名Docker仓库，你可以在上面找到可以运行各种应用的镜像：\n\n[Docker Hub](https://hub.docker.com/search?q=&type=image)\n\n## Docker的安装\n\nDocker支持windowss、macOS、Linux。\n\n在官网上有相应平台的安装教程：\n\n[https://docs.docker.com/engine/install](https://docs.docker.com/engine/install)\n\n注意，Linux平台安装的时候，由于apt或者yum用的软件源是国外的，可能下载安装Docker会失败，建议更改为国内源。\n\n安装好Docker后，还需配置Docker的仓库源，不然下载镜像会很慢，具体教程可以自行百度。\n\n## Docker常用命令\n\n安装好Docker后，启动Docker：\n\n``` bash\nsystemctl start docker #启动docker\nsystemctl enable docker #开机自启动docker\n```\n\n查看Docker信息:\n\n``` bash\ndocker version #docker版本\ndocker info #显示docker的信息，包括镜像、容器数量\n```\n\n查看Docker中的镜像、容器：\n\n``` bash\nroot@zunhuier:~# docker images          #查看docker中所有的镜像\nREPOSITORY          TAG                 IMAGE ID            CREATED             SIZE\ntomcat              9.0                 e0bd8b34b4ea        5 days ago          649MB\nmysql               5.7                 1b12f2e9257b        4 weeks ago         448MB\n\nroot@zunhuier:~# docker ps              #查看正在运行中的容器\nCONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                               NAMES\n50c393a0c18d        mysql:5.7           \"docker-entrypoint.s…\"   6 days ago          Up 6 seconds        33060/tcp, 0.0.0.0:3307->3306/tcp   MySQL-2\n\nroot@zunhuier:~# docker ps -a           #查看docker中所有的容器\nCONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS                      PORTS                               NAMES\n55811db0bf39        tomcat:9.0          \"catalina.sh run\"        17 hours ago        Exited (143) 17 hours ago                                       Tomcat-1\n50c393a0c18d        mysql:5.7           \"docker-entrypoint.s…\"   6 days ago          Up 11 seconds               33060/tcp, 0.0.0.0:3307->3306/tcp   MySQL-2\n```\n\n+ `CONTAINER ID`是容器的ID，通过它可以启动、停止、删除容器，当然也可以使用容器别名。\n\n搜索镜像：\n\n``` bash\ndocker search image\n\nroot@zunhuier:~# docker search tomcat\nNAME                          DESCRIPTION                                     STARS               OFFICIAL            AUTOMATED\ntomcat                        Apache Tomcat is an open source implementati…   2883                [OK]                \ntomee                         Apache TomEE is an all-Apache Java EE certif…   84                  [OK]                \ndordoka/tomcat                Ubuntu 14.04, Oracle JDK 8 and Tomcat 8 base…   55                                      [OK]\nbitnami/tomcat                Bitnami Tomcat Docker Image                     36                                      [OK]\nkubeguide/tomcat-app          Tomcat image for Chapter 1                      29                                      \nconsol/tomcat-7.0             Tomcat 7.0.57, 8080, \"admin/admin\"              17                                      [OK]\ncloudesire/tomcat             Tomcat server, 6/7/8                            15                                      [OK]\naallam/tomcat-mysql           Debian, Oracle JDK, Tomcat & MySQL              13                                      [OK]\narm32v7/tomcat                Apache Tomcat is an open source implementati…   10                                      \nrightctrl/tomcat              CentOS , Oracle Java, tomcat application ssl…   6                                       [OK]\nmaluuba/tomcat7-java8         Tomcat7 with java8.                             6                                       \nunidata/tomcat-docker         Security-hardened Tomcat Docker container.      5                                       [OK]\n```\n\n`OFFICIAL`带有[OK]的是官方出品的镜像。但我们一般不用这个命令搜索镜像，而是到我上面提到的叫Docker Hub的仓库中去搜索镜像。因为Docker Hub上面的镜像比较全，而且可以显示tag，即镜像的版本，以及可以查阅官方提供的Docker版应用文档，了解清楚启动容器的时候可以带什么参数之类的信息。\n\n下载镜像：\n\n``` bash\ndocker pull image:tag\n\n#docker pull tomcat\n```\n\n**镜像名字后面加个冒号和tag，可以指明下载哪个版本的镜像，不加就会默认下载latest，即最新版镜像。**\n\n启动容器：\n\n``` bash\ndocker run image:tag\n\n#docker run -d -p 8080:8080 --name Tomcat-1 tomcat:9.0\n```\n\n`docker run`命令的常用参数有：\n\n+ -d：让容器在后台运行。\n\n+ -it：让容器在前台运行，可以看到容器启动时打印的日志信息。\n\n+ -p 主机端口:容器端口：将容器的端口映射到宿主机的端口上，这样通过访问宿主机的端口就可以访问容器中的服务了：\n\n``` bash\nroot@zunhuier:~# netstat -ntlp        \nActive Internet connections (only servers)\nProto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name    \ntcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN      558/sshd: /usr/sbin \ntcp6       0      0 :::3307                 :::*                    LISTEN      1542/docker-proxy   \ntcp6       0      0 :::8080                 :::*                    LISTEN      2178/docker-proxy   \ntcp6       0      0 :::22                   :::*                    LISTEN      558/sshd: /usr/sbin\n```\n\n上面我启动了两个Docker容器，并用主机端口代理了容器端口。\n\n**运行了Docker的机器上，Docker会创建一个虚拟网桥，名字叫docker0，这个网桥有自己的IP地址作为Docker容器的网关，Docker会为每个容器分配一个相同网段的IP地址以进行容器间的通信（Docker容器的网段跟宿主机的网段不同），docker0相当于将两个不同网段的局域网连接了起来。**\n\n``` bash\nroot@zunhuier:~# ifconfig\ndocker0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500\n        inet 172.17.0.1  netmask 255.255.0.0  broadcast 172.17.255.255\n        inet6 fe80::42:b3ff:fe81:7a7c  prefixlen 64  scopeid 0x20<link>\n        ether 02:42:b3:81:7a:7c  txqueuelen 0  (Ethernet)\n        RX packets 0  bytes 0 (0.0 B)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 5  bytes 526 (526.0 B)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n\neth0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500\n        inet 172.16.22.132  netmask 255.255.255.0  broadcast 172.16.22.255\n        inet6 fe80::20c:29ff:fe38:ea  prefixlen 64  scopeid 0x20<link>\n        ether 00:0c:29:38:00:ea  txqueuelen 1000  (Ethernet)\n        RX packets 1709  bytes 177317 (173.1 KiB)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 1274  bytes 224365 (219.1 KiB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n```\n\n这涉及到了Docker的四种网络模式，具体可以自行查阅Docker的官方文档，这里不过多介绍。\n\n+ --name 容器名：为容器起个名字，不加Docker就会随机起个名字。\n\n+ **-e：添加一些自定义参数，通常是跟容器中的应用密切相关的，可以到Docker Hub上查阅镜像的官方文档，看看可以添加什么参数。**\n\n进入容器：\n\n``` bash\ndocker exec -it 容器名/ID bash\n\ndocker attach 容器名/ID\n\nroot@zunhuier:~# docker exec -it Tomcat-1 bash\nroot@55811db0bf39:/usr/local/tomcat# ls\nBUILDING.txt  CONTRIBUTING.md  LICENSE  NOTICE  README.md  RELEASE-NOTES  RUNNING.txt  bin  conf  lib  logs  native-jni-lib  temp  webapps  webapps.dist  work\nroot@55811db0bf39:/usr/local/tomcat# cd /\nroot@55811db0bf39:/# ls\nbin  boot  dev  etc  home  lib  lib64  media  mnt  opt  proc  root  run  sbin  srv  sys  tmp  usr  var\n```\n\n**从上面可以看出，进入容器后，就是进入了一个Linux系统，Tomcat安装在这个系统上。所以说可以把容器当作是一个简易Linux系统。**\n\n退出容器：\n\n``` bash\nroot@55811db0bf39:/usr/local/tomcat# exit\nexit\nroot@zunhuier:~# \n```\n\n+ 注意如果是通过`exec`命令进入容器的话，退出容器不会使容器停止运行，但`attach`命令会。\n\n查看容器启动日志：\n\n``` bash\ndocker logs 容器名/ID\n```\n\n从宿主机上拷贝文件到容器中：\n\n``` bash\ndocker cp 主机路径 容器名/ID:容器内路径 #如果想从容器中拷贝文件到主机上，交换路径顺序就行了\n```\n\n通过`docker run`命令创建并启动一个容器后，可以通过下面的几条命令操作容器：\n\n``` bash\ndocker start 容器名/ID    #启动\ndocker restart 容器名/ID  #重启容器\ndocker stop 容器名/ID     #停止容器\ndocker kill 容器名/ID     #强制停止\n```\n\n删除镜像，容器：\n\n``` bash\ndocker rmi -f 镜像ID或镜像名          #删除指定镜像\ndocker rmi -f $(docker images -aq)  #删除全部镜像\n\ndocker rm 容器ID或者容器名\t        #删除指定容器\ndocker rm -f $(docker ps -aq)    #删除所有容器\n```\n\n## 挂载容器目录\n\n我们在Docker Hub上面找到了一个Apache官方的Tomcat镜像，然后通过命令把镜像下载下来并启动，接着我们怎么在容器中部署我们的Web应用呢？\n\n当然可以使用`docker cp`命令把Web应用拷贝到容器中，但还有更方便的方式，即让主机上的文件跟容器中的文件同步，主机上的目录挂载到容器目录上，操作主机上的文件就相当于操作容器中的文件。\n\n事实上，整个Docker的镜像、容器之类的对象，都是保存在宿主机的文件上的，Linux下目录为`/var/lib/docker/`。\n\n通过下面的命令可以查看容器的目录挂载情况，由`Mounts`属性记录：\n\n``` bash\ndocker inspect 容器名/ID\n\nroot@zunhuier:~# docker inspect MySQL-2\n...\n\"Mounts\": [\n    {\n        \"Type\": \"volume\",\n        \"Name\": \"62c02e5d5e119b8727b1a6bc136f82ac0d8e30e16eb9de6426b2fa831f941d40\",\n        \"Source\": \"/var/lib/docker/volumes/62c02e5d5e119b8727b1a6bc136f82ac0d8e30e16eb9de6426b2fa831f941d40/_data\",\n        \"Destination\": \"/var/lib/mysql\",\n        \"Driver\": \"local\",\n        \"Mode\": \"\",\n        \"RW\": true,\n        \"Propagation\": \"\"\n    }\n],\n...\n```\n+ type是指挂载类型，`bind`是用户自己指定主机上的目录挂载到容器目录中，`volume`则是将一个Volume(卷，可以自己通过docker命令创建，或者docker自己创建)挂载到容器目录中，这个Volume也是主机上的文件，不过是由docker自身进行管理，保存在主机目录`/var/lib/docker/volumes/`下。\n\n+ Source是宿主机上的文件，Destination是容器中的文件。\n\n在启动容器的时候，我们可以自行挂载容器目录：\n\n``` bash\ndocker run -d --name Tomcat-1 -p 3306:3306 -v /home/zunhuier/tomcat_webapps:/usr/local/tomcat/webapps tomcat:9.0\n\n# 添加 -v 主机路径:容器路径 参数即可\n```\n\n这样我们就可以直接把Web应用放到主机上相应的目录下，就相当于部署到容器中了。还可以同步Tomcat的配置文件，这样就不用进入到容器中修改配置了，Docker容器作为一个简易Linux系统自然没装Vim，还要自己装。。\n\n## 自定义镜像\n\nDocker提供了一个简便的方式来构建新的镜像，即编写Dockerfile文件。\n\n下面我将演示如何将一个SpringBoot应用打包成一个Docker镜像，让其在容器中运行。\n\n创建`Dockerfile`文件，编写如下信息：\n\n``` dockerfile\nFROM java:8\nMAINTAINER zunhuier<1031762684@qq.com>\nCOPY springboot-mybatis-1.0.jar /usr/local/springboot.jar\nENV MYPATH /usr/local\nWORKDIR $MYPATH\nENTRYPOINT [\"java\",\"-jar\",\"/usr/local/springboot.jar\"]\nEXPOSE 8080\n```\n\nDockerfile可以编写的指令有：\n\n    FROM          #从一个基本的镜像开始构建\n    MAINTAINER    #镜像构建者信息\n    RUN           #构建镜像时要运行的命令\n    ADD           #添加文件到镜像中\n    WORKDIR       #设置镜像工作目录，即进入容器时的落脚点\n    VOLUME        #挂载VOLUME到容器目录\n    EXPOSE        #指定容器运行时对外开放的端口\n    CMD           #容器运行时要运行的命令，只有最后一个生效\n    ENTRYPOINT    #容器运行时要运行的命令，可以追加命令\n    ONBUILD       #构建一个被继承DockerFile时会被触发\n    COPY          #将文件拷贝到镜像中\n    ENV           #设置容器中的环境变量\n\n将已经打成jar包的SpringBoot项目放在Dockerfile文件的同目录下，然后在当前目录下执行`docker build -t 起个镜像名 .`命令开始构建镜像：\n\n``` bash\nroot@zunhuier:/home/zunhuier/docker-build# ls\nDockerfile  springboot-mybatis-1.0.jar\n\nroot@zunhuier:/home/zunhuier/docker-build# docker build -t springboot .\nSending build context to Docker daemon  24.21MB\nStep 1/7 : FROM java:8\n8: Pulling from library/java\n5040bd298390: Pull complete \nfce5728aad85: Pull complete \n76610ec20bf5: Pull complete \n60170fec2151: Pull complete \ne98f73de8f0d: Pull complete \n11f7af24ed9c: Pull complete \n49e2d6393f32: Pull complete \nbb9cdec9c7f3: Pull complete \nDigest: sha256:c1ff613e8ba25833d2e1940da0940c3824f03f802c449f3d1815a66b7f8c0e9d\nStatus: Downloaded newer image for java:8\n ---> d23bdf5b1b1b\nStep 2/7 : MAINTAINER zunhuier<1031762684@qq.com>\n ---> Running in 395de34e3527\nRemoving intermediate container 395de34e3527\n ---> f11e4f66867e\nStep 3/7 : COPY springboot-mybatis-1.0.jar /usr/local/springboot.jar\n ---> 93f368c3f9f3\nStep 4/7 : ENV MYPATH /usr/local\n ---> Running in c8643079be39\nRemoving intermediate container c8643079be39\n ---> 35505863be9c\nStep 5/7 : WORKDIR $MYPATH\n ---> Running in f1d8a400d460\nRemoving intermediate container f1d8a400d460\n ---> d06a34032e96\nStep 6/7 : ENTRYPOINT [\"java\",\"-jar\",\"/usr/local/springboot.jar\"]\n ---> Running in 76256d2dedf7\nRemoving intermediate container 76256d2dedf7\n ---> 410e6b45ff53\nStep 7/7 : EXPOSE 8080\n ---> Running in 1e6116caf9a8\nRemoving intermediate container 1e6116caf9a8\n ---> 2f94ca039005\nSuccessfully built 2f94ca039005\nSuccessfully tagged springboot:latest\n\nroot@zunhuier:/home/zunhuier/docker-build# docker images\nREPOSITORY          TAG                 IMAGE ID            CREATED             SIZE\nspringboot          latest              2f94ca039005        10 minutes ago      667MB\ntomcat              9.0                 e0bd8b34b4ea        5 days ago          649MB\nmysql               5.7                 1b12f2e9257b        4 weeks ago         448MB\njava                8                   d23bdf5b1b1b        3 years ago         643MB\n```\n\n默认tag为latest，然后就可以启动容器，运行SpringBoot应用了~\n\n## 总结\n\nDocker真的太方便了，就是命令有点多......","tags":["Docker"],"categories":["Go"]},{"title":"世界新冠疫情数据的动态可视化","url":"/posts/64249/","content":"## 前言\n\n多余的话也不想多说哈，\n\n**希望大家一直都平平安安，幸福安康。**\n\n下面就直接开始完成~~Python大作业~~世界新冠疫情数据的动态可视化~\n\n## 数据获取\n\n首先导入绘制图像需要的库：\n\n```python\nimport requests\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport geopandas as gpd #基于pandas库的用来绘制地图的库\nimport io\nimport PIL #处理图像的库\n```\n\n+ 注意，geopandas库的安装有点麻烦，不是简单的`pip`下载安装就能搞定的，请自行百度安装教程。另外如果运行的时候报错提示缺少库，就按照提示安装相应的库。\n\n### 疫情数据集\n\n美国约翰霍普金斯大学在github上公开了他们每日收集到的关于新冠疫情的数据，相关数据可以从以下网址获得：\n\n[https://github.com/CSSEGISandData/COVID-19](https://github.com/CSSEGISandData/COVID-19)\n\n编写在线获取数据的函数：\n\n``` python\ndef getDataFromGithub():\n    #这个url链接的文件是关于新冠疫情爆发至今，世界上每个国家确诊人数的时间线\n    url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv'\n    try:\n        response = requests.get(url)\n        with open('time_series_covid19_confirmed_global.csv','wb') as f:\n            f.write(response.content)\n    except:\n        print('在线获取失败！')\n        return -1\n```\n\n但由于某些原因，`raw.githubusercontent.com`域名可能会访问错误，所以我事先准备好了数据文件（直接把仓库clone下来，获取数据文件），然后用下面的函数读取即可：\n\n```python\ndef getData():\n    return pd.read_csv('time_series_covid19_confirmed_global.csv') #返回一个pandas的DataFrame数据类型\n```\n\n数据集长这样：\n\n![疫情数据集](https://cdn.jsdelivr.net/gh/shallowhui/cdn/img/covid19/casesdata.png)\n\n### 国家地理数据集\n\n现在加载世界上每个国家的地理数据集，以便用geopandas模块绘制出世界地图，注意这里用的地图数据集不是geopandas模块自带的，是从以下网址获取的：\n\n[https://www.naturalearthdata.com/downloads/10m-cultural-vectors/](https://www.naturalearthdata.com/downloads/10m-cultural-vectors/)\n\n如果不知道要下载什么文件，可以直接到我的github上下载`countries`文件夹，放到代码文件目录下：\n\n[https://github.com/ShallowHui/interesting-small-project](https://github.com/ShallowHui/interesting-small-project)\n\n用下面的函数读取数据文件：\n\n```python\ndef getGeoData():\n    world = gpd.read_file('countries') #将下载得到的数据集文件全部放在同目录下的countries文件夹下，然后用geopandas模块读取\n    return world #返回一个geopandas模块的GeoDataFrame数据类型\n```\n\n数据集长这样：\n\n![国家地理数据集](https://cdn.jsdelivr.net/gh/shallowhui/cdn/img/covid19/countriesdata.png)\n\n## 数据清洗\n\n现在我们有了两个数据集，一个关于疫情的，一个是国家地理数据，但这两个数据集都有一些问题：\n\n+ 两个数据集都是把台湾地区单独列出来的：\n\n![疫情数据集中的台湾](https://cdn.jsdelivr.net/gh/shallowhui/cdn/img/covid19/cases_taiwan.png)\n\n![国家地理数据集中的台湾](https://cdn.jsdelivr.net/gh/shallowhui/cdn/img/covid19/countries_taiwan.png)\n\n+ 两个数据集中的国家名不一定对得上，比如地理数据集中的美国国家名为`United States of America`，而疫情数据集中却为`US`。\n\n所以我们要去清洗整理数据，并把两个数据集合并在一起，为此编写了下面这个函数：\n\n```python\ndef MergeData(df,countries): #接收df：疫情数据集，countries：国家地理数据集\n    #将台湾地区设置为中国\n    df['Country/Region'].replace('Taiwan*','China',inplace=True)\n    countries['SOVEREIGNT'].replace('Taiwan','China',inplace=True)\n    \n    #删除疫情数据集中的经纬度数据，因为这在地理数据集中有\n    df = df.drop(columns=['Lat','Long'])\n    #因为疫情数据集中有一些国家是按省份、州进行统计的，一国数据分散，所以要把它们合并\n    df = df.groupby('Country/Region').sum()\n    \n    #简化地理数据集，只用保留坐标列和主权名即可\n    countries = countries.drop(columns=[col for col in countries.columns if col not in ['SOVEREIGNT','geometry']])\n    #然后尽可能地将地理数据集中的国家名改成跟疫情数据集一样\n    countries['SOVEREIGNT'].replace('United States of America','US',inplace=True)\n    countries['SOVEREIGNT'].replace('South Korea','Korea, South',inplace=True)\n    countries['SOVEREIGNT'].replace('Vatican','Holy See',inplace=True)\n    countries['SOVEREIGNT'].replace('eSwatini','Eswatini',inplace=True)\n    countries['SOVEREIGNT'].replace('United Republic of Tanzania','Tanzania',inplace=True)\n    \n    #合并数据集\n    return countries.join(df,how='right',on='SOVEREIGNT')\n```\n\n现在就可以简单地用这个合并后的数据集绘制某一天的世界疫情图看看：\n\n``` python\ndf = getData()\ncountries = getGeoData()\nmergeData = MergeData(df,countries)\n\nfig,ax = plt.subplots(figsize=(23,10))\nplt.title('Total confirmed cases of COVID-19 in the World') #设置画布标题\nplt.text(-35,-30,'11/11/20',fontdict={'size':26 , 'color':'blue'}) #显示当前日期\nmergeData.plot(\n    column = '11/11/20', #绘制哪一列的数据\n    scheme = 'userdefined', #用户自定义模式\n    classification_kwds = {'bins':[0,100,1000,10000,100000,1000000]}, #定义分位点，即疫情严重程度\n    cmap = 'Reds', #颜色\n    legend = True, #显示图例\n    legend_kwds = dict(loc='lower left'), #指定图例显示位置\n    ax = ax #在指定画布的坐标轴上绘制\n)\nplt.show()\n```\n\n![世界疫情地图](https://cdn.jsdelivr.net/gh/shallowhui/cdn/img/covid19/output_17_1.png)\n\n## 实现动态可视化\n\n实现动态可视化的一个思路就是根据每一天的疫情数据，画出若干张图，然后把这些图片合并在一起，形成一个GIF图，为此编写下面这个函数：\n\n``` python\ndef ImgToGif(data):\n    GIF = [] #保存gif动图里的每一张图片\n    dates = data.columns[76:86] #获取数据集中的日期数据\n    fig,ax = plt.subplots(figsize=(23,10))\n    sum = 0\n    length = len(dates)\n    #循环生成每一天的世界疫情图\n    for date in dates:\n        plt.title('Total confirmed cases of COVID-19 in the World, '+date,fontdict={'size':30}) #设置画布标题\n        data.plot(\n            column = date, #绘制哪一列的数据\n            scheme = 'userdefined', #用户自定义模式\n            classification_kwds = {'bins':[0,100,1000,10000,100000,1000000]}, #定义分位点，即疫情严重程度\n            cmap = 'Reds', #颜色\n            legend = True, #显示图例\n            legend_kwds = dict(loc='lower left'), #指定图例显示位置\n            ax = ax #在指定画布的坐标轴上绘制\n        )\n        img = ax.get_figure() #获取绘制完成后的画布\n        f = io.BytesIO() #打开IO流\n        img.savefig(f,format='png') #将图片写入IO流\n        f.seek(0) #文件指针移回初始位置\n        GIF.append(PIL.Image.open(f)) #用PIL模块的专门处理图像的子模块读取IO流，并将流式数据转化成PngImageFile数据类型存放到GIF列表中\n        sum = sum + 1\n        print('\\r生成动图中：{:.2f}%'.format(sum*100./length),end='')\n        \n    #将列表里的所有图片合并生成GIT图\n    GIF[0].save(\n        'COVID-19_visual.gif',\n        format='GIF', #保存为GIF动图\n        append_images=GIF[1:],\n        save_all=True,\n        duration=200, #动图时间间隔，单位毫秒\n        loop=0 #loop=0代表无限循环播放动图\n    )\n    f.close()\n    print('\\n\\r动图生成完成！')\n```\n\n使用其中一小部分数据生成一个GIF图：\n\n![世界疫情地图动态可视化](https://cdn.jsdelivr.net/gh/shallowhui/cdn/img/covid19/COVID-19_visual.gif)\n\n完整的数据集生成的动图大小大概有几十M，可以自行到下面获取源代码试着运行哦~\n\n## 总结\n\n数据动态可视化就介绍到这了，这篇文章的项目完整代码可以自取：\n\n[https://github.com/ShallowHui/interesting-small-project/blob/master/COVID-19_visual.py](https://github.com/ShallowHui/interesting-small-project/blob/master/COVID-19_visual.py)\n\n+ 本代码只适合运行于windows平台，在其它平台运行可能会报库不兼容错误。","tags":["数据可视化"],"categories":["Python"]},{"title":"搭建远程Jupyter Notebook服务","url":"/posts/61849/","content":"## Jupyter简介\n\n百度百科：\n\n>Jupyter Notebook（此前被称为 IPython notebook）是一个交互式笔记本，支持运行40多种编程语言。\n>\n>Jupyter Notebook的本质是一个Web应用程序，便于创建和共享文学化程序文档，支持实时代码，数学方程，可视化和markdown。用途包括：数据清理和转换，数值模拟，统计建模，机器学习等等.\n\n想必学习Python的人都了解，或使用过Jupyter Notebook。它让我们简单地在浏览器上就可以获得类似于IDE的编程体验，不得不说这个工具很棒。\n\n既然Jupyter是基于Web应用的，那这篇文章就讲解如何在远程服务器上搭建Jupyter服务，以此获得一个个人专属的远程编程环境^ _ ^\n\n## 远程服务器上安装Jupyter\n\nJupyter依赖于Python，所以你的服务器上必须要安装有Python，推荐Python3。\n\n然后安装Jupyter，通过Python自带的pip：\n\n``` bash\npip install -i https://pypi.tuna.tsinghua.edu.cn/simple jupyter\n```\n\nJupyter下载安装好后，试一下jupyter命令，如果终端提示说找不到命令，就将Python程序所在目录下的`bin`目录添加到系统Path中，具体教程自行百度。\n\n+ 如果连Python命令、pip命令都无效，那就......\n\n接着输入命令：\n\n``` bash\njupyter notebook --generate-config\n```\n\n这条命令会在`用户主目录/.jupyter/`下生成Jupyter的配置文件`jupyter_notebook_config.py`。\n\n编辑这个配置文件：\n\n``` python\nc.NotebookApp.allow_remote_access = True #允许远程访问\nc.NotebookApp.ip = '0.0.0.0' #允许任何主机访问\n\nc.NotebookApp.notebook_dir = '自定义路径' #指定Jupyter的工作目录，也就是存放代码文件的位置\n```\n\n+ 这些配置选项都是事先写好的，只不过被注释掉了，你可以找到这几条语句后去掉注释再编写，或者你嫌找得麻烦就自己直接写出这几条语句。\n\n保存配置文件，然后再输入命令：\n\n``` bash\njupyter notebook password\n```\n\n它会提示你输入新密码并确认，这个密码以后就是你远程登录Jupyter的时候需要输入的密码了。\n\n最后启动Jupyter:\n\n``` bash\nnohup jupyter notebook --allow-root &\n```\n\n+ 添加--allow-root参数使得linux下的root用户可以启动Jupyter服务。nohup命令自行查阅资料。\n\n记住启动信息里的端口号，默认应该是8888。\n\n## 配置远程访问Jupyter\n\n其实完成上面的步骤，就可以远程访问Jupyter了，通过下面的地址:\n\n    http://zunhuier.club:8888 #当然你的服务器要开放这个端口\n\n+ 我的域名`zunhuier.club`是解析到我的阿里云服务器的，指向我的服务器IP。*（23年换域名了~）*\n\n但浏览器链接的默认端口是80，每次访问Jupyter都要输入端口号有点麻烦。\n\n当然，你自己可以去配置Jupyter使用80端口，但我的博客服务是已经占用了80端口的，所以我得换个方法。\n\n### 通过Nginx实现对访问Jupyter的代理\n\n首先我去阿里云将下面的这个域名解析到服务器：\n\n    jupyter.zunhuier.club ——> 8.129.78.12\n\n然后在服务器上配置Nginx，在Nginx的配置文件中编辑：\n\n``` code\nserver {\n    listen 80; #监听80端口\n    server_name jupyter.zunhuier.club; #指定要访问的主机名\n\n    location /{\n\n        #转发到Jupyter的服务端口上\n        proxy_pass http://localhost:8888;\n\n        tcp_nodelay on;\n        proxy_set_header Host            $host;\n        proxy_set_header X-Real-IP       $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n\n        #下面三行让Nginx提供WebSocket服务\n        proxy_http_version 1.1;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection \"upgrade\";\n    }\n}\n```\n\n保存配置文件，重启Nginx服务器。\n\n最后用下面的这个地址就可以远程访问Jupyter了：\n\n    http://jupyter.zunhuier.club\n\n+ 可以试试访问我的链接，我是设置了密码的^ _ ^自己完成上面的配置也一定要设置密码哦，保证安全~","tags":["Jupyter","Nginx"],"categories":["Python"]},{"title":"SpringMVC入门","url":"/posts/13031/","content":"## 概述\n\n`MVC`这个著名的设计模式想必大家都很了解，在此不再赘述。\n\n在传统的JavaWeb开发过程中，MVC的`C`层，也就是控制层，是用`servlet`技术开发的，servlet技术也的确是JavaWeb后端的基础，需要好好掌握。\n\n而SpringMVC正是基于servlet技术，对servlet进行了封装的一个框架，本质上还是servlet技术。SpringMVC可以帮我们大大简化之前servlet开发模式的流程，它提供了一个前端控制器用于统一接收请求，不用我们自己去配置每个servlet映射的请求了，并且SpringMVC支持多种视图技术，不再仅限于JSP技术。\n\nSpringMVC还有很多优点，下面简单介绍如何引入框架和其工作原理。\n\n## 引入SpringMVC\n\n首先导入框架的依赖包，除了Spring的核心包之外，还要导入两个包：\n\n+ spring-web.jar\n\n+ spring-webmvc.jar\n\n推荐通过`Maven`把依赖包导入项目中，maven的使用可以参考我的这篇文章：[Maven基础](https://zunhuier.top/posts/37716/)\n\n配置`web.xml`文件：\n\n``` xml\n\n...\n\n<!-- 配置SpringMVC前端核心控制器 -->\n<servlet>\n\t<servlet-name>SpringMVC</servlet-name>\n\t<servlet-class>org.springframework.web.servlet.DispatcherServlet<servlet-class>\n    <!-- 指明SpringMVC的配置文件在哪 -->\n\t<init-param>\n\t\t<param-name>contextConfigLocation</param-name>\n\t\t<param-value>classpath:springmvc-config.xml</param-value>\n\t</init-param>\n\t<!-- 配置服务器启动后立即加载SpringMVC配置文件 -->\n\t<load-on-startup>0</load-on-startup>\n</servlet>\n<servlet-mapping>\n\t<servlet-name>SpringMVC</servlet-name>\n\t<!-- /:拦截所有请求，除了带.xxx文件后缀的请求 -->\n\t<url-pattern>/</url-pattern>\n</servlet-mapping>\n\n<!-- 配置SpringMVC自带的编码过滤器，拦截所有请求 -->\n<filter>\n\t<filter-name>CharacterEncodingFilter</filter-name>\n\t<filter-class>org.springframework.web.filter.CharacterEncodingFilter</filter-class>\n\t<init-param>\n\t\t<param-name>encoding</param-name>\n\t\t<param-value>UTF-8</param-value>\n\t</init-param>\n</filter>\n<filter-mapping>\n\t<filter-name>CharacterEncodingFilter</filter-name>\n\t<url-pattern>/*</url-pattern>\n</filter-mapping>\n\n...\n\n```\n\n**从上面的配置就可以看出SpringMVC是基于servlet技术的，`DispatcherServlet`就是框架提供的一个前端控制器，它可以帮我们接收请求，我们只需编写处理请求的代码即可，也就是后端控制器。换句话说，SpringMVC对servlet的功能进行了分离，前端控制器负责接收请求，后端控制器负责处理请求。**\n\n接着创建SpringMVC的配置文件，一般命名为`springmvc-config.xml`，放在类目录的根路径下：\n\n``` xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n       xmlns:mvc=\"http://www.springframework.org/schema/mvc\"\n       xmlns:context=\"http://www.springframework.org/schema/context\"\n       xmlns:tx=\"http://www.springframework.org/schema/tx\"\n       xsi:schemaLocation=\"http://www.springframework.org/schema/beans\n       http://www.springframework.org/schema/beans/spring-beans.xsd\n       http://www.springframework.org/schema/mvc\n       http://www.springframework.org/schema/mvc/spring-mvc.xsd\n       http://www.springframework.org/schema/context\n       http://www.springframework.org/schema/context/spring-context.xsd\">\n    <!-- 配置包扫描器，扫描controller层 -->\n    <context:component-scan base-package=\"edu.gduf.controller\" />\n    <!-- 加载注解驱动 -->\n    <mvc:annotation-driven />\n    <!-- 配置视图解析器 -->\n    <bean class=\"org.springframework.web.servlet.view.InternalResourceViewResolver\">\n        <!-- 定义视图的前缀和后缀 -->\n        <property name=\"prefix\" value=\"/jsp/\" />\n        <property name=\"suffix\" value=\".jsp\" />\n    </bean>\n</beans>\n```\n\n+ `<component-scan>`标签是搭配注解使用的，在SpringMVC框架中编写处理请求的代码有两种方式，一个是实现SpringMVC的核心后端控制器类，一个就是注解开发，这些在后面都会提及。\n\n## SpirngMVC的工作原理\n\n`DispatcherServlet`前端控制器是SpringMVC的核心类，其在框架的架构中就相当于坐镇中央进行调度，当其接收到一个请求时，就会进行如下工作流程：\n\n1. 用户向服务器发送一个请求，请求会被前端控制器按照配置的规则拦截。\n\n2. 前端控制器收到请求后，就会调用`HandlerMapping`即处理器映射器。\n\n3. 处理器映射器会根据请求的URL找到具体的`处理器`也就是我们编写的后端控制器，生成处理器对象，如果有配置拦截器的话，就会把拦截器对象和处理器对象一起返回给前端控制器。\n\n4. 前端控制器根据收到的处理器，选择合适的`HandlerAdapter`即处理器适配器。\n\n5. 处理器适配器调用处理器，对请求进行处理。\n\n6. 处理器处理完后，会返回一个`ModelAndView`对象给处理器适配器，处理器适配器又会把这个对象返回给前端控制器。\n\n7. 前端控制器根据收到的`ModelAndView`对象，选择一个合适的`ViewReslover`即视图解析器。\n\n8. 视图解析器进行解析后，根据处理器中要返回给用户的`视图`，会向前端控制器返回一个具体的视图（比如说JSP模板）。\n\n9. 前端控制器得到具体的视图后，就会对视图进行渲染，即把数据填充至视图中。\n\n10. 最后前端控制器就会把渲染好的视图返回给浏览器客户端。\n\n**上面进行标记的都是SpringMVC的核心组件、核心类。**\n\n+ SpringMVC自带一些常用的拦截器，比如上面配置`web.xml`时配置的一个编码过滤器，我们也可以自定义一个拦截器。SpringMVC的拦截器就类似于servlet的`filter`，这篇文章就不对其进行展开了。\n\n### 实现Controller接口开发后端控制器\n\n根据上面的SpringMVC工作流程，我们只需编写处理请求的后端控制器就行了。\n\n我们定义一个类，实现`org.springframework.web.servlet.mvc.Controller`接口，然后实现接口定义的方法`handleRequest()`。在方法中，我们对请求进行处理，比如通过`HttpServletRequest`对象，保存要向视图填充的数据，然后指定要返回的JSP视图，最后返回一个`ModelAndView`对象。\n\n然后在`springmvc-config.xml`配置文件中，将这个后端控制器作为一个Bean进行配置，主要配置控制器映射的请求。\n\n听起来是不是和servlet开发模式中，要实现doGet()或者doPost()方法差不多？事实上也大致如此，像servlet中内置的request、response、session等对象在SpringMVC中都一样可以使用。\n\n大致介绍完实现接口的开发方式，本质上和servlet开发模式并没有太大的区别，在实际开发中当然不用这种方式，而是使用注解进行开发。\n\n### 注解开发\n\n使用注解开发有很多好处：\n\n+ 不再需要实现接口，只需在一个类上加一个`@Controller`注解，即可将这个类定义为后端控制器，然后配置Spring注解扫描器即可扫描到这个类。\n\n+ 相比于接口实现类只能处理单一请求相比，使用注解的后端控制器可以通过`@RequestMapping`注解处理若干个请求。\n\n注解开发的模板如下：\n\n``` java\n\n...\n\n@Controller\npublic class HandleController {\n\n    @RequestMapping(value=\"/请求路径\")  //value属性用来指明这个方法映射的请求，当只有这个属性时，属性名可以省略\n    public String handleMethod(HttpServletRequest request, HttpServletResponse response) {\n\n        ... //处理请求的代码\n\n        return \"view.jsp\"; //指明返回的视图，当在SpringMVC的配置文件中配置好了视图解析器后，可以不用加视图文件的前后缀\n        // return \"view\";\n    }\n\n    @RequestMapping(\"/请求路径\")\n    public ModelAndView handleMethod(...) {\n\n        ModelAndView mav = new ModelAndView();\n\n        ... //处理请求的代码\n\n        return mav;\n    }\n\n    ...\n\n}\n```\n\n`@RequestMapping`注解部分属性如下：\n\n属性名 | 属性值描述\n------ | -------\nvalue | 映射请求的地址，以项目根目录为根路径。当只有这个属性时，属性名可以省略。可以定义多个映射路径，如@RequestMapping(\"/{firstrequest,secondrequest}\")\nmethod | 指定方法用于处理什么类型的请求，如@RequestMapping(method={RequestMethod.GET,RequestMethod.POST})\nparams | 指定请求中必须包含哪些参数和其值，多个参数以`{}`数组形式指定\nheaders | 指定请求头中必须包含哪些参数和其值\n\n+ **`@RequestMapping`注解可以加在方法上，也可以加在类上。加在类上并指明value属性，就相当于这个后端控制器类中的所有处理请求的方法，在自身的请求路径前面再加了一个统一的前缀路径。**\n\n#### 请求处理方法的返回类型和参数\n\n返回类型一般有ModelAndView、String、void。ModelAndView类型可以向SpringMVC提供的model对象中添加数据，并指定视图。但添加数据完全可以通过servlet的request等对象完成，所以一般都返回的是String类型，直接指明要返回的视图名字。\n\n方法参数可以自定义，可以没有，也可以自己指定跟请求相关的参数。比如，servlet的request等对象。比如前端发来的请求参数，这涉及到数据绑定，后面会讲。\n\n#### 请求重定向和请求转发\n\n返回类型为String可以进行请求的重定向和转发：\n\n+ 重定向：return \"redirect: 视图名字或者别的请求处理方法的请求路径\";\n\n+ 转发：return \"forward: 视图名字或者别的请求处理方法的请求路径\";\n\n#### @RequestBody和@ResponseBody注解\n\n在实际开发中，有一些请求是在前端中通过`ajax`发往后端的，携带的可能是JSON格式的数据。\n\n这两个注解就是用来处理JSON格式的数据：\n\n``` java\n\n...\n\n@RequestMapping(\"/请求路径\")\n@ResponseBody\npublic Object handleMethod(@RequestBody Object object) {\n\n    ... //处理请求的代码\n\n    return object;\n}\n\n...\n\n```\n\n`@RequestBody`注解加在请求参数前面，指明将请求中的JSON格式数据转化为一个Java对象绑定到请求参数中。\n\n`@ResponseBody`注解加在请求处理方法上，用于将方法返回的对象转化为JSON格式数据以对客户端进行响应。\n\n## 数据绑定\n\n**在SpringMVC的后端控制器中，SpringMVC会根据接收到的请求中的参数信息，以一定的方式将其进行转换并绑定到请求处理方法的参数中，这就是数据绑定。**\n\n### 数据绑定的工作原理\n\n1. 在Web容器中，SpringMVC会把一个封装了请求信息的ServletRequest对象传递给`DataBinder`，还会将请求处理方法的`形参对象`也传递给`DataBinder`。\n\n2. DataBinder调用`ConversionService`组件进行数据转换、数据格式化等工作，并在最后将ServletRequest对象信息中的数据绑定到代表请求参数的对象中。\n\n3. SpringMVC调用`Validator`组件对绑定好的数据进行检验。\n\n4. 检验好后，返回一个`BindingResult`对象，里面封装好了数据绑定的结果。\n\n5. 最后SpringMVC就会根据BindingResult对象中的绑定结果去调用请求处理方法，并传入相应的数据。\n\n\n### 简单数据绑定\n\n#### 默认绑定的数据\n\n+ HttpServletRequest：通过request对象获得请求中的信息。\n\n+ HttpServletResponse：通过response处理响应信息。\n\n+ HttpSession：通过session对象获取存储在`session域`中的信息。\n\n+ Model/Model：SpringMVC提供的一个对象，作用是将model中的数据填充到request域。\n\n#### 绑定简单数据类型\n\n如果在请求中有一个简单的参数，那就可以通过如下数据绑定的方式即可获取到这个参数的值：\n\n``` java\n\n...\n\n@RequestMapping(\"/api\")\npublic String api(int id) {   //请求处理方法名一般跟请求同名，但也无所谓\n\n    ...\n\n}\n\n...\n\n```\n\n发送请求`http://localhost:8080/projectname/api?id=1`到服务器，后端就可以直接、正确地接收到这个名为id的参数了。\n\n也就是说请求参数中的一些简单的数据类型，比如int，Sting，Double之类的数据，请求处理方法可以直接通过`同类型、同名`的参数直接接收请求参数。\n\n当然，有时请求中的参数名跟请求处理方法中的参数名不一样，为此SpringMVC提供了`@RequestParam`注解：\n\n``` java\n\n...\n\n@RequestMapping(\"/api\")\npublic String api(@RequestParam(\"id\") int userID) {\n\n    ...\n\n}\n\n...\n\n```\n\n**`@RequestParam`注解的`required`属性还可以用来指定参数是否必须，因为SpringMVC默认简单数据类型的参数是不能为null的，比如int、double，而包装数据类型的参数是可以为null的，比如String，所以可以添加这个注解指明参数是必须的，不能不传，required属性默认为true。**\n\n#### 绑定实体类型\n\n当请求中有多个简单数据类型的参数要传到后端时，如果这些参数都是用来描述一个实体的话，我们可以创建一个实体类，把请求参数都封装进去。然后在请求处理方法中，直接用这个实体类作为参数即可完成对这些请求参数的数据绑定：\n\n``` java\n\n...\n\n@RequestMapping(\"/api\")\npublic String api(Object object) {\n\n    ...\n\n}\n\n...\n\n```\n\nSpringMVC会自动地把这些请求参数绑定到实体类对象中同名的成员属性。**所以，请求实体类中的成员属性名字必须要跟请求参数名一致。**\n\n#### 绑定复合实体类型\n\n如果绑定的实体类Object中有一个成员属性是另一个实体类ObjectA的对象objectA，则相应的请求参数名设置为`objectA.param`即可完成对Object对象中的ObjectA对象中的成员属性的数据绑定。\n\n### 复杂数据绑定\n\n#### 绑定数组\n\n当请求中有多个同名参数要传到后端时，比如在批量删除的请求中，多个用户的ID都以参数名为id的形式传到后端，可以通过数组的形式完成对这些同名请求参数的数据绑定：\n\n``` java\n\n...\n\n@RequestMapping(\"/api\")\npublic String api(int[] id) { //通过遍历数组即可访问每一个参数具体的值了\n\n    ...\n\n}\n\n...\n\n```\n\n#### 绑定集合\n\n当要传多个实体到后端时，比如要传多个完整的用户对象，我们可以通过集合的形式完成数据绑定。\n\n首先定义一个包装类：\n\n``` java\n\n...\n\npublic class UserVo {\n\n    private List<User> users;\n\n    ...  //可以定义get、set方法\n\n}\n```\n\n然后定义请求处理方法：\n\n``` java\n\n...\n\n@RequestMapping(\"/api\")\npublic String api(UserVo userList) {\n\n    List<User> users = userList.getUsers(); //通过get方法即可获得所有的用户对象了\n\n    ...\n\n}\n\n...\n\n```\n\n最后在请求参数中，注意要指明该参数属于集合中的第几个元素，如`users[index].username`即可。\n\nSpringMVC会自动地把相同序列的属性一同作为一个对象，绑定到集合中相应序列的元素中。\n\n### 自定义数据绑定\n\n在一般情况下，上面的几种类型的数据绑定够用了，但有时会有一些数据绑定无效，比如下面的日期数据绑定。\n\n有一个请求`http://localhost:8080/projectname/api?date=2017-04-08`要发到后端，我们自己是知道date参数的数据类型是日期型的，但SpringMVC是不会把它当做日期型数据的，只会把它当作字符串来处理。\n\n如果在请求处理方法中定义`Date date`参数来接收date参数，是接收不到这个参数的，数据绑定无效，因为数据类型不同。\n\n这时我们就需要自定义一个类型转换器了(`Converter`)：\n\n``` java\npackage club.zunhuier.converter;\n\nimport java.text.ParseException;\nimport java.text.SimpleDateFormat;\nimport java.util.Date;\n\nimport org.springframework.core.convert.converter.Converter;\n\npublic class DateConverter implements Converter<String, Date> {  //实现Converter接口\n\n\t// 定义日期格式\n    private String datePatternShort = \"yyyy-MM-dd\"\n    private String datePatternLong = \"yyyy-MM-dd HH:mm:ss\";\n\n    //实现convert方法\n\tpublic Date convert(String source) {\n\n        // 格式化日期\n\t\tString thePattern = source.indexOf(\":\") == -1 ? datePatternShort : datePatternLong;\n\t\tSimpleDateFormat sdf = new SimpleDateFormat(thePattern);\n\t\ttry {\n\t\t\treturn sdf.parse(source);\n\t\t} catch (ParseException e) {\n\t\t\tthrow new IllegalArgumentException(\"无效的日期格式，请使用这种格式:\" + thePattern);\n        }\n    }\n}\n```\n\n还要在SpringMVC配置文件中配置这个转换器：\n\n``` xml\n\n...\n\n<!-- 配置自定义类型的数据转换器 -->\n<bean id=\"myConversionService\" class=\"org.springframework.context.support.ConversionServiceFactoryBean\">\n\t<property name=\"converters\">\n\t\t<set>\n\t\t\t<bean class=\"club.zunhuier.converter.DateConverter\" />\n\t\t</set>\n\t</property>\n</bean>\n\n...\n\n```\n\n配置好后即可完成日期类型的数据绑定了。\n\n## 总结\n\nservlet和SpringMVC的开发模式是有很多共通之处的，需要我们好好掌握servlet。然后就是要熟练掌握SpringMVC的数据绑定，这样才能正常完成前后端的数据交互。","tags":["Spring","SpringMVC"],"categories":["Java"]},{"title":"利用FRP实现内网穿透","url":"/posts/57237/","content":"## 内网穿透\n\n内网穿透，也称`NAT`穿透，进行NAT穿透是为了让处于不同NAT网络(局域网、内网)下的两个主机节点(Peer)之间建立直接或间接的连接，从而可以互相通信。\n\n## 反向代理\n\n反向代理可以简单便捷地实现内网穿透，只需要有一台具有公网IP的主机即可。\n\n这里使用`FRP`这个开源软件来进行反向代理。\n\n### FRP介绍\n\n>frp是一个专注于内网穿透的高性能的反向代理应用，支持`TCP、UDP、HTTP、HTTPS`等多种协议。可以将内网服务以安全、便捷的方式通过具有公网 IP 节点的中转暴露到公网。\n\n`FRP`开源、免费。\n\n### 实现原理\n\n完整的frp服务由客户端(frpc)和服务端(frps)组成，服务端通常部署在具有公网IP的主机上，客户端通常部署在需要穿透的内网服务所在的主机上。\n\n提供内网服务的主机由于没有公网IP，不能被非局域网内的其他主机访问。\n\n用户通过访问服务端的frps，由frp负责根据请求的端口或其他信息将请求路由(转发)到对应的内网主机上，从而实现通信。\n\n+ **简单来说，就是frp实现了数据包的转发。外网上的主机首先将要发送给内网主机的数据包发给frp服务端，服务端再发送给内网主机，即frp在这通信之间充当了反向代理服务器。**\n\nfrp客户端可以配置多个代理。\n\n### 官方\n\nfrp可以在Gihub上下载：[https://github.com/fatedier/frp/releases](https://github.com/fatedier/frp/releases)\n\n![FRP下载](https://cdn.jsdelivr.net/gh/shallowhui/cdn/img/frp/frpdownload.png)\n\n注意要在相应系统上部署相应的frp服务，还要注意版本一致。\n\n官方网站：[https://gofrp.org/](https://gofrp.org/)\n\n上面说的那些概念都可以查看官方文档。\n\n### 部署\n\n以我的一个案例来进行演示。\n\n由于我要上一个Java项目课程，要在课堂上做项目，学校机房的电脑没有相应的编程环境，我不想每次都要重新配环境，也不想带自己的电脑去上课^ _ ^\n\n于是想到了远程桌面连接，那问题来了，宿舍电脑的网络和机房电脑的网络不是同一个局域网，互相不能`直接`访问，于是需要进行内网穿透。\n\n部署frp客户端的是我宿舍里的电脑，安装的是macOS系统，是要进行穿透的内网主机。部署frp服务端的是我在阿里云上的一台云服务器，具有公网IP。\n\n#### 部署客户端\n\n下载macOS版本的frp，解压后得到的文件目录：\n\n![FRP文件目录](https://cdn.jsdelivr.net/gh/shallowhui/cdn/img/frp/frpdir.png)\n\n下载得到的frp是服务端程序和客户端程序都有的，但我们在客户端只需配置客户端的配置，服务端同理。\n\n配置客户端，即配置`frpc.ini`文件：\n\n    [common]\n    server_addr = xx.xx.xx.xx   #frp服务端的公网IP\n    server_port = 6666          #frp服务端接收来自frp客户端请求的端口，对应服务端配置的bind_port\n\n    [vnc]                       #代理的别名，可以自己起\n    type = tcp                  #请求方式\n    local_ip = 127.0.0.1        #要暴露到公网的本机IP，默认就填这个\n    local_port = 5900           #要暴露到公网的本机端口\n    remote_port = 6000          #指明frp服务端用6000号端口进行代理\n\n    [ssh]\n    type = tcp\n    local_ip = 127.0.0.1\n    local_port = 22\n    remote_port = 6001\n\nmacOS的远程桌面服务是vnc(屏幕共享)，打开方法可以自行百度，这个服务默认占用的端口是5900，所以我上面的配置作用就是：将127.0.0.1(本机)上5900号端口的服务`映射`到IP为xx.xx.xx.xx的frp服务端主机(阿里云服务器)的6000号端口。这样，在外网上访问frp服务端的6000号端口，就可以访问到内网主机上5900号端口上的服务了。\n\n上面的配置中还有我顺便配的一个ssh代理，可以让外网上的主机远程登录我宿舍里的电脑。ssh服务的默认端口为22。\n\n配置好后，在frp文件夹下运行命令：\n\n``` bash\n./frpc -c frpc.ini\n```\n\n没报错就说明frp客户端服务部署成功了，然后就可以将命令行窗口放一边让服务运行，记得不要关，关了服务就停止运行了。\n\n#### 部署服务端\n\n配置`frps.ini`文件：\n\n    bind_port = 6666            # frp服务端服务运行占用的端口，用来监听frp客户端的请求\n\n    dashboard_port = 7500       # frp控制面板端口\n    dashboard_user = admin      # 控制面板用户名\n    dashboard_pwd = admin       # 控制面板密码\n\n+ 在浏览器上访问frp服务端的7500号端口，就可以打开frp的控制面板，查看详细的frp服务信息、代理信息、流量信息等等。\n\n配置好后，在frp文件夹下运行命令：\n\n``` bash\nnohup ./frps -c frps.ini &\n```\n\n+ `nohup`是linux上的一个不挂断运行服务的命令，加上`&`让服务在后台运行。这样在frp服务端上frp服务可以一直运行，而frp客户端关掉命令行窗口就可以停止frp服务，当然在linux上可以直接杀掉frp服务。\n\n最后，如果用浏览器可以访问到frp服务端的frp控制面板，并看到如下代理状态：\n\n![FRP控制面板](https://cdn.jsdelivr.net/gh/shallowhui/cdn/img/frp/frpstat.png)\n\n说明成功完成了内网穿透！\n\n## 总结\n\n实现内网穿透的技术不只端口转发这一种，还有像STUN、TURN、ICE这类复杂的`P2P`协议和技术。","tags":["内网穿透","反向代理"],"categories":["Go"]},{"title":"Maven基础","url":"/posts/37716/","content":"## 项目构建\n\n一般而言，我们开发一个项目时，需要经历的构建步骤有：编码、编译、测试、打包、发布，当然这中间还有一些其它步骤。\n\n但其实在如今各种智能IDE大行其道的背景下，我们对这些构建流程几乎没什么感觉。比如我们开发一个Java Web项目，我们写完代码后点击运行按钮，就可以在浏览器上看到相应的效果，这背后其实是IDE帮我们完成了从编译到把项目发布到服务器的工作，如果你的环境在IDE配置好了的话。\n\n那在以前没有IDE，或者说IDE不够智能的情况下，完成这些工作不难，但一件件去完成就会很繁琐，每个项目都还要各自去配置。\n\n**所以就有了Maven这个专门用于Java项目的管理和构建工具，它提供了一套标准的项目目录结构、一套标准化的项目构建流程，以及最重要的一套标准化的依赖管理机制，这样我们就不用到处去找项目依赖的框架、组件的jar包，还要自己导入到项目中去。**\n\n## Maven\n\n### 安装配置\n\nmaven官网下载：[https://maven.apache.org/download.cgi](https://maven.apache.org/download.cgi)\n\n下载好后，解压文件放到一个目录下，接着配置maven环境变量：\n\n    M2_HOME=/maven存放目录/maven-版本号\n    PATH=$PATH:$M2_HOME/bin\n\n这是linux下的配置方式，windows下配置方式参考jdk的配置方式。\n\n注意，maven是依赖于jdk的，所以要先确保你的系统里有`JAVA_HOME`环境变量。最后在命令行输入`mvn -version`，出现maven相关信息说明配置成功。\n\n### 全局配置\n\n安装好maven后，进入maven的文件夹，打开conf文件夹，里面有一个`settings.xml`文件，它是maven的全局配置文件，打开它并做如下修改：\n\n在`<mirrors>`标签下添加阿里的镜像源，这样maven去官方中央仓库下载依赖的时候能快很多：\n\n``` xml\n<mirror>\n  <id>aliyunmaven</id>\n  <mirrorOf>central</mirrorOf>\n  <name>阿里云公共仓库</name>\n  <url>https://maven.aliyun.com/repository/public</url>\n</mirror>\n```\n\n## 约定大于配置\n\n一个用maven管理的项目是有其约定俗成的项目目录结构的，不要随意更改其目录结构，直接使用就行。\n\n一个标准的maven项目的目录结构如下：\n\n    MavenProject\n    ├── pom.xml\n    ├── src\n    │   ├── main\n    │   │   ├── java\n    │   │   └── resources\n    │   └── test\n    │       ├── java\n    │       └── resources\n    └── target\n\n+ pom.xml：这个maven项目的管理配置文件\n\n+ src/main/java：存放项目的源代码\n\n+ src/main/resource：存放项目的资源文件，比如项目的配置文件\n\n+ src/test/java：存放项目的测试源代码\n\n+ src/test/resource：存放项目的测试资源文件\n\n+ target：存放项目所有编译、打包后的文件\n\n## 依赖管理\n\n最重要的东西先讲~\n\n### 仓库\n\n平时我们开发要用到框架、项目依赖组件，我们是不是要到各个官网上去寻找、下载相应的jar包？这样不仅费时费力，还不一定在一些下载入口很深的官网上找到——没错，说的就是你，Oracle。\n\nMvaen就帮我们解决了这个问题，Maven几乎把你能找到的jar包都放到了互联网上的一个中央仓库中。\n\n你只需要在项目的pom.xml文件中进行配置，Maven就可以帮你自动地把项目依赖的jar包从中央仓库下载下来并导入到项目中。\n\n当然，Maven不是每次都到中央仓库中寻找并下载jar包，它会在你的系统上建立一个本地仓库，位置在`/用户目录/.m2`目录下。\n\n这样Maven从中央仓库下载的jar包，会放到本地仓库中进行缓存，当你在下一个项目中要用到同一个依赖时，Maven就会先去本地仓库查找，没有才去中央仓库。\n\n### 坐标\n\n在Maven的仓库中，唯一确定一个项目的是一个三维坐标：\n\n+ groupId：公司、组织的名称，通常为域名的形式\n\n+ artifactId：项目、模块的名称\n\n+ version：项目的版本\n\n在这个网站中，可以查找知名jar包的坐标：[https://mvnrepository.com/](https://mvnrepository.com/)\n\n在pom.xml配置文件中，我们可以定义自己项目的坐标，以及通过坐标引入依赖：\n\n``` xml\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n    xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd\">\n\n    <modelVersion>4.0.0</modelVersion>\n\n    <!-- 定义自己的项目的坐标 -->\n    <groupId>club.zunhuier</groupId>\n    <artifactId>myproject</artifactId>\n    <version>1.0</version>\n\n    <!-- 指明项目的打包方式，是打成jar包还是war包 -->\n    <packaging>jar</packaging>\n\n    <!-- 引入依赖，比如引入Spring框架所需的jar包 -->\n    <dependencies>\n\t<dependency>\n        <groupId>org.springframework</groupId>\n\t\t<artifactId>spring-context</artifactId>\n\t\t<version>5.2.8.RELEASE</version>\n        </dependency>\n    </dependencies>\n\n</project>\n```\n\n+ **Maven的依赖管理还有一个非常强的地方，就是它会帮我们自动判断我们导入的依赖是否还依赖于其它的jar包，然后帮我们自动导入。比如上面我们只引入了Spring框架的context模块，那maven就会自动帮我们导入context模块依赖的core模块以及其它模块，非常方便。**\n\n### 依赖关系\n\n在`<dependency>`标签下，我们还可以通过`<scope>`标签指定我们导入的每一个依赖在项目的构建流程中的作用域。\n\n有如下几种依赖关系：\n\n+ **compile**：项目编译时需要用到该jar包，是每一个依赖默认的关系\n\n+ **test**：测试项目时，编译test文件夹下的源码需要用到，典型的如JUnit：\n\n``` xml\n<dependency>\n    <groupId>org.junit.jupiter</groupId>\n    <artifactId>junit-jupiter-api</artifactId>\n    <version>5.3.2</version>\n    <scope>test</scope>\n</dependency>\n```\n\n+ **runtime**：项目编译时不需要，但运行时需要，典型的如JDBC驱动，比如MySQL的驱动：\n\n``` xml\n<dependency>\n    <groupId>mysql</groupId>\n    <artifactId>mysql-connector-java</artifactId>\n    <version>5.1.46</version>\n    <scope>runtime</scope>\n</dependency>\n```\n\n+ **provided**：项目编译时需要，但运行时不需要，典型的如servlet的API：\n\n``` xml\n<dependency>\n    <groupId>javax.servlet</groupId>\n    <artifactId>javax.servlet-api</artifactId>\n    <version>4.0.0</version>\n    <scope>provided</scope>\n</dependency>\n```\n\n## 构建流程\n\n### 生命周期(Lifecycle)\n\nMaven提供了一套标准化的构建流程，并用流水线上一个个的阶段(phase)来表示一个maven项目的完整生命周期，比如Maven默认的生命周期：\n\n+ validate\n+ initialize\n+ generate-sources\n+ process-sources\n+ generate-resources\n+ process-resources\n+ compile\n+ process-classes\n+ generate-test-sources\n+ process-test-sources\n+ generate-test-resources\n+ process-test-resources\n+ test-compile\n+ process-test-classes\n+ test\n+ prepare-package\n+ package\n+ pre-integration-test\n+ integration-test\n+ post-integration-test\n+ verify\n+ install\n+ deploy\n\n有点多哈，其实也就大概对应于这篇文章开头说的，一个项目的大致构建流程，编译(compile)、测试(test)、打包(package)、发布(deploy)。\n\n进入项目文件夹，在命令行下，使用命令`mvn phase`就可以自动化地将项目构建到某个阶段，常用的命令有：\n\n+ mvn compile：将项目源代码编译，即构建到默认生命周期的compile阶段\n\n+ mvn package：将项目打包，注意，打包之前要先编译，生命周期里的每一个阶段是依次执行的\n\nMaven还有一个clean生命周期，是用来清理项目编译、打包后产生的文件的，即清理target文件夹：\n\n+ mvn clean\n\n### 插件\n\n上面说的生命周期、阶段是概念上的东西，实际上完成这些构建工作的是maven里的插件，`mvn phase`命令就是去调用这些插件的。常用的命令，maven里都有默认的标准插件。\n\n但这些标准的插件有时不能满足需求。比如3.6.3版本的maven里，对应于package阶段的插件，用于将项目打包。但在将项目打成jar包时，是不会将项目引入的依赖包也打进包里去的。\n\n这时，我们可以在pom.xml文件中通过`<build>`标签对项目的构建流程进行配置：\n\n``` xml\n<project>\n    ...\n    <build>\n        <plugins>\n            <plugin>\n                <!-- 指定构建要用的插件的坐标，maven会去自动下载 -->\n                <groupId>org.apache.maven.plugins</groupId>\n                <artifactId>maven-shade-plugin</artifactId>\n                <version>3.2.1</version>\n                <executions>\n                    <execution>\n                        <!-- 指定哪个阶段使用 -->\n                        <phase>package</phase>\n                        <goals>\n                            <!-- 插件里的方法 -->\n                            <goal>shade</goal>\n                        </goals>\n                        <configuration>\n                            <transformers>\n                                <transformer>\n                                    <!-- 指明打包成的jar包的执行入口，即main方法所在的类 -->\n                                    <mainClass>club.zunhuier.main</mainClass>\n                                </transformer>\n                            </transformers>\n                        </configuration>\n                    </execution>\n                </executions>\n            </plugin>\n        </plugins>\n    </build>\n\n</project>\n```\n\n+ `maven-shade-plugin`插件会把我们的项目打成两个jar包，一个带original标记的jar包，是不含依赖包的，另一个是不带original标记，包含依赖包。\n\n## Maven的其它作用\n\nMaven还有一些更高级的用途，可以根据需要去了解使用。\n\n比如，将一个大型项目拆分为一个个的子模块，通过maven去管理它们之间的依赖关系。\n\n比如，通过maven将项目发布。\n\n还有值得说的一点是，我们当然不是就简简单单地新建一个文件夹，作为项目根目录，然后用记事本写代码，保存源代码文件，然后用maven在这个文件夹下通过命令行对整个项目进行构建、管理。\n\n这种方式可以是可以，但在如今IDE越来越智能化的情况下，我们还是要用IDE来提高我们的开发效率^ _ ^\n\n最好就是在IDE中使用maven。像Eclipse、IDEA这些IDE都支持并内置maven，具体的配置过程可以自行查找。\n\n## 后记\n\n像maven这样的项目构建、管理工具，其实有过以下几代的发展过程：\n\n**make  ——>  ant ——>  maven  ——>  gradle**\n\ngradle是比较新的工具，但目前主流的还是用maven。\n\n像在linux系统上，要对一些软件进行编译，可能就会用到make了。","tags":["Maven"],"categories":["Java"]},{"title":"Spring的AOP","url":"/posts/63389/","content":"## 什么是AOP\n\nAOP的全称是Aspect-Oriented-Programming，即面向切面编程。\n\n在传统的业务代码编写中，通常都会在开始处理业务之前进行检查、事务处理，可能还有开启日志记录的操作。这些功能的代码一般单独编写，然后业务类通过继承这些功能类或者组合的方式可以实现代码的重用，这些都是可以通过面向对象编程（OOP）的模式实现的。\n\n但是这样一来，这些功能代码的调用代码，依然会分布在各个业务方法中。如果想开启或关闭某个功能、或者修改了某个功能方法的调用，就要在所有相关的业务代码中进行修改。这就增大了开发人员的工作量，也增大了业务代码出错的概率。\n\n为了解决这个问题，面向切面编程（AOP）的编程思想应运而生。AOP的思想就是，通过横向抽取的机制，把各个业务方法中重复的功能调用代码抽取出来，然后在程序编译或者运行的时候，再将调用代码重新应用到业务方法中需要执行的地方，专业的说法为“织入”。\n\n![AOP的基本思想](https://cdn.jsdelivr.net/gh/shallowhui/cdn/img/springAOP/aop.png)\n\n>这种横向抽取的机制，OOP显然是办不到的，因为OOP只能实现父子关系的纵向的代码重用。顺带一提，虽然AOP是一种新的编程思想，但它不是OOP的替代品，只是一种对OOP的补充和延伸。\n\n**AOP的实现是通过动态代理的方式实现的。**\n\n## 动态代理\n\n上面讲了AOP这种新的编程思想，那它在编码中到底是如何实现的呢？\n\nAOP通过动态代理的方式实现。代理这种设计模式可以理解为：你要访问一个对象，出于安全和封装的考虑和要求，你不是直接访问这个对象的，而是通过访问这个对象的代理对象以达到调用这个对象的目的。类似于现实中的：你要买房→房屋中介→房主。\n\nJava中实现动态代理的方式一般有以下两种。\n\n### JDK动态代理——实现InvocationHandler接口\n\n首先在项目中新建club.zunhuier包，然后在包下建立UserDao接口和其实现类，UserDao实现类的对象就是我们要代理的对象。\n\n``` java\npackage club.zunhuier;\n\n/**\n * JDK动态代理的实现要求被代理对象必须实现一个或多个接口\n */\npublic interface UserDao {\n    //下面两个方法模拟一下业务，具体在实现类中实现\n    public void addUser();\n    public void deleteUser();\n}\n```\n\n``` java\npackage club.zunhuier;\n\n/**\n * UserDao的实现类，也是要动态代理的对象\n */\npublic class UserDaoImpl implements UserDao {\n\n    public void addUser(){\n        System.out.println(\"The user is adding...\");\n    }\n\n    public void deleteUser(){\n        System.out.println(\"The user is deleting...\");\n    }\n}\n```\n\n然后再新建一个aspect包，在aspect包下编写实现日志记录等功能的类，也就是要重用的功能代码。在AOP的思想中，我们把这种类称为切面类，一个类就是一个切面。切面类中的方法我们称为advice，或者说通知，通知用来增强被代理的对象。\n\n``` java\npackage club.zunhuier.aspect;\n\n/**\n * 切面类，增强被代理对象\n */\npublic class MyAspect {\n    //模拟应用启动前的增强\n    public void addStart(){\n        System.out.println(\"应用正在启动中...\");\n    }\n    //模拟日志记录增强\n    public void addLog(){\n        System.out.println(\"开启日志记录\");\n        System.out.println(\"记录应用日志中...\");\n    }\n}\n```\n\n再新建一个JDKProxy包，包下面编写动态代理的类，用来对UserDao进行动态代理。\n\n``` java\npackage club.zunhuier.JDKProxy;\n\nimport club.zunhuier.UserDao;\nimport club.zunhuier.UserDaoImpl;\nimport club.zunhuier.aspect.MyAspect;\n\nimport java.lang.reflect.InvocationHandler;\nimport java.lang.reflect.Method;\nimport java.lang.reflect.Proxy;\n\n/**\n * 动态代理类\n */\npublic class JDKProxy implements InvocationHandler {\n    //声明要代理的接口\n    private UserDao userDao;\n    //代理方法，给外界调用来获取代理后的对象\n    public Object createProxy(UserDao userDao){\n        this.userDao = userDao;\n        //获取类加载器\n        ClassLoader classLoader = JDKProxy.class.getClassLoader();\n        //被代理对象实现的所有接口\n        Class[] classes = userDao.getClass().getInterfaces();\n        //调用newProxyInstance方法，返回代理后的对象\n        return Proxy.newProxyInstance(classLoader,classes,this);\n    }\n\n    /**\n     * 实现InvocationHandler的invoke方法。动态代理后的对象，其所有方法的调用都会交由invoke方法处理，在这里可以对其方法进行增强\n     * @param proxy 被代理后的对象\n     * @param method 代理对象要执行的方法，invoke里通过反射机制调用\n     * @param args 要执行的方法的参数\n     */\n    public Object invoke(Object proxy, Method method,Object[] args) throws Throwable{\n        //声明切面\n        MyAspect myAspect = new MyAspect();\n        //前置通知\n        myAspect.addStart();\n        Object obj = method.invoke(userDao,args);\n        //后置通知\n        myAspect.addLog();\n        return obj;\n    }\n}\n```\n\n在createProxy()方法中，我们通过`newProxyInstance()`方法返回了一个代理对象，其对目标对象进行了代理。然后在invoke()方法中处理代理对象方法的调用，并进行增强。\n\n**注意，在AOP的思想中，我们把程序执行流程的某个阶段称为连接点（Joinpoint），比如常见的连接点有：方法执行前、方法执行完后、方法抛出了异常。然后我们选择一个连接点作为“切入点”（Pointcut），将切面“插入”其中，从而实现了将“通知”织入（weaving）到目标对象的代码中。**\n\n有不理解的地方可以参考上面AOP基本思想的图。\n\n比如，在上面代码的invoke()方法中，我们选择了在方法执行前和方法执行完后织入通知。\n\n最后在JDKProxy包下编写测试类。\n\n``` java\npackage club.zunhuier.JDKProxy;\n\nimport club.zunhuier.UserDao;\nimport club.zunhuier.UserDaoImpl;\n\n/**\n * 测试JDK动态代理\n */\npublic class JDKProxyTest {\n    public static void main(String[] args) {\n        //创建代理类的对象\n        JDKProxy jdkProxy = new JDKProxy();\n        //创建要代理的目标对象\n        UserDao userDao = new UserDaoImpl();\n        //对目标对象进行动态代理，获得代理后的增强对象。需要进行强转\n        UserDao userDaoP = (UserDao) jdkProxy.createProxy(userDao);\n        userDaoP.addUser();\n        System.out.println(\"**************************************\");\n        userDaoP.deleteUser();\n    }\n}\n```\n\n运行结果如下：\n\n![JDK动态代理](https://cdn.jsdelivr.net/gh/shallowhui/cdn/img/springAOP/JDKProxy.png)\n\n### CGLIB代理——Code Generation Library\n\nCGLIB代理通过非常底层的字节码技术，直接对要代理的目标类生成一个子类，并对子类增强来进行代理。所以具有代理实例运行时的高性能。\n\n并且CGLIB代理解决了JDK代理的一个痛点，也就是由于JDK代理是对接口进行代理，所以实际要代理的目标类（对象）必须要实现一个或多个接口，这样JDK代理才能通过代理接口，来实现代理具体的接口实现类\b（对象）。而CGLIB代理可以直接对目标类进行代理，没有接口的限制。\n\nCGLIB代理的具体代码实现就不演示了，实际过程跟JDK代理差不多。注意，要用CGLIB代理的话，就要引入`org.springframework.cglib`包，也就是要导入spring框架的核心包。JDK代理就不用导入第三方包。\n\n>这里再稍微扩展一下什么是静态代理，相对于动态代理，静态代理就很容易理解和实现了，也能解释了为什么JDK动态代理是代理接口。比如说有一个接口Person，然后接口有一个实现类Baby，现在要对Baby类进行代理怎么实现呢？就是再创建一个BabyProxy类，这个类也实现了Person接口。然后在这个代理类中，有一个私有的成员变量：private Baby baby = new Baby()。接着在下面对目标类（Baby类）中的各个方法进行重写，对方法进行增强，怎么增强就看个人，至于原先的方法就可以直接调用baby.方法名(参数)。在外部需要调用Baby类的对象时，就只需创建代理后的对象就行了：Person baby = new BabyProxy()，这样就可以调用跟原Baby类中方法同名的增强方法。\n>\n>这种模式就是静态代理的实现。静态代理的缺点也很明显：针对不同的目标类要编写不同的代理类，代码量巨大。动态代理就可以实现一个代理类代理多个目标类，只要目标类实现同一个接口就行了。\n\n## Spring中的AOP\n\n上面介绍了两种动态代理的方式，而Spring中的AOP代理方式默认就是以JDK代理的方式实现。\n\nSpring中的AOP具体实现有下面两种方式。\n\n### 基于代理类的实现——ProxyFactoryBean\n\n原理其实跟上面一样，都是通过编写代理类来代理目标类（对象）\b。只不过Spring对代理类的编写、代理对象的获取进行了封装，Spring给我们提供了一个叫`ProxyFactoryBean`的工厂实例，这个工厂就专门负责为其它的Bean创建代理对象的实例。\n\n我们就不用自己编写代理类了，只需在Spring配置文件中编写：\n\n``` xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n       xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\">\n    <!-- 目标类的Bean -->\n    <bean id=\"userDao\" class=\"club.zunhuier.UserDaoImpl\"/>\n    <!-- 切面类的Bean -->\n    <bean id=\"myAspect\" class=\"club.zunhuier.aspect.MyAspect\"/>\n    <!-- 指定代理工厂 -->\n    <bean id=\"userDaoProxy\" class=\"org.springframework.aop.framework.ProxyFactoryBean\">\n        <!-- 指定要代理的接口 -->\n        <property name=\"proxyInterfaces\" value=\"club.zunhuier.UserDao\"/>\n        <!-- 指定目标对象 -->\n        <property name=\"target\" ref=\"userDao\"/>\n        <!-- 指定返回的代理对象是否是单例模式，默认为true -->\n        <property name=\"singleton\" value=\"true\"/>\n        <!-- 指定代理方式， true使用cglib，false(默认)使用JDK动态代理 -->\n        <property name=\"proxyTargetClass\" value=\"false\"/>\n        <!-- 指定切面 -->\n        <property name=\"interceptorNames\" value=\"myAspect\"/>\n    </bean>\n</beans>\n```\n\n需要注意的是，我们在配置中只指定了切面，还没有指定切入点。我们需要在切面类中通过实现特定切入点的接口，来指定切入点：\n\n``` java\npackage club.zunhuier.aspect;\n\nimport org.springframework.aop.AfterReturningAdvice;\nimport org.springframework.aop.MethodBeforeAdvice;\n\nimport java.lang.reflect.Method;\n\n/**\n * 切面类，增强被代理对象\n * 要完成Spring的代理工厂配置，切面类还要实现特定的切入点的接口\n */\npublic class MyAspect implements MethodBeforeAdvice, AfterReturningAdvice {\n    //模拟应用启动前的增强\n    public void addStart(){\n        System.out.println(\"应用正在启动中...\");\n    }\n    //模拟日志记录增强\n    public void addLog(){\n        System.out.println(\"开启日志记录\");\n        System.out.println(\"记录应用日志中...\");\n    }\n    //前置通知的方法\n    public void before(Method method, Object[] objects, Object o) throws Throwable {\n        addStart();\n    }\n    //后置通知的方法\n    public void afterReturning(Object o, Method method, Object[] objects, Object o1) throws Throwable {\n        addLog();\n    }\n}\n```\n\n特定的切入点接口定义在`org.springframework.aop`中，具体有哪些切入点可以自行查阅Spring文档。需要注意的是，实现环绕通知的切入点接口定义在`org.aopalliance.intercept.MethodInterceptor`中，所以还要导入第三方jar包。\n\n然后编写测试类，直接从Spring工厂中获取代理对象的实例：\n\n``` java\npackage club.zunhuier.JDKProxy;\n\nimport club.zunhuier.UserDao;\nimport club.zunhuier.UserDaoImpl;\nimport org.springframework.context.ApplicationContext;\nimport org.springframework.context.support.ClassPathXmlApplicationContext;\n\n/**\n * 测试JDK动态代理\n */\npublic class JDKProxyTest {\n    public static void main(String[] args) {\n        ApplicationContext applicationContext = new ClassPathXmlApplicationContext(\"applicationContext.xml\");\n        UserDao userDao = (UserDao)applicationContext.getBean(\"userDaoProxy\");\n        userDao.addUser();\n        System.out.println(\"**************************************\");\n        userDao.deleteUser();\n    }\n}\n```\n\n运行结果：\n\n![ProxyFactoryBean代理工厂](https://cdn.jsdelivr.net/gh/shallowhui/cdn/img/springAOP/ProxyFactorybean.png)\n\n### 基于AspectJ的实现\n\nAspectJ是一个基于Java的AOP框架，提供了强大的AOP功能。Spring2.0之后，AOP模块就对AspectJ进行了支持，官方也鼓励使用AspectJ来实现AOP，上面的代理工厂反倒很少使用。使用AspectJ需要额外导入一个包：`aspectjweaver.jar`。这个依赖包可以通过下面的网址进行下载：\n\n[http://mvnrepository.com/artifact/org.aspectj/aspectjweaver](http://mvnrepository.com/artifact/org.aspectj/aspectjweaver)\n\nAspectJ框架实现AOP的具体方式有下面两种。\n\n#### 基于XML配置\n\n这个就不多讲了，毕竟XML文件配置还是比较繁琐的。其实也跟上面的配置代理工厂差不多，不过是在`<aop:config>`这个标签下配置，具体实现方式可以自行查找。\n\n需要注意的是要掌握“切入点表达式”。\n\n#### 基于注解配置\n\n首先在Spring的配置文件中开启包的注解扫描，以及AspectJ的注解支持：\n\n``` xml\n<!-- 扫描指定的包，使Spring注解生效，注意需要在<beans>标签中引入<context>和<aop>标签的约束信息 -->\n<context:component-scan base-package=\"club.zunhuier\"/>\n<!-- 启动基于注解的AspectJ支持 -->\n<aop:aspectj-autoproxy/>\n```\n\n接着在UserDaoImpl类上加一个注解：\n\n``` java\n@Repository(\"userDao\") //告诉Spring这是一个Bean\n```\n\n然后在aspect包下新建一个切面类MyAspectAspectJ，里面的通知方法跟之前的那个切面类一样，接着用注解的形式在类中定义切入点、通知类型，以实现AOP：\n\n``` java\npackage club.zunhuier.aspect;\n\nimport org.aspectj.lang.annotation.After;\nimport org.aspectj.lang.annotation.Aspect;\nimport org.aspectj.lang.annotation.Before;\nimport org.aspectj.lang.annotation.Pointcut;\nimport org.springframework.stereotype.Component;\n\n/**\n * 基于注解定义的切面类\n */\n@Aspect //声明这是一个切面类\n@Component //还要告诉Spring这是一个Bean\npublic class MyAspectAspectJ {\n    /**\n     * 定义切入点表达式，这里的表达式的意思是匹配club.zunhuier包下的任意类的任意返回类型、任意参数的方法的执行\n     * @Poincut这个注解要加到一个返回类型为void，且方法体为空的方法上。方法名就可以代表这个切入点\n     */\n    @Pointcut(\"execution(* club.zunhuier.*.*(..))\")\n    private void pointCut(){};\n\n    @Before(value = \"pointCut()\") //声明这是一个前置通知，value参数的值为定义切入点的方法\n    public void addStart(){\n        System.out.println(\"应用正在启动中...\");\n    }\n    @After(\"pointCut()\") //声明这是一个后置通知，value可以省略\n    public void addLog(){\n        System.out.println(\"开启日志记录\");\n        System.out.println(\"记录应用日志中...\");\n    }\n}\n```\n\n最后在测试类中测试，运行结果如下：\n\n![基于注解的AspectJ实现AOP](https://cdn.jsdelivr.net/gh/shallowhui/cdn/img/springAOP/AspectAnnotation.png)\n\n## 总结\n\n本篇文章主要介绍了动态代理和Spring中AOP实现方式。要深入理解AOP的本质就是动态代理，并熟练掌握基于注解的AspectJ实现AOP的方式。\n\n\n\n\n\n\n","tags":["Spring","动态代理"],"categories":["Java"]},{"title":"Spring的IoC和DI","url":"/posts/7343/","content":"## Bean\n\n在Web开发或者软件开发中，我们通常把一些需要复用的代码抽取出来，写成一个个工具类，或者说组件。我们把这些组件称为JavaBean、Bean(Bean英文原意为豌豆)。Spring框架的主要功能就是对这些组件(Beans)的创建和依赖关系，以IoC和DI的方式进行管理。\n\n我们可以把Spring看作是一个大型工厂，这个工厂的作用就是生产和管理Spring容器中的Bean。\n\n## Spring核心容器\n\nSpring对Bean的生产管理功能是通过其核心容器实现的，Spring有两种核心的IoC容器：\n\n1. **BeanFactory：**\n    BeanFactoty由org.springframework.beans.facytory.BeanFactory接口定义。由于这个核心容器在实际开发中并不多用，所以不过多介绍，也不介绍其实现类。\n\n2. **ApplicationContext：**\n    ApplicationContext是BeanFactory的子接口，由org.springframework.context.ApplicationContext接口定义。不仅支持BeanFactory的所有功能，还添加了对国际化、资源访问等方面的支持。\n\n下面介绍ApplicationContext的实现类：\n\n1. **通过ClassPathXmlApplicationContext创建Spring容器：**\n    ClassPathXmlApplicationContext会从**项目的类路径**寻找指定的XML配置文件并装载，完成Spring容器的实例化工作。\n\n2. **通过FileSystemXmlApplicationContext创建Spring容器：**\n    FileSystemXmlApplicationContext会从**操作系统文件目录路径**寻找指定的XML配置文件并装载，完成Spring容器的实例化工作。\n\n实例化Spring容器的语句：\n\n``` java\n/*\n    一般不使用FileSystemXmlApplicationContext类来实例化Spring容器\n*/\nApplicationContext applicationContext = new ClassPathXmlApplicationContext(String XMLPath);\n```\n\n**值得一提的是，在普通的Java项目中，我们要使用Spring容器，就要自己把它实例化出来。不过在Web项目中，我们可以把这项工作交给Web服务器来完成，只需在Web项目的配置文件web.xml中添加下面几行语句：**\n\n``` xml\n<!-- 指定Spring配置文件的位置，多个配置文件以逗号分隔 -->\n<context-param>\n    <param-name>contextConfigLocation</param-name>\n    <param-value>classpath:applicationContext.xml</param-value>\n<!-- Spring配置文件一般以applicationContext命名，直接放在项目的src目录下 -->\n</context-param>\n<!-- 指定Web服务器以ContextLoaderListener的方式启动Spring容器 -->\n<listener>\n    <listener-class>org.springframework.web.context.ContextLoaderListener</listener-class>\n</listener>\n```\n\n## 配置Bean\n\n要让Spring对Bean进行管理，就要在Spring的配置文件中对Bean进行配置。\n\nSpring的配置文件支持XML和Properties两种格式的文件，一般使用XML文件。\n\n在Spring中，XML配置文件的根元素是`<beans>`，`<beans>`中包含多个`<bean>`子元素，每个`<bean>`元素对应了一个Bean，并描述了该Bean如何被装配到Spring容器中。\n\n`<bean>`元素的常用属性及子元素：\n\n![bean元素的常用属性及子元素](https://cdn.jsdelivr.net/gh/shallowhui/cdn/img/springIoCAndDI/spring_bean.png)\n\n通常在XML文件中只需配置Bean的id和class属性就可以了：\n\n``` xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n\txmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n\txmlns:aop=\"http://www.springframework.org/schema/aop\"\n\txmlns:tx=\"http://www.springframework.org/schema/tx\"\n\txmlns:context=\"http://www.springframework.org/schema/context\"\n\txsi:schemaLocation=\"http://www.springframework.org/schema/beans \n            http://www.springframework.org/schema/beans/spring-beans.xsd\n            http://www.springframework.org/schema/tx \n            http://www.springframework.org/schema/tx/spring-tx.xsd\n            http://www.springframework.org/schema/context \n            http://www.springframework.org/schema/context/spring-context.xsd\n            http://www.springframework.org/schema/aop \n            http://www.springframework.org/schema/aop/spring-aop.xsd\">\n    <bean id=\"Bean的唯一标识名称\" class=\"Bean的实际类路径\" /> \n</beans>\n```\n\n+ Spring的XML配置文件约束比较多，手写浪费时间也容易出错，可以直接复制相同Spring版本的配置文件约束就好了。或者打开Spring解压缩文件，在doc目录下，找到spring-framework-reference文件夹打开，然后找到html文件夹打开，最后找到index.html文件。用浏览器打开index.html文件，在Overview of SpringFramework下的Configuration metadata小节中就有配置文件的约束信息，如果没有就在这个文件中多找找。\n\n## 获取Bean\n\n我们在配置好Bean后，可以从Spring容器这个工厂中获取到Bean的实例化对象，通过下面两种方法：\n\n1. Object getBean(String BeanID)：需要将返回结果强制转型。\n\n2. &lt;T&gt; getBean(Class&lt;T&gt; BeanType)：泛型方法，不需要强制转型。\n\n例子：\n\n``` java\n//通过Spring容器的实例化对象获取Bean\nApplicationContext applicationContext = new ClassPathXmlApplicationContext(String XMLPath);\nBean bean = (Bean) applicationContext.getBean(\"BeanID\"); //强制转换为跟Bean的类型一样\n```\n\n## IoC和DI\n\nIoC，全称Inversion of Control，意思是控制反转。DI，全称是Dependency Injection，意思是依赖注入。\n\n**这两个概念的含义相同，不过是从两个不同的角度来描述同一个概念。**\n\n在以前的方式中，当在某个Java类中需要使用另一个Java类的对象时，我们是要在这个类的代码中，自己`new`一个被调用的对象出来。\n\n在使用Spring后，对象的实例不再由我们写的代码来创建，而是由Spring容器来创建。这样，Spring容器负责控制Bean之间的关系，而不是我们写的程序代码直接控制。比如上面介绍的Spring中的Bean，我们并没有直接`new`出Bean的实例化对象出来，而是通过Spring容器来进行创建和获取。\n\n**所以，站在程序员的角度来看，控制权发生了反转，这就是Spring的控制反转，IoC。**\n\n**站在Spring的角度来看，Spring容器负责实例化程序代码中需要用到或者说依赖的对象，并注入到代码的成员变量(属性)中，这就是Spring的依赖注入，DI。**\n\n**依赖注入的作用就是在Spring容器中实例化一个对象(Bean、组件)时，可以动态地将其所依赖的对象注入其中，即为类的属性(成员变量)注入值。**\n\n## 依赖注入方式\n\nSpring的依赖注入方式有基于XML配置文件的方式，还有基于注解(Annotation)的方式。\n\n### 基于XML配置文件\n\n#### 设值注入\n\n在Spring创建Bean的过程中，可以通过**反射**的方式调用属性的setter将依赖对象注入。\n\n因此设值注入必须满足的要求：\n\n+ Bean类必须为需要注入值的属性提供相应的setter。\n\n在Spring配置文件中，配置Bean，并通过`<bean>`元素的子元素`<property>`来为属性注入值。\n\n例子：\n\n``` xml\n<!-- 设值注入 -->\n<bean id=\"beanname\" class=\"beanclasspath\">\n    <!-- 注入基本数据类型的值 -->\n    <property name=\"属性名\" value=\"属性值\"></property>\n    <!-- 可以注入另一个Bean -->\n    <property name=\"属性名\" ref=\"另一个Bean的id\"></property>\n    <!-- 可以注入List类型的属性 -->\n    <property name=\"属性名\">\n        <list>\n            <value>\"属性值1\"</value>\n            <value>\"属性值2\"</value>\n        </list>\n    </property>\n</bean>\n```\n\n#### 构造注入\n\nSpring默认只通过Bean的无参构造方法创建实例对象，可以通过`<constructor-arg>`元素来指定构造方法：\n\n``` xml\n<bean id=\"beanname\" class=\"beanclasspath\">\n    <constructor-arg index=\"方法参数索引\" ref=\"依赖的Bean\"></constructor-arg>\n    <constructor-arg index=\"0\" ref=\"\"></constructor-arg>\n    <constructor-arg index=\"1\" ref=\"\"></constructor-arg>\n    ...\n</bean>\n```\n\n**注意，如果对同一个属性既进行了设值注入又进行了构造注入，则属性最终的值以setter为准。依赖注入可能会发生循环依赖的问题，如果是设值注入时出现循环依赖，Spring本身会通过`三级缓存`的方式解决这个问题，而如果是构造注入时出现，则解决起来比较麻烦。**\n\n#### 自动注入\n\n自动注入就是通过`<bean>`元素的autowire属性来进行自动装配。\n\n![Bean的自动装配](https://cdn.jsdelivr.net/gh/shallowhui/cdn/img/springIoCAndDI/spring_bean_autowire.png)\n\n`byName`是寻找id跟属性的Setter方法名相同的Bean，如Bean的id为xxx，属性的Setter方法名为SetXxx，将其注入进去。`byType`就是找容器中是否有跟属性类型相同的Bean。注意，两者都要求属性有Setter方法。\n\n### 基于注解装配\n\n如果基于XML对Bean进行装配，那么随着Bean的增多，Spring的配置文件会越来越臃肿，对后续的系统维护和升级工作带来一定的困难。为此，Spring提供了对**注解技术**的全面支持。\n\nSpring中定义了一系列的注解：\n\n![Spring的注解](https://cdn.jsdelivr.net/gh/shallowhui/cdn/img/springIoCAndDI/spring_annotation.png)\n\n在类上添加表明这个类是一个Bean的注解，接着在成员属性上添加@Autowired或@Resource注解，然后开启Spring的注解扫描功能，就可以实现依赖注入了。\n\n例子：\n\n``` java\nimport org.springframework.beans.factory.annotation.Autowired; //导入注解类\nimport org.springframework.stereotype.Service;\n\nimport com.java.util.AnotherBean;\n\n@Service\npublic class ServiceBeanImpl{\n\n    ...\n\n    @Autowired\n    private AnotherBean bean; // 另一个Bean\n\n    ...\n}\n\n```\n\n``` xml\n<context:component-scan base-package=\"指定的包路径\"/>\n```\n\n**Spring会在指定包下扫描出加了@Component、@Repository、@Service之类的注解的Bean。如果这些注解后面没有指明Bean的id，Spring默认会以类名(但是首字母小写)作为Bean的id，在BeanFactory中创建出这些Bean的实例。然后在有需要的地方，比如有@Autowired注解，注入依赖。**\n\n**像@Autowired这样具有注入功能的注解，可以加在属性、方法、和构造方法上。加在属性上，Spring就会去容器中寻找相应类型的Bean注入到属性中。加在方法上，Spirng会通过反射调用这个方法，方法的实参从Spring容器中找到并注入，所以一般是加在属性的setter方法上。上面两种方式相当于进行了设值注入。Spring容器如果是通过@Component之类的注解来创建Bean的话，Bean类的定义中必须有且只有一个构造方法供Spring容器调用，否则Spring容器在创建Bean的时候会不知道到底调用哪个构造方法(但如果多个构造方法中有无参构造方法，那Spring容器就会直接调用无参构造方法)，这时将@Autowired加在构造方法上，就指定了创建Bean时调用哪个构造方法，构造方法的实参从Spring容器中找到并注入，这相当于进行了构造注入。以上从Spring容器中寻找实参，如果没找到就会报错。**\n\n这样就不用在XML文件中配置各种Bean了，一句话就搞定了。当然，以后学深了Spring框架，会逐渐摆脱XML文件，使用纯注解的开发方式。\n\n+ 注意，Spring4.0以上的版本，使用注解扫描时，还需要额外在项目中导入Spring AOP模块的spring-aop-版本号.RELEASE.jar包。\n\n## 总结\n\n要理解好IoC和DI的概念，掌握DI的概念和方法。","tags":["Spring"],"categories":["Java"]},{"title":"Spring入门","url":"/posts/35289/","content":"## Spring简介\n\n### 什么是Spring框架\n\nSpring是由Rod Johnson组织和开发的一个用在Java SE/EE开发中的轻量级开源框架，Spring以IoC(Inversion of Control，控制反转)和AOP(Aspect Oriented Programming，面向切面编程)的特性为核心，取代了以前EJB臃肿、低效的开发模式。\n\nSpring具有简单、可测试和松耦合的特点，不仅适用于Web服务器端开发，也可以应用于任何Java应用的开发，并且可以方便地集成其它各种优秀框架。使用Spring，可以将所有对象(JavaBean)的创建和依赖关系的维护工作都交给Spring容器管理，大大地降低了组件之间的耦合性。\n\n### Spring的体系结构\n\nSpring框架采用的是分层架构，它的一系列功能被分为20多个模块，大体上分为以下几大类：\n\n1. **Core Container(核心容器)：**\n    Spring的核心容器是Spring其它模块运行工作的基础，核心容器主要由Beans模块、Core模块、Context模块和Expression(SpEL)模块组成。其中Core是核心模块，它实现了Spring的IoC和DI核心功能。\n\n2. **Data Access/Integration(数据访问/集成)：**\n    数据访问/集成层包括JDBC、ORM、OXM、JMS等模块。主要功能是提供了JDBC的抽象层，并可以良好地与一些数据持久化开源框架，如Hibernate、Mybatis等进行集成，大大地减少了在开发过程中对数据库进行操作的代码。\n\n3. **Web：**\n    Web层包括WebSocket、Servlet、Web和Portlet模块。对于Web服务器端开发而言，主要提供了对MVC模型的实现。\n\n4. **其它模块：**\n    Spring的其它模块还有AOP、Aspects等模块。可以提供面向切面编程的实现，以及一些其它功能。\n\n![Spring框架的体系结构](https://cdn.jsdelivr.net/gh/shallowhui/cdn/img/spring/spring_overview.png)\n\n## Spring的下载和使用\n\n### 下载\n\nSpring的第一个版本是在2004年发布的，经过10多年的发展，截止我写这篇博客的时候，Spring的最新发行版本已经是5.2.7了。\n\n下载可以到[Spring版本仓库](https://repo.spring.io/webapp/#/artifacts/browse/simple/General/libs-release-local/org/springframework/spring/5.2.7.RELEASE)下载。\n\n由于Spring在Github上开源，所以可以在Github上下载Spring的源码，仓库项目名为：`spring-framework`。\n\n### 使用\n\n将下载下来的Spring框架压缩包解压后打开，在lib目录下可以找到Spring每个模块对应的jar包，以及相应的源代码jar包和API文档jar包，也就是说每个模块都有对应的三个jar包，但我们在使用时，只需要在项目中导入以`RELEASE.jar`结尾的jar包，这是Spring框架编译好后的class文件jar包。\n\n在根目录下还有一个schema文件夹，里面包含了开发所需的schema文件，这些文件定义了Sping相关XML配置文件的约束。\n\n在众多jar包中，有四个Spring的基础包，分别对应Spring核心容器的四个模块：\n\n+ spring-core-版本号.RELEASE.jar\n\n+ spring-beans-版本号.RELEASE.jar\n\n+ spring-context-版本号.RELEASE.jar\n\n+ spring-expression-版本号.RELEASE.jar\n\n实际使用Spring开发时，除了要用到Spring自带的jar包，还需要导入一个Spring的依赖包，`commons-logging.jar`。这个依赖包可以通过下面的网址进行下载：\n\n[http://commons.apache.org/proper/commons-logging/download_logging.cgi](http://commons.apache.org/proper/commons-logging/download_logging.cgi)\n\n初学者学习Spring框架的时候，只需将上面四个基础包和依赖包导入到项目中，就可以使用Spring的基本功能了。\n\n\n","tags":["Spring"],"categories":["Java"]},{"title":"Java多线程","url":"/posts/58846/","content":"## 前言\n\n随着微处理器技术的飞速发展，个人计算机上的操作系统纷纷改用多任务和分时的设计。多任务就是指操作系统可以同时运行多个应用程序，为此操作系统引入了`进程`的概念。\n\n## 概述\n\n### 程序\n\n程序就是指我们写的代码，在计算机世界内部其实也就是一条条指令，加上程序里要用到的数据，统统被保存在硬盘或者其它外部存储设备里。也就是说程序是静态的代码。\n\n### 进程\n\n硬盘里的程序经过一系列复杂的步骤后，被操作系统从硬盘调到主存中，然后CPU去访问主存把指令一个个取出来执行，这就是计算机的工作原理。在这里，这个程序的一次执行过程就叫做一个进程，换句话说，一个进程就是一个正在执行的程序，即代码是动态的。进程是操作系统资源分配和处理器调度的基本单位，各自拥有独立的代码、内部数据和运行状态。\n\n多任务就是指在一个系统中可以同时运行多个进程，即有多个独立运行的任务，每个任务对应一个进程，每个进程都有自己专用的内存区域，即使是多次启动同一个程序，产生的多个进程也是如此。所谓的同时运行的进程，其实是由操作系统将系统资源分配给各个进程，每个进程在CPU上交替运行，也就是下面要说的并发执行。每个进程占有不同的内存区域，内存消耗很大，这使得系统在不同的应用进程之间切换时开销很大，进程之间的通信速度也很慢。\n\n### 并行和并发\n\n并发执行和并行执行并不相同。\n\n在计算机中，一条指令是有它的指令周期（取址，间址，执行，中断）的，同一时刻，CPU上只能处理一条指令，这样一条条指令依次执行下去，我们叫做串行执行。\n\n那如何同一时刻执行多条指令呢？这往往需要多个处理器的硬件支持，多条指令在多个CPU上同时执行，这就叫做并行执行。\n\n在一个CPU上其实我们也可以做到伪”并行“的效果。这是因为计算机的运行速度非常快，一个指令周期人是根本感受不到的，那么在一个极短的时间段内，这个极短时间段也是人根本感受不到的，多条指令交替执行，这样给人的感觉就是这些指令是”同时“执行的，即所谓的”微观串行，宏观并行“，并发执行就是这样实现的。\n\n+ 并发执行体现在程序上，就是将本来要顺序执行的程序代码，分成一个个相对独立的代码段，每一个代码段都是一个逻辑上相对完整的程序，那一会去执行一下这个代码段里的代码，一会又去执行一下那个代码段里的代码，这样快速交替执行这些代码段，看上去这些代码段就是“同时”执行的，这就实现了并发执行。\n\n+ 在单处理器上，同一时刻始终还是只能执行一条代码，并发执行实质上还是串行执行。\n\n### 线程\n\n**为了减轻系统的负担，引入了线程的概念，将系统资源分配和处理器调度的基本单位分离。进程现在只是资源分配的基本单位，线程是处理器调度的基本单位。一个进程包含一个以上的线程，进程中的所有线程共享该进程的内存区域和数据。**\n\n所谓的线程，其实与进程相似，也是一个执行中的程序，但线程是一个比进程更小的执行单位，有自身的产生、运行、消亡的过程：\n\n![线程的生命周期](https://cdn.jsdelivr.net/gh/shallowhui/cdn/img/thread/thread.png)\n\n以往开发的程序，大多是单线程的，即一个程序只有从头到尾顺序执行这一条路径，一般也就是main()方法所在线程，我们把它叫做主线程。然而现实世界中很多的过程都具有多条途径同时运作的特征。比如，我们可以一边喝咖啡，一边听音乐。再比如，一个Web服务器需要同时处理多个客户端的请求。\n\n多线程就是指在同一个进程中同时存在多个执行体，将程序执行过程并发化。一个进程在执行过程中可以产生多个线程，形成多条执行路径。线程不能单独存在，必须存在于进程中，由于同一个进程中的线程是共享同一块内存区域的，所以系统在产生一个线程，或是在各个线程之间切换时，负担要比进程小很多，线程间的通信也快得多。让CPU在同一时间段内执行一个程序中的多个代码段，使工作完成得更有效率，这就是多线程的概念。\n\n+ 要注意并发、多线程、多任务这些概念的区别。多线程是通过并发实现的，并发可以实现多个代码段的同时执行，那多线程就通过并发实现程序的多条执行路径同时执行。多线程和多任务是两个不同的概念。多任务是针对操作系统而言的，表示操作系统可以运行多个应用程序。而多线程是针对一个进程而言的，表示在一个进程内部同时执行多个线程。\n\n### 线程的优先级和调度\n\n在多线程的程序中，每个线程都被赋予了一个执行优先级。优先级决定了线程被CPU执行的优先顺序。优先级高的线程可以在一段时间内获得比优先级低的线程更多的执行时间。\n\n+ Java语言中线程的优先级从低到高以整数1~10表示，共分为10级。主线程的优先级默认为5。\n\n线程的调度就是指在各个线程之间分配CPU资源，多个线程的并发执行实际上是通过一个调度模型来进行的。线程调度的模型有两种：分时模型和抢占模型。\n\n在分时模型中，CPU资源是按时间片分配的，即把CPU的使用时间分成一片一片的。获得CPU使用权的线程，只能在指定的一个时间片内执行程序，一旦这个时间片使用完毕，就必须把CPU使用权让给另一个处于就绪状态的线程。分时模型的调度是没有优先级一说的，所有线程轮流获得CPU的使用权，并且平均分配时间片，每个线程获得相同数量的时间片。\n\n在抢占模型中，优先让优先级高的线程使用CPU，如果优先级相同，则随机选择一个线程执行。一旦一个线程获得了CPU的使用权，这个线程将一直执行下去，直到该线程因为某种原因而不得不让出CPU的使用权。比如，一个正在执行的低优先级线程，碰到一个准备就绪的高优先级线程，就会把CPU使用权让出来，或者线程由于某种原因进入阻塞状态，又或者线程执行完毕。那么，为了让低优先级的线程有机会执行，应该让高优先级的线程时不时地进入“休眠”状态。\n\n**Java语言支持的就是抢占式调度模型**\n\n+ 值得注意的是，线程的调度不是跨平台的，是跟当前的操作系统有关的。在某些系统中，一个线程即使没有执行完，也没有遇到阻塞，一切正常也可能会自动让出CPU的使用权，给其它线程执行的机会。这就可能会让你觉得程序运行结果不符合抢占式调度模型。\n\n## Java实现多线程编程\n\nJava在语言层次上对多线程直接提供支持，顺带一提，Java语言对多线程的支持是建立在调用操作系统提供的API基础之上的，这也就是说为什么线程的调度不是跨平台的。\n\nJava语言实现多线程的方法有两种：一种是继承java.lang包中的Thread类；另一种是用户在自定义的类中实现Runnable接口。\n\n+ 由于Java语言支持多线程，所以只要发现程序中代码其实可以同时工作，那就可以创建一个独立于main()方法所在的主线程之外的新线程来同时进行工作。在一般情况下，如果执行程序的机器是单(核)处理器的话，那么其实程序的执行时间并不会因为并发而减少，只不过程序整体看上去执行效率更高，给人的感觉更好，这一点需要明确。\n\n### 利用Thread类的子类创建线程\n\nJava的基本类库中已定义了Thread这个基本类，其中内置了一组方法。利用这些方法可以去产生一个新的线程、执行一个线程、终止一个线程或让其消亡、查看线程的执行状态。下面是Thread类的一些常用方法：\n\n![Thread类的常用方法](https://cdn.jsdelivr.net/gh/shallowhui/cdn/img/thread/threadmethod01.png)\n\n![Thread类的常用方法](https://cdn.jsdelivr.net/gh/shallowhui/cdn/img/thread/threadmethod02.png)\n\n构造方法：\n\n![Thread类的构造](https://cdn.jsdelivr.net/gh/shallowhui/cdn/img/thread/threadcreate.png)\n\n**还有一个最重要的方法：**\n\n    pubic void run(); //线程要执行的任务\n\n简单来说，就是必须要完成下面两件事：\n\n1. 继承Thread类。\n\n2. 重写run()方法，将线程所要执行的代码写在run()方法内。\n\n+ 线程执行时，是从它的run()方法开始执行的。run()方法是线程执行的起点，就像main()方法是应用程序的执行起点，init()方法是小程序的执行起点一样。但我们在实际激活线程时，一般不直接调用run()方法，而是通过Thread类提供的start()方法来启动线程。\n\n#### 实例\n\n``` java\nclass myThread extends Thread{                          //继承Thread类\n    private String who;                                 //定义一个私有属性\n    public String getWho(){\n        return who;\n    }\n    public myThread(String who){\n        this.who=who;\n    }\n    public void run(){                                  //重写覆盖掉Thread类中的run()方法\n        for(int i=0;i<5;i++){\n            try{         //因为sleep()方法会抛出InterruptedException异常，所以要写在try-catch块里\n                sleep((int)(1000*Math.random()));       //1000*Math.random()会让线程随机休眠0~1s\n            }\n            catch(InterruptedException e){}\n            System.out.println(who+\"的线程正在执行!\");\n        }\n    }\n}\npublic class test{\n    public static void main(String[] args){\n        myThread you=new myThread(\"你\");\n        myThread she=new myThread(\"她\");\n        System.out.println(\"主线程的优先级为:\"+Thread.currentThread().getPriority()); //先获取主线程的线程对象，再获得主线程的优先级\n        System.out.println(you.getWho()+\"的线程优先级为:\"+you.getPriority());\n        System.out.println(she.getWho()+\"的线程优先级为:\"+she.getPriority());\n        you.start();                                  //启动线程\n        she.start();\n        for(int i=0;i<5;i++){\n            System.out.println(\"main()方法所在的主线程正在执行!\");\n        }\n    }\n}\n```\n\n运行结果：\n\n![继承Thread类](https://cdn.jsdelivr.net/gh/shallowhui/cdn/img/thread/Threadclass.png)\n\n可以看出，新创建的线程优先级默认都是5，跟主线程的优先级一样。我们注意到，main()方法里的输出主线程的循环语句是写在最后面的，但它在另外两个线程之前就输出了，前面两条start语句不是将两个线程都启动了吗？这是因为main()方法所在的主线程启动了两个线程之后，是继续往下执行，还是跳到那两个线程中执行，全看这三个线程谁先抢到了CPU的使用权。一般来说是会先往下执行的，因为主线程是早就启动了的，不用再经过线程激活的过程，可以轻易先取得CPU的使用权继续往下执行。不过这里主线程可以先执行完，主要原因是因为另外两个线程激活后就马上休眠了。主线程执行完后，那两个线程的执行就看谁的休眠时间短，谁就可以得到更多的CPU使用时间。\n\n每次运行的结果都可能不同，再运行一遍的结果：\n\n    主线程的优先级为:5\n    你的线程优先级为:5\n    她的线程优先级为:5\n    main()方法所在的主线程正在执行!\n    main()方法所在的主线程正在执行!\n    main()方法所在的主线程正在执行!\n    main()方法所在的主线程正在执行!\n    main()方法所在的主线程正在执行!\n    她的线程正在执行!\n    你的线程正在执行!\n    她的线程正在执行!\n    她的线程正在执行!\n    你的线程正在执行!\n    你的线程正在执行!\n    她的线程正在执行!\n    她的线程正在执行!\n    你的线程正在执行!\n    你的线程正在执行!\n\n通过让线程休眠的方式，我们看到了Java语言的线程调度模型是抢占式的。但其实去掉休眠语句，并且还把其中一个线程的优先级调到最高，会发现程序运行结果可能不是抢占式的：\n\n``` java\nclass myThread extends Thread{                          //继承Thread类\n    private String who;                                 //定义一个私有属性\n    public String getWho(){\n        return who;\n    }\n    public myThread(String who){\n        this.who=who;\n    }\n    public void run(){                                  //重写覆盖掉Thread类中的run()方法\n        for(int i=0;i<5;i++){\n            System.out.println(who+\"的线程正在执行!\");\n        }\n    }\n}\npublic class test{\n    public static void main(String[] args){\n        myThread you=new myThread(\"你\");\n        myThread she=new myThread(\"她\");\n        System.out.println(\"主线程的优先级为:\"+Thread.currentThread().getPriority()); //先获取主线程的线程对象，再获得主线程的优先级\n        you.setPriority(10);                          //将该线程设置为最高优先级\n        System.out.println(you.getWho()+\"的线程优先级为:\"+you.getPriority());\n        System.out.println(she.getWho()+\"的线程优先级为:\"+she.getPriority());\n        you.start();                                  //启动线程\n        she.start();\n        for(int i=0;i<5;i++){\n            System.out.println(\"main()方法所在的主线程正在执行!\");\n        }\n    }\n}\n```\n\n运行结果：\n\n    主线程的优先级为:5\n    你的线程优先级为:10\n    她的线程优先级为:5\n    main()方法所在的主线程正在执行!\n    main()方法所在的主线程正在执行!\n    main()方法所在的主线程正在执行!\n    你的线程正在执行!\n    你的线程正在执行!\n    你的线程正在执行!\n    main()方法所在的主线程正在执行!\n    main()方法所在的主线程正在执行!\n    她的线程正在执行!\n    你的线程正在执行!\n    她的线程正在执行!\n    她的线程正在执行!\n    你的线程正在执行!\n    她的线程正在执行!\n    她的线程正在执行!\n\n我们可以发现，最高优先级的线程在抢到CPU使用权后，并没有按照抢占式调度模型一直执行下去直到线程完成任务，执行完毕。而是会自动让出CPU的使用权，即使线程没有遇到问题。倒是因为没有让其它线程休眠，主线程还没执行完就被高优先级的线程抢走了CPU使用权。\n\n这并不用感到奇怪，前面就提到过，线程的调度是跟当前操作系统有关的。这篇博客的代码是在macOS上调试完成的，可能macOS的线程调度模式就是这样的，不用过于纠结这个。可能想深入理解并发编程的原理，还得深入理解计算机操作系统，了解操作系统是如何管理进程，线程的。\n\n### 利用Runnable接口来创建线程\n\n前面介绍了利用Thread类来创建线程，但如果一个类继承了其它的类，由于Java是不支持多继承的，这个类就无法再继承Thread类了。这种情况下，就可以通过实现Runnable接口来创建线程。Runnable接口是Java语言中实现线程的接口，定义在`java.lang`包中，其中只提供了一个run()抽象方法。实质上，Thread类就是实现了Runnable接口，并增加了一组线程的方法，其子类才具有创建线程的功能。\n\n但由于Runnable接口并没有任何对线程支持的方法，所以需要用到Thread类的一个构造方法`Thread(Runnable target)`或者其它构造方法，只要参数中有Runnable实现类对象，我们把Runnable接口实现类的对象称为可运行对象，只需要把这个可运行对象作为参数传递给Thread类的构造方法，就可以创建出一个线程。线程会自动调用接口实现类中的run()方法。\n\n#### 实例\n\n``` java\nclass myThread implements Runnable{                     //实现Runnable接口\n    private String who;                                 //定义一个私有属性\n    public String getWho(){\n        return who;\n    }\n    public myThread(String who){\n        this.who=who;\n    }\n    public void run(){                                  //重写覆盖掉run()方法\n        for(int i=0;i<5;i++){\n            try{\n                //由于没有继承Thread类，所以要通过Thread类调用其静态方法\n                Thread.sleep((int)(1000*Math.random()));\n            }\n            catch(InterruptedException e){}\n            System.out.println(who+\"的线程正在执行!\");\n        }\n    }\n}\npublic class test{\n    public static void main(String[] args){\n        //先创建可运行对象\n        myThread you=new myThread(\"你\");\n        myThread she=new myThread(\"她\");\n        //再通过可运行对象创建线程对象\n        Thread t1=new Thread(you);\n        Thread t2=new Thread(she);\n        System.out.println(\"主线程的优先级为:\"+Thread.currentThread().getPriority()); //先获取主线程的线程对象，再获得主线程的优先级\n        System.out.println(you.getWho()+\"的线程优先级为:\"+t1.getPriority());\n        System.out.println(she.getWho()+\"的线程优先级为:\"+t2.getPriority());\n        t1.start();                                  //启动线程\n        t2.start();\n        for(int i=0;i<5;i++){\n            System.out.println(\"main()方法所在的主线程正在执行!\");\n        }\n    }\n}\n```\n\n运行结果：\n\n    主线程的优先级为:5\n    你的线程优先级为:5\n    她的线程优先级为:5\n    main()方法所在的主线程正在执行!\n    main()方法所在的主线程正在执行!\n    main()方法所在的主线程正在执行!\n    main()方法所在的主线程正在执行!\n    main()方法所在的主线程正在执行!\n    她的线程正在执行!\n    她的线程正在执行!\n    她的线程正在执行!\n    你的线程正在执行!\n    她的线程正在执行!\n    她的线程正在执行!\n    你的线程正在执行!\n    你的线程正在执行!\n    你的线程正在执行!\n    你的线程正在执行!\n\n## 线程间的数据共享\n\n同一进程中的多个线程可以共享同一块内存区域，并可以利用这些共享单元来实现数据的交换，实时通信和必要的同步操作。\n\n### 通过继承Thread类实现数据共享\n\n``` java\nclass myThread extends Thread{        //继承Thread类\n    public myThread(String name){\n        super(name);                  //调用父类Thread类的一个构造方法，这样可以给线程对象起名字\n    }\n    public void run(){\n        for(int i=0;i<5;i++){\n            test.revoke();            //调用test类的静态方法对共享数据进行改动\n            System.out.println(getName()+\"执行了revoke()方法：total=\"+test.getTotal()); //getName()方法获得当前线程的名字\n        }\n    }\n}\npublic class test{\n    private static int total=10;      //定义一个模拟的共享数据\n    public static int getTotal(){\n        return total;\n    }\n    public static void revoke(){\n        total--;\n    }\n    public static void main(String[] args){\n        myThread t1=new myThread(\"一号线程\");\n        myThread t2=new myThread(\"二号线程\");\n        t1.start();                    //启动线程\n        t2.start();\n    }\n}\n```\n\n运行结果：\n\n    二号线程执行了revoke()方法：total=8\n    二号线程执行了revoke()方法：total=7\n    一号线程执行了revoke()方法：total=8\n    一号线程执行了revoke()方法：total=5\n    一号线程执行了revoke()方法：total=4\n    二号线程执行了revoke()方法：total=6\n    二号线程执行了revoke()方法：total=2\n    一号线程执行了revoke()方法：total=3\n    二号线程执行了revoke()方法：total=1\n    一号线程执行了revoke()方法：total=0\n\n### 通过实现Runnable接口来实现数据共享\n\n前面我们学会了通过创建Runnable接口实现类的可运行对象来创建线程，知道线程执行时会调用可运行对象里的run()方法。那么我们可以用同一个可运行对象创建多个线程，这样一来多个线程就共享同一个可运行对象里的数据了。\n\n``` java\nclass myThread implements Runnable{\n    private int tickes=10;               //定义一个模拟的共享数据\n    public void run(){\n        while(tickes>0){\n            System.out.println(Thread.currentThread().getName()+\"卖出了第\"+tickes+\"张票!\");\n            tickes--;\n        }\n    }\n}\npublic class test{\n    public static void main(String[] args){\n        myThread t=new myThread();              //先创建一个可运行对象\n        Thread t1=new Thread(t,\"一号窗口\");      //再用同一个可运行对象创建多个线程\n        Thread t2=new Thread(t,\"二号窗口\");\n        Thread t3=new Thread(t,\"三号窗口\");\n        t1.start();                             //启动线程\n        t2.start();\n        t3.start();\n    }\n}\n```\n\n运行结果：\n\n    二号窗口卖出了第10张票!\n    二号窗口卖出了第9张票!\n    三号窗口卖出了第10张票!\n    一号窗口卖出了第10张票!\n    一号窗口卖出了第6张票!\n    三号窗口卖出了第7张票!\n    二号窗口卖出了第8张票!\n    三号窗口卖出了第4张票!\n    一号窗口卖出了第5张票!\n    三号窗口卖出了第2张票!\n    二号窗口卖出了第3张票!\n    一号窗口卖出了第1张票!\n\n通过上面两个不同实现方法的例子，我们可以看出线程间实现了数据共享。但是都存在一个问题，即数据出现了脏读、重读。在第二个例子里，同一张票居然卖出多次，这在现实生活中就是一个很严重的bug了。我们可以这样理解：“二号窗口”线程读到了数据为10，输出10然后将数据改为9，准备把9写入到内存变量中的时候，“三号窗口”线程抢到了CPU的使用权或者“二号窗口“线程进入阻塞状态，这时候“三号窗口”线程去读内存里的变量，就还是没改变之前的10。这样就造成了数据的重读，接下来各个线程按照自己读到的数据去执行run()方法，就可能会出现各种各样的问题。\n\n**这些问题出现的根本原因就是并发的线程共享同一块内存区域造成的，要解决这些问题，就要引入线程间的同步控制。**\n\n## 多线程的同步控制\n\n我们再来看一个共享数据不安全的例子：\n\n``` java\nclass Mbank{                                  //定义一个银行的模拟类\n    private int sum=2000;                     //模拟银行余额作为线程间的共享数据\n    public void take(int x){                  //模拟银行取款的方法\n        sum-=x;\n        System.out.println(\"sum=\"+sum);       //余额减去取款数后输出余额\n    }\n}\nclass myThread extends Thread{                //继承Thread类\n    private static Mbank bank=new Mbank();    //实例化一个唯一的静态对象\n    public void run(){                        //重写覆盖run()方法\n        for(int i=0;i<5;i++){\n            try{\n                sleep(100);                   //让线程休眠\n            }\n            catch(InterruptedException e){}\n            bank.take(100);                   //调用Mbank类的静态方法对共享数据进行修改\n        }\n    }\n}\npublic class test{\n    public static void main(String[] args) {\n        myThread c1=new myThread();\n        myThread c2=new myThread();\n        c1.start();                           //启动两个线程\n        c2.start();\n    }\n}\n```\n\n运行结果：\n\n    sum=1800\n    sum=1800\n    sum=1600\n    sum=1600\n    sum=1400\n    sum=1400\n    sum=1300\n    sum=1300\n    sum=1200\n    sum=1100\n\n该程序的本意是两个线程分别调用5次Mbank类的静态取款方法， 这样一来，程序运行结果应该是余额递减输出，并且每次减100，最终余额应该为1000。\n\n要解决这样的问题，就必须要对线程进行同步控制。\n\n同步控制要保证，一个线程对数据的操作，不能被其它线程所打断，或修改结果被其它线程的修改结果覆盖掉，即线程间要“互斥”地运行。\n\n**Java中，利用了对象的“互斥锁”机制来实现线程间的互斥操作。“互斥”即一个线程在对一个对象中的共享资源进行访问时，它拿到了这个对象的“锁”，那其它线程就不可以再访问这个对象中被保护起来的共享资源，必须等有“锁”的线程执行完毕，释放掉“锁”。**\n\nJava语言中，使用`synchronized`关键字来标识特定的共享资源，以实现同步限制。这个关键字的功能就是：首先判断对象的互斥锁是否在，若在线程就获得对象的互斥锁，然后就可以访问特定的共享资源，如果不在，线程就进入等待，直到获得锁才能对特定的共享资源进行访问。\n\n+ 专业的说法是，这些共享的数据、资源，称为`临界资源`，而访问这些资源的代码，称为`临界区`代码。\n\n+ 一个普通类的实例化对象，在一个应用进程中来说，对所有线程都是可见的，也就是说所有线程共享这个资源。这个对象中可能还有一些属性，是线程间的共享数据，那为了保证数据的安全性，对象中那些对属性进行操作的方法、代码，本来是所有线程共享的资源，现在要对其进行同步限制。\n\n### Synchronized的使用方法\n\n**`synchronized`可以用来修饰一个方法或者一个代码块甚至一个类，能够保证在同一时刻最多只有一个线程执行该段代码。**\n\n我们来重写一下上面例子中的take()方法：\n\n``` java\npublic synchronized void take(int x){     //模拟银行取款的方法，并加上synchronized标记\n    sum-=x;\n    System.out.println(\"sum=\"+sum);       //余额减去取款数后输出余额\n}\n```\n\n运行结果：\n\n    sum=1900\n    sum=1800\n    sum=1700\n    sum=1600\n    sum=1500\n    sum=1400\n    sum=1300\n    sum=1200\n    sum=1100\n    sum=1000\n\n程序运行结果符合预期，可以说线程是安全的。这是因为我们用`synchronized`关键字修饰了take()方法，对其进行了同步限制，所以在一个线程，比如c1线程执行完take()方法之前，c2线程不能进入take()方法，执行代码对共享数据sum进行访问，从而避免了一个线程对共享数据的修改结果覆盖了另一线程对共享数据的修改结果。那么，共享的数据sum就应该要设置为`private`权限，不然的话，通过**对象名.属性名**就能访问到sum，这样对共享数据的保护就没有意义了。\n\n`synchronized`也可以这样用：\n\n``` java\npublic void take(int x){                  //模拟银行取款的方法\n    synchronized(this){                   //指定要锁定的对象，通常直接写this，后面接访问共享数据、需要互斥操作的代码块\n        sum-=x;\n        System.out.println(\"sum=\"+sum);   //余额减去取款数后输出余额\n    }\n}\n```\n\n运行结果跟上面一样。\n\n我们可以这样理解：c1线程获得了bank对象的锁之后，由于bank对象是静态的，属于Mbank类，所以是唯一的，那对象锁只有一个，c2线程只能等待锁被释放掉，才能去访问bank对象中被`synchronized`标记或者说保护起来的共享资源。\n\n那我们把bank对象的`static`去掉呢？\n\n``` java\nprivate Mbank bank=new Mbank();\n```\n\n运行结果：\n\n    sum=1900\n    sum=1900\n    sum=1800\n    sum=1800\n    sum=1700\n    sum=1700\n    sum=1600\n    sum=1600\n    sum=1500\n    sum=1500\n\n程序运行结果又不符合预期了，这是因为去掉了`static`之后，每创建一个线程对象，在线程对象内部又会各自实例化自己的bank对象，这样每个线程都拿到了bank对象的锁，但不是同一个bank对象的锁，而是自己的bank对象的锁。\n\n**所以，要理解“互斥锁”的含义，它锁的是一个实例化对象，一个对象只有一个自己的互斥锁，利用这种对锁的争夺，就可以实现不同线程间的互斥效果了。**\n\n除了对象锁之外，还有另一种类型的锁，即`类锁`，一般用于两个地方：\n\n1. `synchronized`用在类声明中，则表示该类中的所有方法都是synchronized的。\n\n2. 一般用于标记`static`方法，即类方法。static方法要么整个是synchronized的，要么整个不是synchronized的，不能是其中一段代码被标记为synchronized。\n\n### Synchronized的进一步说明\n\n1. 被`synchronized`标记的代码块或方法，在各个线程中就不是并发执行了，而是串行执行了，因为互斥锁机制。\n\n2. `synchronized`代码块中代码数量越少越好，包含的操作越少越好，因为没有锁的线程就不能执行这些操作，只能等待，白白浪费了CPU资源，这样就会丧失了多线程并发执行的性能优势。\n\n3. **同一个对象中的`非synchronized`方法或代码块，都还是可以自由调用。即使一个线程获得了这个对象的锁，其它线程还是能自由调用该对象的所有非synchronized方法和代码块。**\n\n4. **任何一个时刻，一个对象的互斥锁只能被一个线程拥有。只有当线程执行完它所调用的synchronized方法和代码之后，锁才会被释放掉。**\n\n5. synchronize代码中要访问的共享数据，应该要设为`private`，原因上面讲过。\n\n## 总结\n\n这篇博客简单讲解了一下并发编程的基本原理和实现方法，以及synchronized。事实上，Java不止一种同步控制的方法，synchronized只是一种在早期并发编程中解决同步问题的一种方法，但也需要我们去好好理解synchronized，才能进一步学习好并发编程。","tags":["并发编程"],"categories":["Java"]},{"title":"macOS下用zsh配置环境变量","url":"/posts/45668/","content":"## 前言\n\n这篇博客简单记录下如何在macOS下用zsh这个Shell配置环境变量，因为在mac配置环境变量容易被网上一些比较旧的教程带入坑，比windows要麻烦一些。同时也简单介绍一下Shell和Vim。\n\n## Shell\n\n首先我们简单了解一下，操作系统可以大致分为内核和外壳，Shell就是指外壳，英文意思就是“外壳、贝壳“。Shell就是操作系统内核与用户之间进行交互的”桥梁“，可以把它看成是一种解释命令的软件。比如windows下我们看到的桌面（explrer.exe），就是一层Shell，一种图形化的Shell，cmd（cmd.exe）是一种命令行式的Shell。\n\n那么就有多种Shell，就好像人不止一件衣服。你可以用下面这条命令看看macOS下有多少个Shell：\n\n``` bash\n$ cat /etc/shells\n```\n\n我们可以看到：\n\n![mac下的Shell](https://cdn.jsdelivr.net/gh/shallowhui/cdn/img/mac/shell.png)\n\n本来，Linux和macOS都是以bash作为默认的Shell，不过Apple官方宣布，macOS从`Catalina`这个大版本之后，把zsh作为默认的Shell。\n\n![Catalina](https://cdn.jsdelivr.net/gh/shallowhui/cdn/img/mac/catalina.png)\n\n这样一来，网上很多以bash作为默认Shell的配置环境变量的教程就过时了。\n\n## 以zsh配置环境变量\n\n网上很多教程说的mac有多个不同优先级的保存环境变量的文件。我试了下用zsh在.bash_profile文件保存环境变量，根本不能长久保存下来，每次打开zsh，上次保存的环境变量的路径就会消失。\n\n网上有关于这个问题的解释和解决办法，但我也不想继续麻烦下去了，直接用paths文件保存环境变量。paths文件的路径为：`/etc/paths`。这个路径是隐藏起来的，我们可以用`Command+Shift+.`组合键来显示隐藏目录。\n\npaths文件是系统级别的全局文件，对所有用户可见，系统启动时会自动加载。我们需要用sudo权限来编辑它。\n\n### Vim\n\nVim是一个远古时代的编辑器。\n\n我们用sudo命令编辑paths文件：\n\n``` bash\nsudo vim /etc/paths\n```\n\n输入电脑密码后：\n\n![vim](https://cdn.jsdelivr.net/gh/shallowhui/cdn/img/mac/vim.png)\n\n注意，这时我们要在英文输入法的状态下按一次`i`，这样Vim就会从命令模式转变为输入模式，即insert。\n\n![insert](https://cdn.jsdelivr.net/gh/shallowhui/cdn/img/mac/vim_insert.png)\n\n现在我们就可以输入我们要保存的环境变量了，注意一行一条路径。\n\n输入完后，我们按下ESC退出输入模式，然后还是在英文输入法状态下按下`Shift` + `;`键，会发现光标移动到了Shell最后一行的冒号后面，接着我们在后面输入命令：`wq`，意思是退出Vim并保存修改，最后按下Enter键就OK了。如果不能保存，试一下`!wq`强制保存命令。\n\n最后一步用下面的命令使paths文件的修改生效：\n\n``` bash\n$ source /etc/paths\n```\n\n我们可以用下面的命令查看系统环境变量是否添加成功：\n\n``` bash\n$ echo $PATH\n```\n\n## 小结\n\n由于Linux和macOS都是类Unix系统，Vim和Shell都是Linux的基础，这次配置环境的过程算是我开始接触Linux。","tags":["macOS"],"categories":["开发环境配置"]},{"title":"正则表达式","url":"/posts/46563/","content":"## 前言\n\n字符串是我们编程时涉及到的最多的一种数据结构，对字符串进行操作的需求几乎无处不在，比如我们使用[爬虫](https://zunhuier.top/posts/19580/)时需要在一大片的字符串中定位到我们所需要的数据以便提取数据；打开一个字符流，查找其中特定的内容；对用户输入进来的内容进行检验，防止SQL注入。\n\n正则表达式就是一种用来匹配字符串的强大武器，它的设计思想就是用一种描述性的语言给字符串定义了一个规则，凡是满足这个规则的字符串，我们就说它与这个正则表达式匹配了，否则就是不匹配的。\n\n许多编程语言都支持正则表达式，不同编程语言对正则表达式的支持也有些许不同，这里我用Java语言来实现正则表达式的功能。\n\n需要说明的是，正则表达式的功能非常强大，特性也非常丰富，一篇博客是讲不完的，只能入门正则表达式。如果需要经常与正则表达式打交道，最好还是常备一本正则表达式的参考书。是的，关于正则表达式可以写一本书出来。\n\n## Java中支持正则表达式的类库\n\n在java中，String类本身就提供了一个`matches`方法用来进行正则表达式的匹配，如下面的例子：\n\n``` java\npublic class Demo{\n    public static void main(String[] args){\n        String str = \"abc\";\n        System.out.println(str.matches(\"abc\")); //matches方法接收一个正则表达式作为参数，返回一个关于匹配结果的布尔值，true表示成功，false表示失败\n    }\n}\n```\n\n结果：\n\n    true\n\n+ matches方法进行的是全文本匹配，后文会讲到。\n\nJava还提供了一个支持正则表达式的类库：`java.util.regex`，其中主要包括三个类：\n\n1. Pattern类：pattern类的对象是一个正则表达式的编译表示。Pattern类没有公共构造方法。要创建一个Pattern对象，你必须首先调用其公共静态编译方法，它返回一个Pattern对象。该方法接受一个正则表达式作为它的第一个参数。\n\n2. Matcher类：matcher类的对象是对输入字符串进行解释和匹配操作的引擎。与Pattern类一样，matcher类也没有公共构造方法。你需要调用Pattern对象的matcher方法来获得一个Matcher对象。\n\n3. PatternSyntaxException类：是一个非强制异常类，它表示一个正则表达式模式中的语法错误。\n\n下面看一个例子：\n\n``` java\nimport java.util.regex.*; //导入类库\n\npublic class Demo{\n    public static void main(String[] args){\n        String context = \"abc-123\"; //待匹配的字符串\n        String re = \"\\\\w.*\\\\d\"; //正则表达式字符串，注意在java字符串中`\\`需要转义\n        Pattern p = Pattern.compile(re); //调用Pattern类的静态方法，编译正则表达式，获得pattern类对象\n        Matcher m = p.matcher(context); //获得匹配器对象\n        System.out.println(m.matches());\n    }\n}\n```\n\n+ Matcher类的对象的matches方法也是进行全文本匹配，返回一个布尔值。除此之外，匹配器对象还有需要重复调用以匹配内容符合规则的全部子串的find方法，以及提取分组匹配中内容符合规则的子串的group方法，这些在下面都会讲到。\n\n结果：\n\n    true\n\n+ 再重申一遍，由于正则表达式也是一个字符串，所以正则表达式中的特殊字符，如'\\\\'需要在java字符串中转义表示。\\w、\\d、*，等等是正则表达式的元字符，后文会讲到它们的作用。\n\n**下面开始讲解正则表达式**\n\n## 正则表达式是一个字符串\n\n>**从形式上看，正则表达式也是一个字符串，是一个描述规则的字符串，它规定了另一个符合这个规则的字符串中应该有什么内容，有什么样的内容，或者说另一个字符串中的某个子串的内容符合这个规则。使用正则表达式，就可以去匹配出一个字符串中的特定内容。**\n\n### 全文本匹配\n\n我们除了需要去匹配一个字符串中是否有特定内容，有时还希望去匹配整个字符串或者说文本（文本就是一行一行的字符串，有换行，但本质上就是一个字符串），看它是否符合我们正则表达式的规则，这时就需要对字符串进行全文本匹配。\n\n正则表达式中有两个特殊的定界符：`^`和`$`。\n\n^表示字符串开始的位置，$表示字符串结束的位置，如\"^a\"表示字符串必须以字符'a'开头，\"9$\"表示字符串必须以字符'9'结束。\n\n举个例子，我们假设区号+电话号是这样一种形式：123-12345678，即满足这样一个规则：必须以3个数字开头，中间以一个英文的破折号'-'分隔，再以8个数字结尾。我们可以写出正则表达式如下：\n\n    ^\\d{3}-\\d{8}$\n\n+ 关于这个正则表达式的元字符和限定符下面会讲。\n\n凡是用这个正则表达式去匹配成功的字符串，我们就可以认为它是合规的电话号码。如\"110-11079117\"是合规的，\"a110-12345678\"、\"110-12345678a\"、\"110+12345678\"、\"110-123456789\"等等都是不合规的。\n\n注意，java中的matches方法就是进行全文本匹配，不用再加这两个定界符了（单独的写全文本匹配的正则表达式才需要加），所以用matches方法进行匹配的字符串必须整体满足正则表达式的规则才能匹配成功。\n\n### 精确匹配\n\n比如我们有一个字符串：`\"I'am java, I love java.\"`，想要知道里面有没有`java`这个内容或者说子串，我们可以这样写java代码：\n\n``` java\nString context=\"I'am java, I love java.\"; //待匹配的字符串\nString re = \"java\"; //正则表达式字符串\nPattern p = Pattern.compile(re);\nMatcher m = p.matcher(context);\nwhile(m.find()){\n    System.out.print(\"起始位置：\"+m.start()); //start方法返回符合规则的子串的起始位置，注意字符串中的序号以0开始计数\n    System.out.print(\"------\"+m.group()+\"------\");\n    System.out.println(\"结束位置：\"+m.end()); //end方法返回符合规则的子串的结束位置加1\n}\n```\n\n+ 关于find方法：find方法通过循环调用，可以去遍历整个字符串，找出符合规则的全部内容或者说子串，每一次可以通过group()方法返回当前找到的符合规则的子串。find方法也可以进行全文本匹配，只需在正则表达式中加上两个定界符就可以了。group方法在后面分组匹配的时候再讲。\n\n这样可以匹配出两个结果：\n\n    起始位置：5------java------结束位置：9\n    起始位置：18------java------结束位置：22\n\n\n像`\"java\"`这样直接给出明确字符的正则表达式去匹配明确内容的情况，我们叫做精确匹配。\n\n### 模糊匹配\n\n精确匹配在实际应用中用处不大，因为String类本身就提供了equals方法实现了精确匹配的功能。而且大多数情况下，我们想要进行的是模糊匹配，也就是**可以匹配任意字符，也可以匹配限定任意个数的任意字符**。\n\n在模糊匹配下，我们只是给字符串设立了一个规则，在满足这个规则的前提下，我们匹配出的字符有多少个我们并不知道，比如上面那个电话号码的例子，我们可以重新设立必须以3~8个数字结尾的规则，那这样我们匹配成功的字符串，可能是以5个数字结尾的，也可能是以6个数字结尾的。\n\n这时候我们就需要使用正则表达式的元字符的功能。\n\n## 元字符\n\n我们需要一些特殊字符去匹配一个任意字符，下面列出一些常用的元字符和它们的功能：\n\n元字符 | 功能\n----- | ---\n\\ | 将后一个字符转义，例如，'n'匹配字符'n'，而'\\n'匹配一个换行符。'\\\\\\\\'匹配'\\\\'，'\\\\('则匹配 '('\n. | 匹配除换行回车符（\\n,\\r）之外的一个任意字符\n\\n | 匹配一个换行符\n\\r | 匹配一个回车符\n\\t | 匹配一个制表符\n\\d | 匹配一个任意的数字字符\n\\D | 匹配一个任意的非数字字符\n\\w | 即word，匹配一个任意的字母或数字或下划线字符\n\\W | 匹配一个任意的非字母、数字、下划线的字符\n\\s | 匹配一个任意的空白字符，包括空格，换行回车符，制表符等等\n\\S | 匹配一个任意的非空白字符\n\\un | 匹配一个Unicode字符，其中n由四位十六进制数组成\n\n**容易发现，元字符的大小写功能完全相反。** 我们可以用java代码测试一下这些元字符：\n\n待匹配的字符串：\n\n``` java\nString context = \"我I'am java, I love java, I'm 25.\";\n```\n\n不同的正则表达式（注意转义问题）：\n\n``` java\n...\nString re = \"我\"; //因为这里匹配的是中文，正则表达式也可以写成对应的Unicode字符编码\n...\nwhile(m.find()){\n    System.out.print(\"起始位置：\"+m.start());\n    System.out.print(\"------\"+m.group()+\"------\");\n    System.out.println(\"结束位置：\"+m.end());\n}\n\n/*\n    起始位置：0------我------结束位置：1\n*/\n```\n\n``` java\n...\nString re = \"\\\\n\";\n...\n\n/*\n    无匹配结果\n*/\n```\n\n``` java\n...\nString re = \"\\\\s\";\n...\n\n/*\n    起始位置：5------ ------结束位置：6\n    起始位置：11------ ------结束位置：12\n    起始位置：13------ ------结束位置：14\n    起始位置：18------ ------结束位置：19\n    起始位置：24------ ------结束位置：25\n    起始位置：28------ ------结束位置：29\n*/\n```\n\n\n\n``` java\n...\nString re = \"\\\\S\";\n...\n\n/*\n    起始位置：0------我------结束位置：1\n    起始位置：1------I------结束位置：2\n    起始位置：2------'------结束位置：3\n    起始位置：3------a------结束位置：4\n    起始位置：4------m------结束位置：5\n    起始位置：6------j------结束位置：7\n    起始位置：7------a------结束位置：8\n    起始位置：8------v------结束位置：9\n    起始位置：9------a------结束位置：10\n    起始位置：10------,------结束位置：11\n    起始位置：12------I------结束位置：13\n    起始位置：14------l------结束位置：15\n    起始位置：15------o------结束位置：16\n    起始位置：16------v------结束位置：17\n    起始位置：17------e------结束位置：18\n    起始位置：19------j------结束位置：20\n    起始位置：20------a------结束位置：21\n    起始位置：21------v------结束位置：22\n    起始位置：22------a------结束位置：23\n    起始位置：23------,------结束位置：24\n    起始位置：25------I------结束位置：26\n    起始位置：26------'------结束位置：27\n    起始位置：27------m------结束位置：28\n    起始位置：29------2------结束位置：30\n    起始位置：30------5------结束位置：31\n    起始位置：31------.------结束位置：32\n*/\n```\n\n``` java\n...\nString re = \"\\\\w\";\n...\n\n/*\n    起始位置：1------I------结束位置：2\n    起始位置：3------a------结束位置：4\n    起始位置：4------m------结束位置：5\n    起始位置：6------j------结束位置：7\n    起始位置：7------a------结束位置：8\n    起始位置：8------v------结束位置：9\n    起始位置：9------a------结束位置：10\n    起始位置：12------I------结束位置：13\n    起始位置：14------l------结束位置：15\n    起始位置：15------o------结束位置：16\n    起始位置：16------v------结束位置：17\n    起始位置：17------e------结束位置：18\n    起始位置：19------j------结束位置：20\n    起始位置：20------a------结束位置：21\n    起始位置：21------v------结束位置：22\n    起始位置：22------a------结束位置：23\n    起始位置：25------I------结束位置：26\n    起始位置：27------m------结束位置：28\n    起始位置：29------2------结束位置：30\n    起始位置：30------5------结束位置：31\n*/\n```\n\n``` java\n...\nString re = \"\\\\d\";\n...\n\n/*\n    起始位置：29------2------结束位置：30\n    起始位置：30------5------结束位置：31\n*/\n```\n\n### 匹配指定范围的字符\n\n正则表达式中有一类特殊的元字符，它可以用来匹配指定范围的字符，形式为：`[xyz]`。\n\n**`[xyz]`表示一个字符集合，匹配其所包含的任意一个字符。它还有一种不包含的写法，如`[^x]`，匹配除字符x之外的任意一个字符**\n\n例如，`[abcdef]`可以匹配出\"apple\"中的'a'和'e'，`[123456789]`可以匹配出任意一个其中包含的数字字符，即1~9。\n\n但是这样把要匹配的字符一个一个写进去太麻烦了，有一些常用的简便写法如下：\n\n匹配范围 | 功能\n------- | ---\n[0-9] | 匹配一个0~9的数字字符，等价于元字符'\\d'\n\\[^0-9] | 匹配一个非0~9的任意字符，等价于'\\D'\n[a-z] | 匹配一个任意的小写字母字符\n[A-Z] | 匹配一个任意的大写字母字符\n\\[^a-z] | 匹配一个任意的非小写字母的字符\n[a-zA-Z0-9_] | 匹配一个小写或大写字母字符或数字字符或下划线，等价于'\\w'\n\n我们还是用上面的待匹配字符串测试一下：\n\n``` java\n...\nString re = \"[aj]\";\n...\n\n/*\n    起始位置：3------a------结束位置：4\n    起始位置：6------j------结束位置：7\n    起始位置：7------a------结束位置：8\n    起始位置：9------a------结束位置：10\n    起始位置：19------j------结束位置：20\n    起始位置：20------a------结束位置：21\n    起始位置：22------a------结束位置：23\n*/\n```\n\n``` java\n...\nString re=\"[0-9]\";\n...\n\n/*\n    起始位置：29------2------结束位置：30\n    起始位置：30------5------结束位置：31\n*/\n```\n\n### 限定符\n\n前面写的正则表达式中，不管是明确的字符'a'，还是元字符'\\w'，它们在表达式中出现一次就代表匹配一次，在匹配成功出来的内容或者说子串中出现一次这个字符。例如，表达式\"a\\wc\"，代表要匹配出的内容中有3个字符，可能是\"abc\"或者\"a6c\"或者\"a_c\"，这些字符串都符合规则。\n\n还有一类特殊的元字符，可以用来指定正则表达式中前一个字符或者子表达式的匹配次数，有下面三种：\n\n限定符 | 功能\n----- | ---\n\\* | 匹配前面的一个字符或子表达式零次或多次。例如，\"zo*\"能匹配出\"z\"、\"zo\"以及\"zoooooo\"\n? | 匹配前面的一个字符或子表达式零次或一次。例如，\"do(es)?\"可以匹配出\"do\"或\"does\"\n\\+ | 匹配前面的一个字符或子表达式一次或多次。例如，\"zo+\"能匹配出\"zo\"以及\"zoo\"，但不能匹配出\"z\"，即至少匹配一次\n\n我们还是用上面的待匹配字符串测试一下：\n\n``` java\n...\nString re = \"\\\\w+\";\n...\n\n/*\n    起始位置：1------I------结束位置：2\n    起始位置：3------am------结束位置：5\n    起始位置：6------java------结束位置：10\n    起始位置：12------I------结束位置：13\n    起始位置：14------love------结束位置：18\n    起始位置：19------java------结束位置：23\n    起始位置：25------I------结束位置：26\n    起始位置：27------m------结束位置：28\n    起始位置：29------25------结束位置：31\n*/\n```\n\n+ 可以看出跟上面单独一个正则表达式`\\w`的例子匹配出来的结果不同，这里相当于把字符串切分了（忽略中文）。没错，你可能已经联想到了，正则表达式还可以用来切分字符串，而且比一般编程语言里面自带的切分字符串的方法更加强大，灵活。这里只是简单提一下，这篇博客并不会深入去讲。\n\n限定符还有另外一种写法，形式如下面几种：\n\n限定符 | 功能\n----- | ---\n{n} | n是一个非负整数，匹配前面的一个字符或子表达式n次\n{n,} | 匹配前面的一个字符或子表达式n次或多次，即至少匹配n次\n{n,m} | m和n均为非负整数，其中n<=m。匹配前面的一个字符或子表达式最少n次，最多m次\n{1,} | 等价于限定符 +\n{0,1} | 等价于 ？\n{0,} | 等价于 *\n\n我们还是用上面的待匹配字符串测试一下：\n\n``` java\n...\nString re = \"\\\\d{0,}\";\n...\n\n/*\n    起始位置：0------------结束位置：0\n    起始位置：1------------结束位置：1\n    起始位置：2------------结束位置：2\n    起始位置：3------------结束位置：3\n    起始位置：4------------结束位置：4\n    起始位置：5------------结束位置：5\n    起始位置：6------------结束位置：6\n    起始位置：7------------结束位置：7\n    起始位置：8------------结束位置：8\n    起始位置：9------------结束位置：9\n    起始位置：10------------结束位置：10\n    起始位置：11------------结束位置：11\n    起始位置：12------------结束位置：12\n    起始位置：13------------结束位置：13\n    起始位置：14------------结束位置：14\n    起始位置：15------------结束位置：15\n    起始位置：16------------结束位置：16\n    起始位置：17------------结束位置：17\n    起始位置：18------------结束位置：18\n    起始位置：19------------结束位置：19\n    起始位置：20------------结束位置：20\n    起始位置：21------------结束位置：21\n    起始位置：22------------结束位置：22\n    起始位置：23------------结束位置：23\n    起始位置：24------------结束位置：24\n    起始位置：25------------结束位置：25\n    起始位置：26------------结束位置：26\n    起始位置：27------------结束位置：27\n    起始位置：28------------结束位置：28\n    起始位置：29------25------结束位置：31\n    起始位置：31------------结束位置：31\n    起始位置：32------------结束位置：32\n*/\n```\n\n+ 这里匹配出许多空字符，是因为`{0,}`就相当于`*`，两者都可以指定匹配前面的一个字符或子表达式零次或多次。所以在字符串中，遇到非数字字符，就相当于正则表达式用`\\d`匹配了零次，这种规则下当然就匹配出了空字符，也当成结果返回。\n\n## 贪婪匹配和非贪婪匹配\n\n### 贪婪匹配\n\n在上面的一个例子中，正则表达式`\\w+`相当于把字符串切分了，从这里可以看出，在正则表达式中，在一个字符或子表达式后面加上限定符后，默认进行的是贪婪匹配，也就是说，在这个例子的匹配的过程中，正则表达式遇到一个`\\w`代表的字符后，其实它已经满足了限定符`+`指定的至少一次的匹配次数，但它还不满足，想要继续匹配下去，直到遇到非字母，非数字，非下划线的字符才停止这次匹配。之后它会跳过这些不符合规则的字符，去后面继续匹配出符合规则的字符。所以这就是为什么，这个例子中的字符串看上去是以空格、逗号进行切分的。\n\n我们还是以`我I'am java, I love java, I'm 25.`这个字符串进行举例：\n\n``` java\n...\nString re = \".*java\";\n...\n\n/*\n    起始位置：0------我I'am java, I love java------结束位置：23\n*/\n```\n\n+ 可以看出，即使中间已经出现了java这个字符串，前面也是符合`.*`的字符串，也就是说`我I'am java`这个子串已经符合正则表达式的规则了。但它还是会继续匹配下去，直到匹配出最后一个java字符串为止，因为`我I'am java, I love java`这个子串也符合规则，那它就要“贪婪“一点。\n\n**贪婪匹配就是尽可能多的匹配出符合规则的内容。**\n\n### 非贪婪匹配\n\n**非贪婪匹配也称惰性匹配，只要在一个限定符后面加上一个`?`就可以进行惰性匹配了。**\n\n我们还是以`我I'am java, I love java, I'm 25.`这个字符串进行举例：\n\n``` java\n...\nString re = \".*?java\";\n...\n\n/*\n    起始位置：0------我I'am java------结束位置：10\n    起始位置：10------, I love java------结束位置：23\n*/\n```\n+ 可以看出，非贪婪匹配只要匹配出了符合规则的内容就进行返回，即去匹配尽可能少的内容。\n\n## 分组匹配\n\n**`()`在正则表达式中有一个重要的作用，就是进行分组匹配。分组匹配的功能就是在一个匹配出的符合正则表达式规则的字符串中，提取特定子串出来。**\n\n+ 在java中，通过`Matcher.group(index)`方法提取子串：\n    + group()与group(0)等价，返回的是整个正则表达式匹配出的内容\n    + group(i)返回的是正则表达式中从左往右数第i个分组里的内容\n    + 分组就是正则表达式中用`()`括起来的子表达式\n\n我们来看下面两个例子：\n\n``` java\npublic class Demo{\n    public static void main(String[] args){\n        String context=\"<a href=\\\"zunhuier.club\\\">zunhuier's</a>...<a href=\\\"http://zunhuier.club\\\">博客</a>\";\n        String re = \"<a href=\\\"(.*?)\\\">(.*?)</a>\";\n        Pattern p = Pattern.compile(re);\n        Matcher m = p.matcher(context);\n        while(m.find()){\n            System.out.print(\"起始位置：\"+m.start());\n            System.out.print(\"------\"+m.group(0)+\"------\");\n            System.out.println(\"结束位置：\"+m.end());\n        }\n    }\n}\n\n/*\n    起始位置：0------<a href=\"zunhuier.club\">zunhuier's</a>------结束位置：38\n    起始位置：41------<a href=\"http://zunhuier.club\">博客</a>------结束位置：78\n*/\n```\n\n``` java\npublic class Demo{\n    public static void main(String[] args){\n        String context=\"<a href=\\\"zunhuier.club\\\">zunhuier's</a>...<a href=\\\"http://zunhuier.club\\\">博客</a>\";\n        String re = \"<a href=\\\"(.*?)\\\">(.*?)</a>\";\n        Pattern p = Pattern.compile(re);\n        Matcher m = p.matcher(context);\n        while(m.find()){\n            for(int i=1;i<=m.groupCount();i++){ //groupCount方法返回正则表达式中的分组个数\n                System.out.print(\"起始位置：\"+m.start());\n                System.out.print(\"------\"+m.group(i)+\"------\");\n                System.out.print(\"结束位置：\"+m.end());\n                System.out.print(\"      \");\n            }\n            System.out.println();\n        }\n    }\n}\n\n/*\n    起始位置：0------zunhuier.club------结束位置：38      起始位置：0------zunhuier's------结束位置：38      \n    起始位置：41------http://zunhuier.club------结束位置：78      起始位置：41------博客------结束位置：78\n*/\n```\n\n## 总结\n\n正则表达式非常强大，在一篇博客中是讲不完的，这篇博客只是简单的入门正则表达式。我们只需记住正则表达式可以用来匹配字符串中的特定内容就行了。\n\n## 在线正则表达式测试网站\n\n这里推荐一个正则表达式的在线测试[网站](https://regexr.com)：\n\n![在线正则表达式测试](https://cdn.jsdelivr.net/gh/shallowhui/cdn/img/regularexpression/reonline.png)","tags":["正则表达式"],"categories":["Java"]},{"title":"Python的高级特性","url":"/posts/64035/","content":"## 函数的嵌套定义\n\nPython函数可以嵌套定义，即在函数体内再定义另一个函数。嵌套函数的定义形式与普通函数一样，只是要位于一个函数的函数体内。\n\n### 示例\n\n``` python\ndef outer():\n    def inner():\n        print(\"inner function\")\n    print(\"outer function\")\n```\n\n**被嵌套函数不会随着外部函数的执行而自动执行，例如：**\n\n``` python\nouter()\n```\n\n输出：\n\n    outer function\n\n**要执行被嵌套函数，需要在外部函数的函数体内显式地调用被嵌套函数：**\n\n``` python\ndef outer():\n    def inner():\n        print(\"inner function\")\n    inner() #显式地调用被嵌套函数\n    print(\"outer function\")\n```\n\n调用外部函数：\n\n``` python\nouter()\n```\n\n输出：\n\n    inner function\n    outer function\n\n## Python的装饰器\n\n### 定义\n\n嵌套函数的一个重要应用就是装饰器。装饰器也是一个函数，它接收其它函数作为参数，在此函数的基础上增加一些功能作为装饰，最后返回一个新函数。\n\n### 示例\n\n例如，我们有一个普通函数，它负责完成某项功能：\n\n``` python\ndef main():\n    print(\"主要功能\")\n```\n\n直接去调用它：\n\n``` python\nmain()\n```\n\n只会输出：\n\n    主要功能\n\n我们可以写一个装饰器函数，来为main函数添加一些新的功能，比如输出main函数的调用时间：\n\n``` python\nimport time # 导入时间模块\n\ndef decorator(fun): #装饰器函数接收一个函数作为参数\n    def wrapper(*args,**kwargs): # 不定长参数的写法，*表示接收若干个参数作为一个元组传给形参args，**表示接收若干个类似键值对的参数作为一个字典传给形参kwargs\n        print(\"前装饰：\",time.ctime()) #作日志记录\n        result=fun(*args,**kwargs) #执行被装饰的函数，结果作为result保存\n        print(\"后装饰\")\n        return result #返回被装饰函数的执行结果\n    return wrapper #返回装饰后的新函数\n```\n\n用装饰器来装饰函数：\n\n``` python\n@decorator\ndef main():\n    print(\"主要功能\")\n```\n\n+ 在普通函数前面加上`@装饰器函数名`就可以使用该装饰器了，这样普通函数就变成了装饰后的新函数，函数名不变，调用函数的方法与原来一样。\n\n调用新函数：\n\n``` python\nmain()\n```\n\n结果：\n\n    前装饰：Mon Apr 6 13:14:20 2020\n    主要功能\n    后装饰\n\n### 应用\n\n装饰器是一种高级编程方法，常见于框架/架构等大型系统内，可用于日志/授权/性能测试等方面。装饰器的作用就是为已经存在的函数对象添加额外的功能。一般出于安全性考虑，不允许修改原来存在的函数代码，就可以用装饰器来实现功能的拓展。\n\n## Python的生成器\n\n### 关键字——yield\n\n生成器也是一种函数，是一种内含yield语句的特殊函数，用于创建生成器对象。\n\n### 生成器应用\n\n例如，如果需要产生一亿个数据，普通函数就需要将这一亿个数据都生成出来并返回，这样内存消耗巨大。而使用生成器对象生成数据，可以每次只生成一个数据，处理完后通过迭代再生成下一个数据，这样就节省内存。\n\n### 生成器对象的特点\n\n1. 惰性机制：生成器对象创建出来后本身并没有数据，需要通过迭代去一个一个地生成数据。\n2. 只能向前：生成器对象只能向前迭代，例如已经生成了1，2，3这3个数据，就不能再重新生成1，2，3。\n3. 节省内存。\n\n### 示例一\n\n我们写一个生成器函数并迭代输出它：\n\n``` python\ndef g(): #生成器函数\n    a=1\n    while True:\n        yield a\n        a=a+2\n\nc=g() #创建生成器对象\nprint(next(c))\nprint(next(c))\nprint(next(c))\n```\n\n+ yield语句的作用就是返回一个值并暂停生成器函数的执行，只有下次通过内置函数next或for循环来迭代生成器对象时再恢复执行，并且是从yield语句的下一条语句继续执行。由于这个示例的生成器函数里的循环条件为True，那么生成器对象可以无限迭代下去，生成无穷多个数据。\n\n输出结果：\n\n    1\n    3\n    5\n\n### 示例二\n\n我们经常使用的for循环语句`for x in range(n)`中的range函数也可以创建一个迭代对象，但请注意它不是生成器函数。range函数可以接收3个参数range(m,n,q)，作用是生成[m,n)范围内的数据，数据间隔或者说步长为整型q。我们可以使用生成器来重写range函数，使其具有浮点步长：\n\n``` python\ndef range2(m,n,q): #生成器函数\n    while m<n:\n        yield m\n        m=m+q\n\nfor x in range2(1,5,0.5): #通过for循环来迭代生成器对象\n    print(x,end=' ')\n```\n\n输出结果：\n\n    1 1.5 2.0 2.5 3.0 3.5 4.0 4.5\n\n### 注意\n\n生成器创建的生成器对象，一旦被迭代完毕，即这个对象所能生成的数据都生成完了，那么该对象就被消耗完了，继续迭代该对象不会再生成任何数据，就不会有任何输出了。如果还想继续使用这个生成器，就需要重新创建生成器对象。\n\n## 列表生成式\n\n列表生成式即List Comprehensions，是生成器的另一种创建方式，以表达式进行创建。\n\n例如，要生成list`[1,2,3,4,5,6]`，我们可以使用一个迭代对象来生成list：\n\n``` python\nlist(range(1,7))\n```\n\n结果：\n\n    [1,2,3,4,5,6]\n\n但如果我们要生成list`[1,2,3,4,5,6]^2`，即列表里的每个元素变成平方值，我们该如何做？\n\n我们可以使用强大的列表生成式：\n\n``` python\nx=[x**2 for x in range(1,7)]\nprint(x)\n```\n\n+ 写列表生成式时，把要生成的元素的表达式写在前面，后面跟个for循环，就可以把list创建出来了。\n\n结果：\n\n    [1,4,9,16,25,36]\n\n我们还可以继续在列表生成式后面加上if判断：\n\n``` python\nx=[x**2 for x in range(1,7) if x%2==0]\nprint(x)\n```\n\n+ 这样就可以仅生成偶数的平方。if仅作为筛选条件，后面不能再跟else。\n\n结果：\n\n    [4,16,36]\n\n还可以通过循环嵌套来进行排列组合，例如：\n\n``` python\nx=[m+n for m in 'ABC' for n in 'XYZ']\nprint(x)\n```\n\n结果：\n\n    ['AX', 'AY', 'AZ', 'BX', 'BY', 'BZ', 'CX', 'CY', 'CZ']\n\nfor循环中还可以使用两个变量来生成list：\n\n``` python\nd={1:'A',2:'B',3:'C'} #先创建一个字典\nx=[str(key)+'='+value for key,value in d.items()]\nprint(x)\n```\n\n结果：\n\n    ['1=A', '2=B', '3=C']","tags":["Python高级"],"categories":["Python"]},{"title":"Lambda表达式","url":"/posts/34313/","content":"## lambda表达式\n\n通常我们在写程序的时候都要写很多函数，这些函数都有自己的名字，我们称为普通函数。但有时候我们可能只需要使用一个函数一次，在这种情况下，就无需正式定义一个普通函数，可以用lambda表达式定义一个匿名函数。lambda表达式不仅仅在Python中有，在其它很多编程语言，如Java，C#中都是存在的。\n\n## lambda表达式的格式\n\n``` python\nlambda 形参 : 返回值表达式\n```\n**lambda表达式就是将接收进来的参数经过一个表达式的运算后，运算结果作为返回值返回。**\n\n特别地，为了函数定义的方便，也可以将lambda表达式变成命名函数，格式如下：\n\n``` python\n函数名 = lambda 形参 : 返回值表达式\n```\n\n这样就可以像普通函数一样通过函数名去多次调用函数。\n\n**注意，lambda表达式形式简单，只支持单条语句，不支持选择和循环结构。**\n\n## 示例\n\n我们写一个简单的排序程序，希望通过列表里的元素的平方值进行排序。\n\n通常我们先定义一个普通函数：\n\n``` python\nfrom random import randint,seed #引入随机数模块\n\ndef square(x):\n    return x**2\n\nseed(1) #将随机数种子设为1，这样每次随机出来的数相同\na=[randint(-10,10) for _ in range(10)] #列表生成式生成随机数列表\nprint('排序前:',a)\na.sort(key=square) #将排序的依据设为数据的平方值\nprint('排序后:',a)\n```\n结果为：\n\n    排序前:[-6,8,-8,-2,-7,5,4,5,10,2]\n    排序后:[-2,2,4,5,5,-6,-7,8,-8,10]\n\nsquare这个函数只使用了一次，我们可以通过lambda表达式改写程序：\n\n``` python\na.sort(key=lambda x:x**2) #lambda表达式让程序更加简洁\n```\n\n结果一样：\n\n    排序前:[-6,8,-8,-2,-7,5,4,5,10,2]\n    排序后:[-2,2,4,5,5,-6,-7,8,-8,10]","tags":["Lambda表达式"],"categories":["Python"]},{"title":"windows下MySQL常见问题解决","url":"/posts/2584/","content":"*我们在日常开发中，使用MySQL总会遇到各种各样的问题，这篇博客就记录总结一下windows系统下MySQL常见的问题和解决方法。*\n\n## Community Server安装常见问题\n\n### 下载\n\n[官网](https://dev.mysql.com/downloads/)下载社区版服务，也可以去[清华镜像站](https://mirrors.tuna.tsinghua.edu.cn/mysql/)下载。安装方式有两种：MSI安装和ZIP解压缩到指定目录。\n\n### 配置\n\n>**MySQL Community Server是MySQL的开源版本，其就是我们常用的数据库版本，已经是一个完整的数据库服务器了。MySQL Installer提供了Server及其它组件的安装，是MySQL集成的一个安装工具。推荐下载Installer，这样就不用进行下面的配置，因为在安装程序安装的时候都搞定了。这里就是要解决仅安装Server时遇到的一些问题。**\n\n网上的资料说MySQL Server 5.7之后的版本都默认安装目录下不存在my.ini文件和data文件夹。那么需要我们自己创建。\n\n![MySQL安装目录](https://cdn.jsdelivr.net/gh/shallowhui/cdn/img/mysql/mysqlcata.png)\n\n**首先要把MySQL安装目录下的bin目录添加到系统环境变量中，因为后面会在cmd中用到MySQL自带的命令。**\n\n关于my.ini文件，是MySQL的一个配置文件，无非就是配置一些参数，如端口号，最大连接数，创建数据库时的编码格式等等。这些MySQL都是有默认配置的，也可以通过命令在MySQL中自定义配置，my.ini的作用就是将命令配置持久保存下来，所以这个文件有没有都影响不大。如果你需要自己配置MySQL参数并保存，可以在安装目录下新建一个my.ini文件，填入以下参数，注意目录路径要填自己实际的路径：\n\n    [mysql]\n    # 设置mysql客户端默认字符集\n    default-character-set=utf8\n    [mysqld]\n    #设置3306端口\n    port=3306\n    # 设置mysql的安装目录\n    basedir=D:\\Program Files\\MySQL\\\n    # 设置mysql数据库的数据的存放目录\n    datadir=D:\\Program Files\\MySQL\\data\n    # 允许最大连接数\n    max_connections=200\n    # 服务端使用的字符集默认为8比特编码的latin1字符集\n    character-set-server=utf8\n    # 创建新表时将使用的默认存储引擎\n    default-storage-engine=INNODB\n\n+ 用ANSI编码格式（记事本默认格式）保存为my.ini，存放在MySQL安装目录下。\n\n重点是data文件夹的创建，一定不能手动创建，要通过MySQL的命令创建，有以下两种方式：\n\n**第一种方式会为root账号随机生成一个密码：**\n\n``` bash\n> mysqld --initialize\n```\n等待一会，没有提示即为创建成功data文件夹，随机密码在data文件夹下的xxx.err文件中，打开这个文件找到：\n\n    2020-03-28T10:01:52.840136Z 1 [Note] A temporary password is generated for root@localhost: i?nEs.svL4QL\n\n其中`i?nEs.svL4QL`就是随机生成的密码。\n\n**第二种方式不会为root账号生成随机密码，默认为空：**\n\n``` bash\n> mysqld --initialize-insecure\n```\n\n创建好data文件夹后，就添加MySQL服务到服务进程中：\n\n``` bash\n> mysqld -install\n> # mysqld -remove # 移除服务\n```\n\n启动服务：\n\n``` bash\n> net start mysql #需要以管理员的身份打开cmd\n> # net stop mysql # 关闭服务\n```\n\n+ MySQL的服务名（mysql）可能不一样，要到你自己的电脑服务进程中查看\n\n**MySQL服务启动成功后，我们就可以登录MySQL，使用数据库了^_^**\n\n### 修改密码\n\n以root账号登录MySQL后，可以通过下面的命令修改密码：\n\n``` bash\nmysql> ALTER USER 'root'@'localhost' IDENTIFIED BY '重设密码';\n```\n\n## 编码问题\n\n我们在使用数据库驱动连接到数据库，进行SQL语句查询时，经常会遇到一些编码格式的问题，比如用insert语句插入一条带有中文的记录，在数据库中中文会显示为`???`，明显编码格式错误。\n\n首先要确保数据库是utf-8编码格式的，可以用下面这条SQL语句创建数据库：\n\n``` bash\nmysql> CREATE DATABASE 数据库名 DEFAULT CHARACTER SET utf8 COLLATE utf8_general_ci;\n```\n\n然后在程序中修改数据库驱动连接：\n\n    jdbc:mysql://localhost:3306/数据库名?useUnicode=true&characterEncoding=utf8\n\n注意，如果是在xml文件中配置数据库驱动连接的话，这句话要写成：\n\n    jdbc:mysql://localhost:3306/数据库名?useUnicode=true&amp;characterEncoding=utf8\n\n这是xml的语法规定的，`&amp;`是转义字符，相当于&。\n\n## useSSL问题\n\n我们在Web应用中连接到较高版本的MySQL数据库时，可能会遇到以下警告：\n\n    WARN:Establishing SSL connection without server’s identity verification is not recommended. According to MySQL 5.5.45+,5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn’t set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to ‘false’. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.\n\n原因是连接高版本的MySQL时需要指明是否建立SSL连接，实测MySQL Server 5.7.29需要指明。\n\n解决方法是添加连接参数：\n\n    jdbc:mysql://localhost:3306/数据库名?useSSL=false\n\n一般填false，不建议在没有服务器身份验证的情况下建立SSL连接。\n\n## 命令行下备份还原数据库\n\n备份先不用登录mysql，直接在命令行下执行命令，还原才需要先登录mysql。\n\n### 备份\n\n备份使用的是`mysqldump`命令，命令格式如下：\n\n``` bash\n> mysqldump [远程服务器地址] -u用户名 -p密码 [-P端口号] 数据库名 [表名] > 备份路径\n```\n\n+ 这里[ ]括起来是可以省略的意思。\n\n比如，备份一个本机的名为spring的数据库到D盘下，可以这样写命令：\n\n``` bash\n> mysqldump -uroot -p888888 spring > d:\\spring.sql\n```\n\n### 还原\n\n从上面可以知道，命令行备份数据库保存的是数据库完整的SQL脚本，还原就是要执行这个脚本，使用如下的`source`命令：\n\n``` bash\nmysql> source SQL脚本路径\n```\n\n+ 如果备份完后就把数据库删了，那么还原之前要先重新创建数据库，并use它，再执行还原命令。\n\n比如，还原spring数据库：\n\n``` bash\nmysql> source d:\\spring.sql\n```\n\n## 未完待续\n","tags":["windowss"],"categories":["MySQL"]},{"title":"Python爬虫","url":"/posts/19580/","content":"## 网络爬虫简介\n\n网络爬虫又称网络蜘蛛、网络蚂蚁、网络机器人等，可以自动化浏览网络中的信息，也可以自动化收集数据。当然这需要按照我们制定的规则进行，这些规则我们称之为网络爬虫算法。\n\n例如搜索引擎离不开爬虫，百度搜索引擎的爬虫叫作百度蜘蛛（Baiduspider）。百度蜘蛛每天会在海量的互联网信息中进行爬取，爬取优质信息并收录，当用户在百度搜索引擎上检索对应关键词时，百度将对关键词进行分析处理，从收录的网页中找出相关网页，按照一定的排名规则进行排序并将结果展现给用户。\n\n## 为什么选择Python\n\n### 使网络爬虫的编写变得简单\n\n网络爬虫一个广泛的定义就是它可以模拟人的行为去浏览网页，那么python提供了功能强大的库来帮助我们模拟人的行为去访问服务器、浏览网页，如requests模块。另外python也对文本处理，数据分析等功能有着大量功能强大的库进行支持。最重要的就是python语法简单，适合新手入门^_^\n\n### 网络爬虫开发的前期准备\n\n用python来开发当然要安装python开发环境，编写程序可以用python自带的IDLE或者其它IDE如Anaconda、Pycharm等等都可以，本篇博客使用的是VS Code。安装好了python开发环境后首先就要下载安装requests模块：\n\n+ 使用pip进行安装：\n\n``` bash\n$ pip install requests\n```\n\n如果下载速度慢，下载站点可以使用国内的清华镜像站：\n\n``` bash\n$ pip install -i https://pypi.tuna.tsinghua.edu.cn/simple requests\n```\n\n下面我们就来用面向过程的方法进行一个python原生爬虫的小项目实战开发——爬取网络小说的章节目录。\n\n## Python原生爬虫的开发\n\n### 导入所需模块\n\n``` python\nimport requests\nimport re #python中自带的对正则表达式支持的库\n```\n\n### 模拟请求，获取网页源代码\n\n``` python\nurl='http://www.xbiquge.la/13/13959/' #小说目录网页的网址 \nresponse=requests.get(url)\nresponse.encoding='utf-8' #注意网页编码问题\ncatalogHtml=response.text #获取目录网页的html源代码\n```\n\n我们可以看一下获取到的HTML源代码：\n\n``` python\nprint(catalogHtml)\n```\n\n![HTML](https://cdn.jsdelivr.net/gh/shallowhui/cdn/img/spider/spiderhtml.png)\n\n### 定位数据，采集数据\n\n这一步我们需要用到正则表达式在HTML源代码中对我们所需的数据进行定位，以此来采集我们所需的数据。定位的标准是尽可能的唯一，准确。比如说，`<a href=\"xx\">xx</a>`这个标签对中就可以匹配出每章章节的URL地址和章节名字。\n\n``` python\nchapterDiv=re.findall(r'<div id=\"list\">.*?</div>',catalogHtml,re.S)[0]\nchapter_list=re.findall(r'href=\\'(.*?)\\' >(.*?)<',chapterDiv)\n```\n\n我们可以看一下匹配结果：\n\n``` python\nprint(chapter_list)\n```\n\n![list](https://cdn.jsdelivr.net/gh/shallowhui/cdn/img/spider/spiderlist.png)\n\n+ 可以看出findall函数返回一个匹配结果形成的列表，我会另写一篇博客来专门介绍用来在字符串中匹配特定内容的[正则表达式](https://zunhuier.top/posts/46563/)。\n\n### 清洗数据，打印输出\n\n清洗数据就是对采集到的数据进行整理、规范化，使数据更加直观易读。这里我就简单整理了下数据，直接打印输出：\n\n``` python\nfor chapter in chapter_list:\n    chapter_url='http://www.xbiquge.la'+chapter[0] #补全章节完整域名\n    chapter_title=chapter[1]\n    print(chapter_url,chapter_title)\n```\n\n![Result](https://cdn.jsdelivr.net/gh/shallowhui/cdn/img/spider/spiderresult.png)\n\n### 分析数据\n\n我们已经拿到想要的数据了，接下来就可以利用，分析这些数据，我们还可以拿着上面的章节完整域名继续去爬取每章小说的具体内容^_^具体怎么利用这些数据就看个人了。\n\n但请注意！！！爬虫需谨慎！！！《中华人民共和国网络安全法》！！！\n\n### 附上完整源代码\n\n``` python\nimport requests\nimport re #python中自带的对正则表达式支持的库\n\n\nurl='http://www.xbiquge.la/13/13959/' #小说目录网页的网址 \n\n#requests模块帮助我们模拟浏览器去访问网页并获取服务器响应结果，不用关心底层实现\nresponse=requests.get(url)\nresponse.encoding='utf-8' #注意网页编码问题\ncatalogHtml=response.text #获取目录网页的html源代码\n\n#用正则表达式在html源代码中匹配每一章的url和章名，需要会看html源代码\nchapterDiv=re.findall(r'<div id=\"list\">.*?</div>',catalogHtml,re.S)[0]\n#形成章节列表，注意单引号里的单引号需要转义\nchapter_list=re.findall(r'href=\\'(.*?)\\' >(.*?)<',chapterDiv)\n\n#循环遍历列表，爬取章节目录\nfor chapter in chapter_list:\n    chapter_url='http://www.xbiquge.la'+chapter[0] #补全章节完整域名\n    chapter_title=chapter[1]\n    print(chapter_url,chapter_title)\n```\n\n## 总结\n\n这是一种最简单的爬虫，只展示了爬虫的基本实现原理，除了python没用到其它更复杂的技术，只能用来完成一些简单的特定功能。当然，爬虫还有更高级的应用，网络上也有着大量优秀的爬虫开源框架。","tags":["网络爬虫"],"categories":["Python"]},{"title":"Git的基础命令","url":"/posts/64652/","content":"## Git——分布式版本控制系统\n\n### 简介\n\nLinus大佬花了两周的时间用C语言写出了Git。Git是套命令行工具，去[官网](https://git-scm.com/)直接下载安装即可(windows下需要配环境变量，mac下不用(git会自动将一个命令替身安装在/usr/bin/目录下))，linux下直接终端输入sudo apt-get install git)。安装好后用命令配置个人用户信息(git配置按优先级从低到高分为：全局配置，适用于全体电脑用户→用户配置，适用于当前电脑用户→项目(特定仓库)配置)：\n\n``` bash\n$ git config --global user.name \"输入你的名字\"\n$ git config --global user.email \"输入你的邮箱\"\n```\n这个配置起识别用户的作用。\n\n### 推荐\n\n 我这篇博客只是简单总结了一下git的常用简单命令，若想系统地了解git，分支，标签，分布式等等，这里推荐一个[教程](https://www.liaoxuefeng.com/wiki/896043488029600)。\n\n## 简单命令的使用\n\n### 一些基本概念\n\n+ 工作区：指本地仓库(git初始化后的本地文件夹)，你进行操作的地方。\n+ 暂存区：修改必须先送到暂存区保存起来。\n+ 版本库：从暂存区将修改送到版本库即完成一次提交。\n+ 修改：在git中，增、删、改操作都可以叫做修改。\n+ 提交：对修改进行提交，完成一次版本记录。\n\n### Git进行版本控制的精髓\n\n**git通过一系列底层数据对象和结构，对文件内容和修改提交进行追踪并引用。git有HEAD引用，指向当前分支，分支指向最新提交，提交指向当时的顶层tree对象。解决合并冲突需要手动修改文件然后再提交。**\n\n上面一段话看不懂没关系，可以去Git的官方文档查看Git的底层原理那一节，讲得非常详细。\n\n![Branch](https://cdn.jsdelivr.net/gh/shallowhui/cdn/img/git/git.jpg)\n\n### 初始化一个本地仓库\n\n新建一个文件夹当做本地仓库准备初始化，然后在这个文件夹下进行git命令操作，windows下控制台cd进入文件夹，mac下打开当前文件夹的终端。\n\n``` bash\n$ git init #初始化一个本地git仓库，目录下会多出一个隐藏文件夹(.git)，暂存区、版本库、项目配置等都在里面\n```\n### 建立远程连接\n\n+ 这一步可以不做。\n\n``` bash\n$ git remote add 自定义远程仓库名 远程仓库地址 #可以将本地仓库与一个远程仓库关联\n```\n可以是Gihthub上的一个仓库，也可以是自己搭建的Git服务器。如果要与Github上的仓库连接，事先要进行本机的.ssh_key配置，具体教程百度，很简单，当然要有Github账户。\n\n### 完成一次提交\n\n提交要按顺序不能颠倒命令。\n\n``` bash\n$ git add 文件名.扩展名 #将修改送到暂存区，可以一次性add多份文件，注意后面的命令都要加上扩展名\n$ git add . #将工作区里的所有修改送到暂存区\n```\n``` bash\n$ git commit -m \"提交备注\" #将暂存区里的所有修改提交到版本库\n```\n### 常用命令\n\n``` bash\n$ git push 自定义的远程仓库名 本地仓库分支名 #将本地仓库的一个指定分支推送到远程仓库\n```\n+ 注意：不能推送远程仓库已有的同名分支，git会认为这两个分支冲突(除非远程仓库的那个同名分支最初是由这个本地仓库推送过去的)，这种情况下要先从远程仓库拉取该分支过来进行合并。\n\n``` bash\n$ git fetch 自定义的远程仓库名 远程仓库分支名 #将远程仓库的一个指定分支拉取到本地仓库\n```\n``` bash\n$ git merge 指定分支名 #将指定分支合并到当前分支\n```\n``` bash\n$ git pull 自定义的远程仓库名 远程仓库分支名 # = git fetch + git merge\n```\n``` bash\n$ git status #查看当前分支的工作区的状态\n```\n``` bash\n$ git diff #查看工作区与当前分支的版本库的区别\n```\n``` bash\n$ git log #查看当前分支的提交历史\n```\n``` bash\n$ git checkout -- 文件名 #将指定文件回溯到当前分支最近一次add或commit之后的状态，即撤销修改\n```\n``` bash\n$ git reset HEAD 文件名 #将指定文件已经在暂存区的修改撤销掉\n```\n``` bash\n$ git rm 文件名 #删除工作区里的指定文件，并且已经将这个修改给add了\n```\n``` bash\n$ git clone 远程仓库地址 #将远程仓库里的项目克隆到本地\n```\n``` bash\n$ git branch #查看分支情况\n```\n``` bash\n$ git checkout -b 新建分支名 #新建一个分支并切换过去\n$ git switch -c 新建分支名 #新版git的创建切换分支的新命令\n```\n``` bash\n$ git checkout 分支名 #切换到指定分支\n$ git switch 分支名 #新命令\n```\n``` bash\n$ git branch -d 分支名 #删除指定分支，删除当前分支要先切换到其它分支\n$ git branch -D 分支名 #强制删除分支\n```\n``` bash\n$ git tag \"标签名称\" #给当前分支的最新提交打上一个标签，进行版本控制\n```\n``` bash\n$ git tag #查看当前分支的标签情况\n```\n``` bash\n$ git reset --hard 提交历史id #将当前分支的版本回退到指定的一次提交，即版本回退\n```\n## 未完待续\n","tags":["Git基础"],"categories":["Git"]}]